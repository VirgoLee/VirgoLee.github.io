<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Go语言之Context]]></title>
    <url>%2Fposts%2F6dc53ef7.html</url>
    <content type="text"><![CDATA[本文主要简单介绍了Go语言(golang)中的context。通过对底层结构的分析和实例讲述了context的基本用法。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述1.1 作用 1.web编程中，一个请求对应多个goroutine之间的数据交互 2.超时控制 3.上下文控制 1.2 底层结构12345678910type Context interface &#123; //返回一个time.Time，表示当前Context应该结束的时间，ok则表示有结束时间 Deadline() (deadline time.Time, ok bool) //当Context被取消或者超时时候返回的一个close的channel，告诉给context相关的函数要停止当前工作然后返回了。(这个有点像全局广播) Done() &lt;-chan struct&#123;&#125; //context被取消的原因 Err() error //ntext实现共享数据存储的地方，是协程安全的 Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 同时包中也定义了提供cancel功能需要实现的接口。这个主要是后文会提到的“取消信号、超时信号”需要去实现。 123456// A canceler is a context type that can be canceled directly. The// implementations are *cancelCtx and *timerCtx.type canceler interface &#123; cancel(removeFromParent bool, err error) Done() &lt;-chan struct&#123;&#125;&#125; 1.3 context的创建为了更方便的创建Context，包里头定义了Background来作为所有Context的根，它是一个emptyCtx的实例。 12345678var ( background = new(emptyCtx) todo = new(emptyCtx) // )func Background() Context &#123; return background&#125; 你可以认为所有的Context是树的结构，Background是树的根，当任一Context被取消的时候，那么继承它的Context 都将被回收 2. context实战应用2.1 WithCancel可以手动取消的 Context 12345func WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123; c := newCancelCtx(parent) propagateCancel(parent, &amp;c) return &amp;c, func() &#123; c.cancel(true, Canceled) &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637func main()&#123; ctx, cancel := context.WithCancel(context.Background()) add := CountAddCancel(ctx) for value := range add &#123; //当累加超过30时 手动调用cancel() 取消context if value &gt; 30 &#123; cancel() break &#125; &#125; fmt.Println("正在统计结果。。。") time.Sleep(1500 * time.Millisecond)&#125;func CountAddCancel(ctx context.Context) &lt;-chan int &#123; c := make(chan int) n := 0 t := 0 go func() &#123; for &#123; time.Sleep(time.Second * 1) select &#123; //手动调用cancel() 取消context 后 channel被close case &lt;-ctx.Done(): fmt.Printf("耗时 %d S 累加值 % d \n", t, n) return case c &lt;- n: // 随机增加1-5 incr := rand.Intn(4) + 1 n += incr t++ fmt.Printf("当前累加值 %d \n", n) &#125; &#125; &#125;() return c&#125; 2.2 WithDeadline &amp; WithTimeout设定超时时间，时间到了自动取消context。 12345678910111213141516171819202122232425262728func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123; if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123; // The current deadline is already sooner than the new one. return WithCancel(parent) &#125; c := &amp;timerCtx&#123; cancelCtx: newCancelCtx(parent), deadline: d, &#125; propagateCancel(parent, c) dur := time.Until(d) if dur &lt;= 0 &#123; c.cancel(true, DeadlineExceeded) // deadline has already passed return c, func() &#123; c.cancel(true, Canceled) &#125; &#125; c.mu.Lock() defer c.mu.Unlock() if c.err == nil &#123; c.timer = time.AfterFunc(dur, func() &#123; c.cancel(true, DeadlineExceeded) &#125;) &#125; return c, func() &#123; c.cancel(true, Canceled) &#125;&#125;func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout))&#125; 123456789101112131415161718192021func main()&#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second*10) CountAddTimeOut(ctx) defer cancel()&#125;func CountAddTimeOut(ctx context.Context) &#123; n := 0 for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println("时间到了 \n") return default: incr := rand.Intn(4)+1 n += incr fmt.Printf("当前累加值 %d \n", n) &#125; time.Sleep(time.Second) &#125;&#125; 2.3 WithValue可以传递数据的context，携带关键信息，为全链路提供线索，比如接入elk等系统，需要来一个trace_id，那WithValue就非常适合做这个事。 123456789func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123; if key == nil &#123; panic("nil key") &#125; if !reflect.TypeOf(key).Comparable() &#123; panic("key is not comparable") &#125; return &amp;valueCtx&#123;parent, key, val&#125;&#125; 3. 建议 1.不要把Context放在结构体中，要以参数的方式传递，parent Context一般为Background 2。应该要把Context作为第一个参数传递给入口请求和出口请求链路上的每一个函数，放在第一位，变量名建议都统一，如ctx。 3.给一个函数方法传递Context的时候，不要传递nil，否则在tarce追踪的时候，就会断了连接 4.Context的Value相关方法应该传递必须的数据，不要什么数据都使用这个传递 5.Context是线程安全的，可以放心的在多个goroutine中传递 6.可以把一个 Context 对象传递给任意个数的 gorotuine，对它执行 取消 操作时，所有 goroutine 都会接收到取消信号。 4. 参考https://blog.csdn.net/qq_36183935/article/details/81137834 https://blog.csdn.net/u011957758/article/details/82948750 https://www.jianshu.com/p/e5df3cd0708b]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go-Micro框架入门教程(一)---框架结构]]></title>
    <url>%2Fposts%2F91b4718c.html</url>
    <content type="text"><![CDATA[Go语言微服务系列文章，使用golang实现微服务，这里选用的是go-micro框架,本文主要是对该框架的一个架构简单介绍。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述go-micro是go语言下的一个很好的微服务框架。 1.服务间传输格式为protobuf，效率上没的说，非常的快，也很安全。 2.go-micro的服务注册和发现是多种多样的。我个人比较喜欢etcdv3的服务服务发现和注册。 3.主要的功能都有相应的接口，只要实现相应的接口，就可以根据自己的需要订制插件。 2. 通信流程 go-micro的通信流程大至如下 Server端需要向Register注册自己的存在或消亡，这样Client才能知道自己的状态。 同时Server监听客户端的调用和Brocker推送过来的信息进行处理。 Client端从Register中得到Server的信息，然后每次调用都根据算法选择一个的Server进行通信，当然通信是要经过编码/解码，选择传输协议等一系列过程的。 3. 框架结构 go-micro 之所以可以高度订制和他的框架结构是分不开的，go-micro 由8个关键的 interface组成，每一个interface 都可以根据自己的需求重新实现，这8个主要的inteface也构成了go-micro的框架结构。 1.Transort服务之间通信的接口。 也就是服务发送和接收的最终实现方式，是由这些接口定制的 123456789101112131415161718192021type Socket interface &#123; Recv(*Message) error Send(*Message) error Close() error&#125; type Client interface &#123; Socket&#125; type Listener interface &#123; Addr() string Close() error Accept(func(Socket)) error&#125; type Transport interface &#123; Dial(addr string, opts ...DialOption) (Client, error) Listen(addr string, opts ...ListenOption) (Listener, error) String() string&#125; Transport 的Listen方法是一般是Server端进行调用的，他监听一个端口，等待客户端调用。 Transport 的Dial就是客户端进行连接服务的方法。他返回一个Client接口，这个接口返回一个Client接口，这个Client嵌入了Socket接口，这个接口的方法就是具体发送和接收通信的信息。 是go-micro默认的同步通信机制是http传输。当然还有很多其他的插件：grpc,nats,tcp,udp,rabbitmq,都是目前已经实现了的方式。 2. Codec有了传输方式，下面要解决的就是传输编码和解码问题，go-micro有很多种编码解码方式，默认的实现方式是protobuf,当然也有其他的实现方式，json、protobuf、jsonrpc、mercury等等。 12345678910111213141516type Codec interface &#123; ReadHeader(*Message, MessageType) error ReadBody(interface&#123;&#125;) error Write(*Message, interface&#123;&#125;) error Close() error String() string&#125; type Message struct &#123; Id uint64 Type MessageType Target string Method string Error string Header map[string]string&#125; Codec接口的Write方法就是编码过程，两个Read是解码过程。 3. Registry服务的注册和发现，目前实现的consul,mdns, etcd,etcdv3,zookeeper,kubernetes.等 123456789type Registry interface &#123; Register(*Service, ...RegisterOption) error Deregister(*Service) error GetService(string) ([]*Service, error) ListServices() ([]*Service, error) Watch(...WatchOption) (Watcher, error) String() string Options() Options&#125; 简单来说就是Service 进行Register，来进行注册，Client 使用watch方法进行监控，当有服务加入或者删除时这个方法会被触发，以提醒客户端更新Service信息。 默认的是服务注册和发现是consul， 我个人比较喜欢etcdv3集群。大家可以根据自己的喜好选择。 4. Selector 以Registry为基础，Selector 是客户端级别的负载均衡，当有客户端向服务发送请求时， selector根据不同的算法从Registery中的主机列表，得到可用的Service节点，进行通信。目前实现的有循环算法和随机算法，默认的是随机算法 1234567891011121314type Selector interface &#123; Init(opts ...Option) error Options() Options // Select returns a function which should return the next node Select(service string, opts ...SelectOption) (Next, error) // Mark sets the success/error against a node Mark(service string, node *registry.Node, err error) // Reset returns state back to zero for a service Reset(service string) // Close renders the selector unusable Close() error // Name of the selector String() string&#125; 默认的是实现是本地缓存，当前实现的有blacklist,label,named等方式。 5. BrokerBroker是消息发布和订阅的接口。很简单的一个例子，因为服务的节点是不固定的，如果有需要修改所有服务行为的需求，可以使服务订阅某个主题，当有信息发布时，所有的监听服务都会收到信息，根据你的需要做相应的行为。 12345678910type Broker interface &#123; Options() Options Address() string Connect() error Disconnect() error Init(...Option) error Publish(string, *Message, ...PublishOption) error Subscribe(string, Handler, ...SubscribeOption) (Subscriber, error) String() string&#125; Broker默认的实现方式是http方式，但是这种方式不要在生产环境用。go-plugins里有很多成熟的消息队列实现方式，有kafka、nsq、rabbitmq、redis等等。 6. Client Client是请求服务的接口。 他封装 Transport 和 Codec 进行rpc调用，也封装了Brocker进行信息的发布。 12345678910type Client interface &#123; Init(...Option) error Options() Options NewMessage(topic string, msg interface&#123;&#125;, opts ...MessageOption) Message NewRequest(service, method string, req interface&#123;&#125;, reqOpts ...RequestOption) Request Call(ctx context.Context, req Request, rsp interface&#123;&#125;, opts ...CallOption) error Stream(ctx context.Context, req Request, opts ...CallOption) (Stream, error) Publish(ctx context.Context, msg Message, opts ...PublishOption) error String() string&#125; 当然他也支持双工通信 Stream 这些具体的实现方式和使用方式，默认的是rpc实现方式，他还有grpc和http方式，在go-plugins里可以找到 7. Server Server看名字大家也知道是做什么的了。监听等待rpc请求。监听broker的订阅信息，等待信息队列的推送等。 12345678910111213type Server interface &#123; Options() Options Init(...Option) error Handle(Handler) error NewHandler(interface&#123;&#125;, ...HandlerOption) Handler NewSubscriber(string, interface&#123;&#125;, ...SubscriberOption) Subscriber Subscribe(Subscriber) error Register() error Deregister() error Start() error Stop() error String() string&#125; 默认的是rpc实现方式，他还有grpc和http方式，在go-plugins里可以找到 8. ServiceService是Client和Server的封装，他包含了一系列的方法使用初始值去初始化Service和Client，使我们可以很简单的创建一个rpc服务。 12345678type Service interface &#123; Init(...Option) Options() Options Client() client.Client Server() server.Server Run() error String() string&#125; 4. 参考https://blog.csdn.net/mi_duo/article/details/82701732]]></content>
      <categories>
        <category>Micro</category>
      </categories>
      <tags>
        <tag>Micro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gRPC入门教程(零)---使用gRPC时遇到的问题]]></title>
    <url>%2Fposts%2Fff853faf.html</url>
    <content type="text"><![CDATA[本文章主要记录在使用gRPC时遇到的一些问题及其解决方案。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述gRPC是支持跨语言的，但是最近在使用gPRC跨语言调用时遇到一个奇怪的问题。 2. 具体问题其中客户端由golang编写，服务端由python编写。 golang客户端调用Python服务时一直报如下这个错： 1rpc error:Code=Unimplemented desc = Method Not Found！ 下面是官网上的错误列表，其中GRPC_STATUS_UNIMPLEMENTED对应的case也是Method not found on server。 Case Status code Client application cancelled the request GRPC_STATUS_CANCELLED Deadline expired before server returned status GRPC_STATUS_DEADLINE_EXCEEDED Method not found on server GRPC_STATUS_UNIMPLEMENTED Server shutting down GRPC_STATUS_UNAVAILABLE Server threw an exception (or did something other than returning a status code to terminate the RPC) GRPC_STATUS_UNKNOWN 最奇怪的是单独测试时都正常 python自己写的客户端 服务端可以正常交互 golang写的客户端 服务端也可以正常交互。 但是两个互相调用时会出现Method Not Found这个错误 然后都仔细检查代码之后并没有什么问题。 3. 原因看了各种官方文档和issue之后也没有找到原因。 最终在下面这个文章里面找到了原因,博主也遇到了相同的问题。 地址：https://www.itread01.com/content/1547029280.html 这是由于.proto文件中的package name被修改，和 server 端的package 不一致导致的,双方同步.proto文件packagename 重新编译生成对应的代码即可。 由于python编写.proto文件时没有加package xxx;然后golang对包名是比较严格的,所以这边加了package xxx;就是因为这个小改动导致一直无法正常调用,果然在修改.proto文件从新编译后就能成功运行了。 4. 参考https://www.itread01.com/content/1547029280.html]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gRPC入门教程(二)---gRPC简单使用]]></title>
    <url>%2Fposts%2F5ad1b62f.html</url>
    <content type="text"><![CDATA[本文主要对 gRPC 框架做了简单的介绍，同时记录了具体安装方法与基本使用教程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述gRPC 是一个高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf(Protocol Buffers)序列化协议开发，且支持众多开发语言。 gRPC基于HTTP/2标准设计，带来诸如双向流控、头部压缩、单TCP连接上的多复用请求等特性。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。 在 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。 gRPC 默认使用 protocol buffers，这是 Google 开源的一套成熟的结构数据序列化机制（当然也可以使用其他数据格式如 JSON）。 2. 环境准备env gRPC 需要 go 1.6以上 安装gRPC1go get -u google.golang.org/grpc 12$ go get -u google.golang.org/grpcpackage google.golang.org/grpc: unrecognized import path "google.golang.org/grpc" (https fetch: Get https://google.golang.org/grpc?go-get=1: dial tcp 216.239.37.1:443: i/o timeout) 国内一般这样安装不上，具体解决办法：https://github.com/grpc/grpc-go#FAQ 如果用了go mod 可以用下面的方法 1234go mod edit -replace=google.golang.org/grpc=github.com/grpc/grpc-go@latestgo mod tidygo mod vendorgo build -mod=vendor 安装protobuf具体见gRPC入门教程(一)—Protobuf安装与基本使用 3. 使用步骤 1）需要使用 protobuf 定义接口，即编写 .proto 文件 2）然后使用 compile 工具生成特定语言的执行代码，比如 Java、C/C++、Python 等。类似于 thrift，为了解决跨语言问题。 3）启动一个 Server 端，server 端通过侦听指定的 port，来等待 Client 链接请求，通常使用 Netty 来构建，gRPC 内置了 Netty 的支持。 4）启动一个或者多个 Client 端，Client 也是基于 Netty，Client 通过与 Server 建立 TCP 长链接，并发送请求；Request 与 Response 均被封装成 HTTP2 的 stream Frame，通过 Netty Channel 进行交互。 4. 示例程序1.hello.proto12345678910111213141516171819syntax = &quot;proto3&quot;;package helloworld;// The greeting service definition.service Greeter &#123; // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// The request message containing the user&apos;s name.message HelloRequest &#123; string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123; string message = 1;&#125; 编译 12345678910// 官方插件protoc --go_out=plugins=grpc:. hello.proto// protoc 编译命令// go_out 编译成go代码 java_out 则编译成Java代码// plugins=grpc 使用grpc插件提供对grpc的支持 否则不会生成Service的接口// :. 编译到当前路径// hello.proto 被编译的文件// gofast插件protoc --gofast_out=plugins=grpc:. hello.proto 生成对应的 pb.go 文件。这里用了 plugins 选项，提供对 grpc 的支持，否则不会生成 Service 的接口。 这里定义了一个服务 Greeter，其中有个API SayHello。其接受参数为HelloRequest类型，返回HelloReply类型。这里HelloRequest和HelloReply就是普通的PB定义 服务定义为： 123456789// The greeting service definition.service Greeter &#123; // Sends a greeting rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125; service定义了一个server。其中的接口可以是四种类型 rpc GetFeature(Point) returns (Feature) {}类似普通的函数调用，客户端发送请求Point到服务器，服务器返回相应Feature. rpc ListFeatures(Rectangle) returns (stream Feature) {}客户端发起一次请求，服务器端返回一个流式数据，比如一个数组中的逐个元素 rpc RecordRoute(stream Point) returns (RouteSummary) {}客户端发起的请求是一个流式的数据，比如数组中的逐个元素，服务器返回一个相应 rpc RouteChat(stream RouteNote) returns (stream RouteNote) {}客户端发起的请求是一个流式数据，比如数组中的逐个元素，二服务器返回的也是一个类似的数据结构 2.Server123456789101112131415161718192021222324252627282930313233package main import ( "log" "net" //pb文件目录 pb "your_path_to_gen_pb_dir/helloworld" "golang.org/x/net/context" "google.golang.org/grpc") const ( port = ":50051") // server is used to implement helloworld.GreeterServer.type server struct&#123;&#125; // SayHello implements helloworld.GreeterServerfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123; return &amp;pb.HelloReply&#123;Message: "Hello " + in.Name&#125;, nil&#125; func main() &#123; lis, err := net.Listen("tcp", port) if err != nil &#123; log.Fatalf("failed to listen: %v", err) &#125; s := grpc.NewServer() pb.RegisterGreeterServer(s, &amp;server&#123;&#125;) s.Serve(lis)&#125; 这里首先定义一个 server 结构，然后实现 SayHello 的接口。 1SayHello(context.Context, *HelloRequest) (*HelloReply, error) 然后调用grpc.NewServer() 创建一个server s。接着注册这个server s到结构server上面 pb.RegisterGreeterServer(s, &amp;server{}) 最后将创建的net.Listener传给s.Serve()。就可以开始监听并服务了，类似HTTP的ListenAndServe。 3.client123456789101112131415161718192021222324252627282930313233343536package main import ( "log" "os" pb "your_path_to_gen_pb_dir/helloworld" "golang.org/x/net/context" "google.golang.org/grpc") const ( address = "localhost:50051" defaultName = "world") func main() &#123; // Set up a connection to the server. conn, err := grpc.Dial(address, grpc.WithInsecure()) if err != nil &#123; log.Fatalf("did not connect: %v", err) &#125; defer conn.Close() c := pb.NewGreeterClient(conn) // Contact the server and print out its response. name := defaultName if len(os.Args) &gt; 1 &#123; name = os.Args[1] &#125; r, err := c.SayHello(context.Background(), &amp;pb.HelloRequest&#123;Name: name&#125;) if err != nil &#123; log.Fatalf("could not greet: %v", err) &#125; log.Printf("Greeting: %s", r.Message)&#125; 这里通过pb.NewGreeterClient()传入一个conn创建一个client，然后直接调用client上面对应的服务器的接口 1SayHello(context.Context, *HelloRequest) (*HelloReply, error) 接口，返回*HelloReply 对象。 先运行服务器，在运行客户端，可以看到。 12019/07/02 17:07:50 Greeting: Hello world 5. 小结使用gRPC的3个步骤 1. 写proto文件12345678910111213141516171819syntax = &quot;proto3&quot;;package helloworld;// 定义一个服务service UserService &#123; // 定义服务中的某个方法 请求参数User 返回值Resp rpc Create (User) returns (Resp) &#123; &#125;&#125;// 请求参数message User &#123; string name = 1; string age = 2;&#125;// 返回值message Resp &#123; string message = 1;&#125; 2. 编译后的文件部分代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// UserServiceClient is the client API for UserService service.//// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.// 客户端调用接口type UserServiceClient interface &#123; Create(ctx context.Context, in *User, opts ...grpc.CallOption) (*Resp, error)&#125;type userServiceClient struct &#123; cc *grpc.ClientConn&#125;func NewUserServiceClient(cc *grpc.ClientConn) UserServiceClient &#123; return &amp;userServiceClient&#123;cc&#125;&#125;// 客户端调用的方法具体实现func (c *userServiceClient) Create(ctx context.Context, in *User, opts ...grpc.CallOption) (*Resp, error) &#123; out := new(Resp) // invoke 大概是反射调用 service中的方法 err := c.cc.Invoke(ctx, "/helloworld.UserService/Create", in, out, opts...) if err != nil &#123; return nil, err &#125; return out, nil&#125;// UserServiceServer is the server API for UserService service.type UserServiceServer interface &#123; Create(context.Context, *User) (*Resp, error)&#125;func RegisterUserServiceServer(s *grpc.Server, srv UserServiceServer) &#123; s.RegisterService(&amp;_UserService_serviceDesc, srv)&#125;func _UserService_Create_Handler(srv interface&#123;&#125;, ctx context.Context, dec func(interface&#123;&#125;) error, interceptor grpc.UnaryServerInterceptor) (interface&#123;&#125;, error) &#123; in := new(User) if err := dec(in); err != nil &#123; return nil, err &#125; if interceptor == nil &#123; return srv.(UserServiceServer).Create(ctx, in) &#125; info := &amp;grpc.UnaryServerInfo&#123; Server: srv, FullMethod: "/helloworld.UserService/Create", &#125; handler := func(ctx context.Context, req interface&#123;&#125;) (interface&#123;&#125;, error) &#123; return srv.(UserServiceServer).Create(ctx, req.(*User)) &#125; return interceptor(ctx, in, info, handler)&#125;var _UserService_serviceDesc = grpc.ServiceDesc&#123; ServiceName: "helloworld.UserService", HandlerType: (*UserServiceServer)(nil), Methods: []grpc.MethodDesc&#123; &#123; MethodName: "Create", Handler: _UserService_Create_Handler, &#125;, &#125;, Streams: []grpc.StreamDesc&#123;&#125;, Metadata: "hello.proto",&#125; 3. Service定义结构体，实现proto中定义的接口。 1234567891011121314151617181920212223242526package mainimport ( "golang.org/x/net/context" "google.golang.org/grpc" pb "i-go/grpc/proto" "log" "net")// 定义一个结构体type userServer struct &#123;&#125;// 然后实现proto中定义的方法func (s *userServer) Create(ctx context.Context, user *pb.User) (msg *pb.Resp, err error) &#123; return &amp;pb.Resp&#123;Message: "Create Success"&#125;, nil&#125;func main() &#123; listener, err := net.Listen("tcp", "50052") if err != nil &#123; log.Fatalf("net.Listen fail: %v", err) &#125; newServer := grpc.NewServer() pb.RegisterUserServiceServer(newServer, &amp;userServer&#123;&#125;) newServer.Serve(listener)&#125; 4. client12345678910111213141516171819202122232425package mainimport ( "context" "google.golang.org/grpc" pb "i-go/grpc/proto" "log")func main() &#123; // grpc.WithInsecure() 禁用传输安全性 conn, err := grpc.Dial("localhost:50052", grpc.WithInsecure()) if err != nil &#123; log.Fatalf("did not connect: %v", err) &#125; defer conn.Close() // 创建一个client client := pb.NewUserServiceClient(conn) // 调用的是UserServiceClient中的方法 resp, err := client.Create(context.Background(), &amp;pb.User&#123;Name: "illusory", Age: "23"&#125;) if err != nil &#123; log.Fatalf("could not Create: %v", err) &#125; log.Printf("Create Resp: %s", resp.Message)&#125;]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gRPC入门教程(一)---Protobuf安装与基本使用]]></title>
    <url>%2Fposts%2F5ad1b62f.html</url>
    <content type="text"><![CDATA[本文主要记录了 Windows 环境下 Protobuf 的安装与基本使用教程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述Protocol buffers是一个灵活的、高效的、自动化的用于对结构化数据进行序列化的协议，与XML、json相比，Protocol buffers序列化后的码流更小、速度更快、操作更简单。 2. 安装2.1 安装protocprotoc 用来将.proto文件转化为自己使用的语言格式，我使用的是go语言，所以还要下载一个与protoc配合的插件，一会再说这个插件。 下载地址 1https://github.com/protocolbuffers/protobuf/releases 我这里是windows，所以下载的是[protoc-3.8.0-win64.zip],下载后解压,将bin目录下的protoc.exe复制到$GOPATH/bin目录中。 2.2 安装插件protoc-gen-go 是用来将protobuf的的代码转换成go语言代码的一个插件 github地址：https://github.com/golang/protobuf 使用以下命令将会自动把protoc-gen-go安装到$GOPATH/bin目录下 1go get -u github.com/golang/protobuf/protoc-gen-go goprotobuf还有另外两个插件 protoc-gen-gogo：和protoc-gen-go生成的文件差不多，性能也几乎一样(稍微快一点点) protoc-gen-gofast：生成的文件更复杂，性能也更高(快5-7倍) 12345//gogogo get github.com/gogo/protobuf/protoc-gen-gogo //gofastgo get github.com/gogo/protobuf/protoc-gen-gofast 2.3 安装protoproto是protobuf在golang中的接口模块 1go get github.com/golang/protobuf/proto 如果是使用的另外两个插件，则可以装下面的 12go get github.com/gogo/protobuf/protogo get github.com/gogo/protobuf/gogoproto 3. 使用3.1 编写一个proto文件derssbook.proto 1234567891011121314151617181920212223242526syntax = &quot;proto3&quot;;package go_protoc;message Person &#123; string name = 1; int32 id = 2; string email = 3; enum PhoneType &#123; MOBILE = 0; HOME = 1; WORK = 2; &#125; message PhoneNumber &#123; string number = 1; PhoneType type = 2; &#125; repeated PhoneNumber phones = 4;&#125;message AddressBook &#123; repeated Person people = 1;&#125; 3.2 编译12345678//官方protoc --go_out=. derssbook.proto//gogoprotoc --gogo_out=. derssbook.proto //gofastprotoc --gofast_out=. derssbook.proto 编译后会生成一个derssbook.pb.go文件。 编译命令解释 1$ protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --java_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR --ruby_out=DST_DIR --javanano_out=DST_DIR --objc_out=DST_DIR --csharp_out=DST_DIR path/to/file.proto 这里详细介绍golang的编译姿势: -I 参数：指定import路径，可以指定多个-I参数，编译时按顺序查找，不指定时默认查找当前目录 --go_out ：golang编译支持，支持以下参数 plugins=plugin1+plugin2 - 指定插件，目前只支持grpc，即：plugins=grpc M 参数 - 指定导入的.proto文件路径编译后对应的golang包名(不指定本参数默认就是.proto文件中import语句的路径) import_prefix=xxx - 为所有import路径添加前缀，主要用于编译子目录内的多个proto文件，这个参数按理说很有用，尤其适用替代一些情况时的M参数，但是实际使用时有个蛋疼的问题导致并不能达到我们预想的效果，自己尝试看看吧 import_path=foo/bar - 用于指定未声明package或go_package的文件的包名，最右面的斜线前的字符会被忽略 末尾 :编译文件路径 .proto文件路径(支持通配符) 4. 小结到此为止 主要记录了 protobuf 安装与插件支持，proto文件的编写与编译等流程。]]></content>
      <categories>
        <category>gRPC</category>
      </categories>
      <tags>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB入门系列(一)---基于Docker安装MongoDB]]></title>
    <url>%2Fposts%2F5d09291b.html</url>
    <content type="text"><![CDATA[本文主要记录了如何通过Docker方便快捷的安装MongoDB数据库。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述MongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。 MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。 2. 安装2.1 拉取镜像1docker pull mongo 2.2 准备环境123/usr/local/docker/mongodb/data //数据/usr/local/docker/mongodb/backup //备份/usr/local/docker/mongodb/conf //配置文件 准备3个文件夹用来存放相应数据。 2.3 配置文件mongodb.conf配置文件如下，建立好配置文件放到前面建好的目录中。 12345678# mongodb.conflogappend=true# bind_ip=127.0.0.1port=27017 fork=falsenoprealloc=true# 是否开启身份认证auth=false 2.4 启动容器1234567891011121314docker run --name mongodb -v \/usr/local/docker/mongodb/data:/data/db -v \/usr/local/docker/mongodb/backup:/data/backup -v \/usr/local/docker/mongodb/conf:/data/configdb -p \27017:27017 -d mongo \-f /data/configdb/mongodb.conf \--auth# 命令说明容器命名mongodb，数据库数据文件挂载到/usr/local/docker/mongodb/data备份文件挂载到/usr/local/docker/mongodb/backup启动的配置文件目录挂载到容器的/usr/local/docker/mongodb/conf--auth开启身份验证。-f /data/configdb/mongodb.conf 以配置文件启动 # mongod启动命令是在容器内执行的，因此使用的配置文件路径是相对于容器的内部路径。 3. 添加用户使用MongoDB之前需要先创建用户。 3.1 进入容器1docker exec -it mongodb bash 执行该命令进入到刚才启动的容器中。 3.2 进入 MongoDB1mongo 执行该命令进入到MongoDB客户端。 3.3 创建用户12345678910111213141516# 进入 admin 的数据库use admin# 创建管理员用户db.createUser( &#123; user: "admin", pwd: "123456", roles: [ &#123; role: "userAdminAnyDatabase", db: "admin" &#125; ] &#125; ) # 创建有可读写权限的用户. 对于一个特定的数据库, 比如'demo' db.createUser(&#123; user: 'test', pwd: '123456', roles: [&#123;role: "readWrite", db: "demo"&#125;] &#125;) 4. 使用到此为止MongoDB就安装完成了，可以远程连接了。连接之前先关闭Linux防火墙。 4.1 可视化工具可视化工具暂时用的Robo3T,官网：https://robomongo.org/ 4.2 连接使用前面创建的用户就可以远程连接到MongoDB了. 其中管理员用户是用来管理用户的。 每个用户只能访问指定的db。 比如上面的test账号只能访问demo这个db。 123url:192.168.1.1:27017username:testpassword:123456 5. 参考https://www.runoob.com/mongodb/mongodb-tutorial.html]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中为什么方法内定义的内部类可以访问方法中的局部变量]]></title>
    <url>%2Fposts%2F7d00948d.html</url>
    <content type="text"><![CDATA[本文主要通过实例代码分析了 Java 中为什么方法内定义的内部类可以访问方法中的局部变量。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述匿名内部类和非匿名内部类。 在平时写代码的过程中， 我们经常会写类似下面的代码段： 1234567891011public class Test &#123; public static void main(String[] args) &#123; final int count = 0; new Thread()&#123; public void run() &#123; int var = count; &#125;; &#125;.start(); &#125;&#125; 这段代码在 main 方法中定义了一个匿名内部类， 并且创建了匿名内部类的一个对象， 使用这个对象调用了匿名内部类中的方法。 所有这些操作都在new Thread(){}.start() 这一句代码中完成， 这不禁让人感叹 Java 的表达能力还是很强的。 上面的代码和以下代码等价： 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; final int count = 0; //在方法中定义一个内部类 class MyThread extends Thread&#123; public void run() &#123; int var = count; &#125; &#125; new MyThread().start(); &#125;&#125; 这里我们不关心方法中匿名内部类和非匿名内部类的区别， 我们只需要知道， 这两种方式都是定义在方法中的内部类， 他们的工作原理是相同的。 在本文中主要根据非匿名内部类讲解。 让我们仔细观察上面的代码都有哪些“奇怪”的行为： 1.在外部类的 main 方法中有一个局部变量 count， 并且在内部类的 run 方法中访问了这个 count 变量。 也就是说， 方法中定义的内部类， 可以访问方法中的局部变量（方法的参数也是局部变量）； 2.count 变量使用 final 关键字修饰， 如果去掉 final， 则编译失败。 也就是说被方法中的内部类访问的局部变量必须是final的。 由于我们经常这样做， 这样写代码， 久而久之养成了习惯， 就成了司空见惯的做法了。 但是如果要问为什么Java支持这样的做法， 恐怕很少有人能说的出来。 在下面， 我们就会分析为什么Java支持这种做法， 让我们不仅知其然， 还要知其所以然。 为什么定义在方法中的内部类可以访问方法中的局部变量？ 2. 原理分析2.1 当被访问的局部变量是编译时可确定的字面常量时我们首先看这样一段代码， 本文的以下部分会以这样的代码进行讲解。 123456789101112public class Outer &#123; void outerMethod()&#123; final String localVar = "abc"; /*定义在方法中的内部类*/ class Inner&#123; void innerMethod()&#123; String a = localVar; &#125; &#125; &#125;&#125; 在外部类的方法 outerMethod 中定义了成员变量 String localVar， 并且用一个编译时字面量 “abc” 给他赋值。在 outerMethod 方法中定义了内部类 Inner， 并且在内部类的方法 innerMethod 中访问了 localVar 变量。 接下来我们就根据这个例子来讲解为什么可以这样做。 首先看编译后的文件， 和普通的内部类一样， 定义在方法中的内部类在编译之后， 也有自己独立的 class 文件： 1. 反编译执行以下命令反编译该文件 1javap -classpath . -v Outer$1Inner -classpath . : 说明在当前目录下寻找要反编译的class文件-v : 加上这个参数输出的信息比较全面。包括常量池和方法内的局部变量表， 行号， 访问标志等等。 2. 结果分析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798D:\lillusory\Java\work_idea\java-learning\target\classes\jvm\localfiled&gt;javap -classpath . -v Outer$1InnerClassfile /D:/lillusory/Java/work_idea/java-learning/target/classes/jvm/localfiled/Outer$1Inner.class Last modified 2019-4-29; size 643 bytes MD5 checksum 12cea9ab1340856585960146078de1b3 Compiled from "Outer.java" &lt;!--版本号等信息--&gt;class jvm.localfiled.Outer$1Inner minor version: 0 major version: 52 flags: ACC_SUPER &lt;!--常量池--&gt;Constant pool: #1 = Fieldref #4.#27 // jvm/localfiled/Outer$1Inner.this$0:Ljvm/localfiled/Outer; #2 = Methodref #5.#28 // java/lang/Object."&lt;init&gt;":()V #3 = String #29 // abc #4 = Class #30 // jvm/localfiled/Outer$1Inner #5 = Class #31 // java/lang/Object #6 = Utf8 this$0 #7 = Utf8 Ljvm/localfiled/Outer; #8 = Utf8 &lt;init&gt; #9 = Utf8 (Ljvm/localfiled/Outer;)V #10 = Utf8 Code #11 = Utf8 LineNumberTable #12 = Utf8 LocalVariableTable #13 = Utf8 this #14 = Utf8 Inner #15 = Utf8 InnerClasses #16 = Utf8 Ljvm/localfiled/Outer$1Inner; #17 = Utf8 MethodParameters #18 = Utf8 innerMethod #19 = Utf8 ()V #20 = Utf8 a #21 = Utf8 Ljava/lang/String; #22 = Utf8 SourceFile #23 = Utf8 Outer.java #24 = Utf8 EnclosingMethod #25 = Class #32 // jvm/localfiled/Outer #26 = NameAndType #33:#19 // outerMethod:()V #27 = NameAndType #6:#7 // this$0:Ljvm/localfiled/Outer; #28 = NameAndType #8:#19 // "&lt;init&gt;":()V #29 = Utf8 abc #30 = Utf8 jvm/localfiled/Outer$1Inner #31 = Utf8 java/lang/Object #32 = Utf8 jvm/localfiled/Outer #33 = Utf8 outerMethod &lt;!--从这里开始看--&gt;&#123; final jvm.localfiled.Outer this$0; descriptor: Ljvm/localfiled/Outer; flags: ACC_FINAL, ACC_SYNTHETIC jvm.localfiled.Outer$1Inner(jvm.localfiled.Outer); descriptor: (Ljvm/localfiled/Outer;)V flags: Code: stack=2, locals=2, args_size=2 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Ljvm/localfiled/Outer; 5: aload_0 6: invokespecial #2 // Method java/lang/Object."&lt;init&gt;":()V 9: return LineNumberTable: line 11: 0 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Ljvm/localfiled/Outer$1Inner; 0 10 1 this$0 Ljvm/localfiled/Outer; MethodParameters: Name Flags this$0 final mandated void innerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: ldc #3 // String abc 2: astore_1 3: return LineNumberTable: line 13: 0 line 14: 3 LocalVariableTable: Start Length Slot Name Signature 0 4 0 this Ljvm/localfiled/Outer$1Inner; 3 1 1 a Ljava/lang/String;&#125;SourceFile: "Outer.java"EnclosingMethod: #25.#26 // jvm.localfiled.Outer.outerMethodInnerClasses: #14= #4; //Inner=class jvm/localfiled/Outer$1Inner 其中 InnerMethod 相关如下： 123456789101112131415void innerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: ldc #3 // String abc 2: astore_1 3: return LineNumberTable: line 13: 0 line 14: 3 LocalVariableTable: Start Length Slot Name Signature 0 4 0 this Ljvm/localfiled/Outer$1Inner; 3 1 1 a Ljava/lang/String; 1ldc #3 // String abc Idc 指令的意思是将索引指向的常量池中的项压入操作数栈。 这里的索引为3 ， 引用的常量池中的项为字符串“abc” 。 这句话就揭示了内部类访问方法局部变量的原理。 让我们从常量池第3项看起。 1#3 = String #29 // abc 但是这个字符串 “abc” 明明是定义在外部类 Outer 中的， 因为出现在外部类的 outerMethod 方法中。 为了查看这个 “abc” 是否在外部类中， 我们继续反编译外部类 Outer.class 。 3. 反编译外部类反编译外部类结果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071D:\lillusory\Java\work_idea\java-learning\target\classes\jvm\localfiled&gt;javap -classpath . -v Outer.classClassfile /D:/lillusory/Java/work_idea/java-learning/target/classes/jvm/localfiled/Outer.class Last modified 2019-4-29; size 471 bytes MD5 checksum 4442fd25b31a0563253f16e275643d11 Compiled from "Outer.java"public class jvm.localfiled.Outer minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#20 // java/lang/Object."&lt;init&gt;":()V #2 = String #21 // abc #3 = Class #22 // jvm/localfiled/Outer #4 = Class #23 // java/lang/Object #5 = Class #24 // jvm/localfiled/Outer$1Inner #6 = Utf8 Inner #7 = Utf8 InnerClasses #8 = Utf8 &lt;init&gt; #9 = Utf8 ()V #10 = Utf8 Code #11 = Utf8 LineNumberTable #12 = Utf8 LocalVariableTable #13 = Utf8 this #14 = Utf8 Ljvm/localfiled/Outer; #15 = Utf8 outerMethod #16 = Utf8 localVar #17 = Utf8 Ljava/lang/String; #18 = Utf8 SourceFile #19 = Utf8 Outer.java #20 = NameAndType #8:#9 // "&lt;init&gt;":()V #21 = Utf8 abc #22 = Utf8 jvm/localfiled/Outer #23 = Utf8 java/lang/Object #24 = Utf8 jvm/localfiled/Outer$1Inner&#123; public jvm.localfiled.Outer(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object."&lt;init&gt;":()V 4: return LineNumberTable: line 6: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Ljvm/localfiled/Outer; void outerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: ldc #2 // String abc 2: astore_1 3: return LineNumberTable: line 8: 0 line 16: 3 LocalVariableTable: Start Length Slot Name Signature 0 4 0 this Ljvm/localfiled/Outer; 3 1 1 localVar Ljava/lang/String;&#125;SourceFile: "Outer.java"InnerClasses: #6= #5; //Inner=class jvm/localfiled/Outer$1Inner 1#2 = String #21 // abc 我们可以看到， “abc” 这个字符串确实出现在 Outer.class 常量池的第15项。 这就奇怪了， 明明是定义在外部类的字面量， 为什么会出现在 内部类的常量池中呢？ 其实这正是编译器在编译方法中定义的内部类时， 所做的额外工作。 4. 修改局部变量类型下面我们将这个被内部类访问的局部变量改成整形的。 看看在字节码层面上会有什么变化。 修改后的源码如下： 12345678910111213public class Outer &#123; void outerMethod()&#123; final int localVar = 1; /*定义在方法中的内部类*/ class Inner&#123; void innerMethod()&#123; int a = localVar; &#125; &#125; &#125;&#125; 反编译内部类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293D:\lillusory\Java\work_idea\java-learning\target\classes\jvm\localfiled&gt;javap -classpath . -v Outer$1Inner警告: 二进制文件Outer$1Inner包含jvm.localfiled.Outer$1InnerClassfile /D:/lillusory/Java/work_idea/java-learning/target/classes/jvm/localfiled/Outer$1Inner.class Last modified 2019-4-29; size 616 bytes MD5 checksum f3e4d21797e0fe422029c3894699dbf6 Compiled from "Outer.java"class jvm.localfiled.Outer$1Inner minor version: 0 major version: 52 flags: ACC_SUPERConstant pool: #1 = Fieldref #3.#26 // jvm/localfiled/Outer$1Inner.this$0:Ljvm/localfiled/Outer; #2 = Methodref #4.#27 // java/lang/Object."&lt;init&gt;":()V #3 = Class #28 // jvm/localfiled/Outer$1Inner #4 = Class #29 // java/lang/Object #5 = Utf8 this$0 #6 = Utf8 Ljvm/localfiled/Outer; #7 = Utf8 &lt;init&gt; #8 = Utf8 (Ljvm/localfiled/Outer;)V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Inner #14 = Utf8 InnerClasses #15 = Utf8 Ljvm/localfiled/Outer$1Inner; #16 = Utf8 MethodParameters #17 = Utf8 innerMethod #18 = Utf8 ()V #19 = Utf8 a #20 = Utf8 I #21 = Utf8 SourceFile #22 = Utf8 Outer.java #23 = Utf8 EnclosingMethod #24 = Class #30 // jvm/localfiled/Outer #25 = NameAndType #31:#18 // outerMethod:()V #26 = NameAndType #5:#6 // this$0:Ljvm/localfiled/Outer; #27 = NameAndType #7:#18 // "&lt;init&gt;":()V #28 = Utf8 jvm/localfiled/Outer$1Inner #29 = Utf8 java/lang/Object #30 = Utf8 jvm/localfiled/Outer #31 = Utf8 outerMethod&#123; final jvm.localfiled.Outer this$0; descriptor: Ljvm/localfiled/Outer; flags: ACC_FINAL, ACC_SYNTHETIC jvm.localfiled.Outer$1Inner(jvm.localfiled.Outer); descriptor: (Ljvm/localfiled/Outer;)V flags: Code: stack=2, locals=2, args_size=2 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Ljvm/localfiled/Outer; 5: aload_0 6: invokespecial #2 // Method java/lang/Object."&lt;init&gt;":()V 9: return LineNumberTable: line 12: 0 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Ljvm/localfiled/Outer$1Inner; 0 10 1 this$0 Ljvm/localfiled/Outer; MethodParameters: Name Flags this$0 final mandated void innerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: iconst_1 1: istore_1 2: return LineNumberTable: line 14: 0 line 15: 2 LocalVariableTable: Start Length Slot Name Signature 0 3 0 this Ljvm/localfiled/Outer$1Inner; 2 1 1 a I&#125;SourceFile: "Outer.java"EnclosingMethod: #24.#25 // jvm.localfiled.Outer.outerMethodInnerClasses: #13= #3; //Inner=class jvm/localfiled/Outer$1Inner 其中 InnerMethod 如下： 123456789101112131415void innerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: iconst_1 1: istore_1 2: return LineNumberTable: line 14: 0 line 15: 2 LocalVariableTable: Start Length Slot Name Signature 0 3 0 this Ljvm/localfiled/Outer$1Inner; 2 1 1 a I 第一句变成了 1iconst_1 这句字节码的意义是：将int类型的常量 1 压入操作数栈。 这就是在内部类中访问外部类方法中的局部变量 int localVar = 1 的原理。 5. 小结 由此可见， 当内部类中访问的局部变量是int型的字面量时， 编译器直接将对该变量的访问嵌入到内部类的字节码中， 也就是说， 在运行时， 方法中的内部类和外部类， 和外部类方法中的局部变量就没有任何关系了。 这也是编译器所做的额外工作。 上面两种情况有一个共同点， 那就是， 被内部类访问的外部了方法中的局部变量， 都是在编译时可以确定的字面常量。 像下面这样的形式都是编译时可确定的字面常量： 123final String localVar = "abc";final int localVar = 1; 他们之所以被称为字面常量， 是因为他们被 final 修饰， 运行时不可改变， 当编译器在编译源文件时， 可以确定他们的值， 也可以确定他们在运行时不会被修改， 所以可以实现类似C语言宏替换的功能。也就是说虽然在编写源代码时， 在内部类中访问的是外部类定义的这个变量， 但是在编译成字节码时， 却把这个变量的值放入了访问这个变量的内部类的常量池中， 或直接将这个变量的值嵌入内部类的字节码指令中。 运行时这两个类各不相干， 各自访问各自的常量池， 各自执行各自的字节码指令。在编译方法中定义的内部类时， 编译器的行为就是这样的。 2.2 当被访问的局部变量的值在编译时不可确定时那么当方法中定义的内部类访问的局部变量不是编译时可确定的字面常量， 又会怎么样呢？想要让这个局部变量变成编译时不可确定的， 只需要将源码修改如下： 12345678910111213141516171819public class Outer &#123; void outerMethod()&#123; final String localVar = getString(); /*定义在方法中的内部类*/ class Inner&#123; void innerMethod()&#123; String a = localVar; &#125; &#125; new Inner(); &#125; String getString()&#123; return "illusory"; &#125;&#125; 由于使用 getString 方法的返回值为 localVar 赋值， 所以在编译时期， 编译器不可确定 localVar 的值， 必须在运行时执行了 getString 方法之后才能确定它的值。 既然编译时不不可确定， 那么像上面那样的处理就行不通了。 1. 反编译执行以下命令反编译该文件 1javap -classpath . -v Outer$1Inner -classpath . : 说明在当前目录下寻找要反编译的class文件-v : 加上这个参数输出的信息比较全面。包括常量池和方法内的局部变量表， 行号， 访问标志等等。 那么在这种情况下， 内部类是通过什么机制访问方法中的局部变量的呢？ 让我们继续反编译内部类的字节码： 2. 结果分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110D:\lillusory\Java\work_idea\java-learning\target\classes\jvm\localfiled&gt;javap -classpath . -v Outer$1Inner警告: 二进制文件Outer$1Inner包含jvm.localfiled.Outer$1InnerClassfile /D:/lillusory/Java/work_idea/java-learning/target/classes/jvm/localfiled/Outer$1Inner.class Last modified 2019-4-29; size 716 bytes MD5 checksum e63d82ebc8752469f0d30edde17e88a5 Compiled from "Outer.java"class jvm.localfiled.Outer$1Inner minor version: 0 major version: 52 flags: ACC_SUPERConstant pool: #1 = Fieldref #4.#29 // jvm/localfiled/Outer$1Inner.this$0:Ljvm/localfiled/Outer; #2 = Fieldref #4.#30 // jvm/localfiled/Outer$1Inner.val$localVar:Ljava/lang/String; #3 = Methodref #5.#31 // java/lang/Object."&lt;init&gt;":()V #4 = Class #32 // jvm/localfiled/Outer$1Inner #5 = Class #33 // java/lang/Object #6 = Utf8 val$localVar #7 = Utf8 Ljava/lang/String; #8 = Utf8 this$0 #9 = Utf8 Ljvm/localfiled/Outer; #10 = Utf8 &lt;init&gt; #11 = Utf8 (Ljvm/localfiled/Outer;Ljava/lang/String;)V #12 = Utf8 Code #13 = Utf8 LineNumberTable #14 = Utf8 LocalVariableTable #15 = Utf8 this #16 = Utf8 Inner #17 = Utf8 InnerClasses #18 = Utf8 Ljvm/localfiled/Outer$1Inner; #19 = Utf8 MethodParameters #20 = Utf8 Signature #21 = Utf8 ()V #22 = Utf8 innerMethod #23 = Utf8 a #24 = Utf8 SourceFile #25 = Utf8 Outer.java #26 = Utf8 EnclosingMethod #27 = Class #34 // jvm/localfiled/Outer #28 = NameAndType #35:#21 // outerMethod:()V #29 = NameAndType #8:#9 // this$0:Ljvm/localfiled/Outer; #30 = NameAndType #6:#7 // val$localVar:Ljava/lang/String; #31 = NameAndType #10:#21 // "&lt;init&gt;":()V #32 = Utf8 jvm/localfiled/Outer$1Inner #33 = Utf8 java/lang/Object #34 = Utf8 jvm/localfiled/Outer #35 = Utf8 outerMethod&#123; final java.lang.String val$localVar; descriptor: Ljava/lang/String; flags: ACC_FINAL, ACC_SYNTHETIC final jvm.localfiled.Outer this$0; descriptor: Ljvm/localfiled/Outer; flags: ACC_FINAL, ACC_SYNTHETIC jvm.localfiled.Outer$1Inner(); descriptor: (Ljvm/localfiled/Outer;Ljava/lang/String;)V flags: Code: stack=2, locals=3, args_size=3 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Ljvm/localfiled/Outer; 5: aload_0 6: aload_2 7: putfield #2 // Field val$localVar:Ljava/lang/String; 10: aload_0 11: invokespecial #3 // Method java/lang/Object."&lt;init&gt;":()V 14: return LineNumberTable: line 12: 0 LocalVariableTable: Start Length Slot Name Signature 0 15 0 this Ljvm/localfiled/Outer$1Inner; 0 15 1 this$0 Ljvm/localfiled/Outer; MethodParameters: Name Flags this$0 final mandated val$localVar final synthetic Signature: #21 // ()V void innerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: aload_0 1: getfield #2 // Field val$localVar:Ljava/lang/String; 4: astore_1 5: return LineNumberTable: line 14: 0 line 15: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Ljvm/localfiled/Outer$1Inner; 5 1 1 a Ljava/lang/String;&#125;SourceFile: "Outer.java"EnclosingMethod: #27.#28 // jvm.localfiled.Outer.outerMethodInnerClasses: #16= #4; //Inner=class jvm/localfiled/Outer$1Inner 首先来看它的构造方法。 方法的签名为： 1234jvm.localfiled.Outer$1Inner(); descriptor: (Ljvm/localfiled/Outer;Ljava/lang/String;)V flags: Code: 我们知道， 如果不定义构造方法， 那么编译器会为这个类自动生成一个无参数的构造方法。 这个说法在这里就行不通了， 因为我们看到， 这个内部类的构造方法又两个参数。 至于第一个参数， 是指向外部类对象的引用， 在前面一篇博客中已经详细的介绍过了， 不明白的可以先看上一篇博客， 这里就不再重复叙述。这也说明了方法中的内部类和类中定义的内部类有相同的地方， 既然他们都是内部类， 就都持有指向外部类对象的引用。 我们来分析第二个参数， 他是 String 类型的， 和在内部类中访问的局部变量 localVar 的类型相同。 再看构造方法中编号为6和7的字节码指令： 126: aload_27: putfield #2 // Field val$localVar:Ljava/lang/String; 这句话的意思是， 使用构造方法的第二个参数， 为当前这个内部类对象的成员变量赋值， 这个被赋值的成员变量的名字是 val$localVar 。 由此可见， 编译器自动为内部类增加了一个成员变量， 其实这个成员变量就是被访问的外部类方法中的局部变量。 这个局部变量在创建内部类对象时， 通过构造方法注入。 在调用构造方法时， 编译器会默认为这个参数传入外部类方法中的局部变量的值。 再看内部类中的方法 innerMethod 中是如何访问这个所谓的“局部变量的”。 看 innerMethod 中的前两条字节码： 12345678910111213141516void innerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: aload_0 1: getfield #2 // Field val$localVar:Ljava/lang/String; 4: astore_1 5: return LineNumberTable: line 14: 0 line 15: 5 LocalVariableTable: Start Length Slot Name Signature 0 6 0 this Ljvm/localfiled/Outer$1Inner; 5 1 1 a Ljava/lang/String; 其中 120: aload_01: getfield #2 // Field val$localVar:Ljava/lang/String; 这两条指令的意思是， 访问成员变量val$localVar的值。 而源代码中是访问外部类方法中局部变量的值。 所以， 在这里将编译时对外部类方法中的局部变量的访问， 转化成运行时对当前内部类对象中成员变量的访问。 3. 小结总结一下就是： 当方法中定义的内部类访问的方法局部变量的值， 不是在编译时能确定的字面常量时， 编译器会为内部类增加一个成员变量， 在运行时， 将对外部类方法中局部变量的访问转换成对这个内部类成员变量的方法。 这就要求内部类中的这个新增的成员变量和外部类方法中的局部变量具有相同的值。 编译器通过为内部类的构造方法增加参数， 并在调用构造器初始化内部类对象时传入这个参数， 来初始化内部类中的这个成员变量的值。 所以， 虽然在源文件中看起来是访问的外部类方法的局部变量， 其实运行时访问的是内部类对象自己的成员变量。 3. 为什么局部变量必须是final的上面我们讲解了， 方法中的内部类访问方法局部变量是怎么实现的。 那么为什么这个局部变量必须是 final 的呢？ 我认为有以下两个原因： 1. 原因一当局部变量的值为编译时可确定的字面常量时（ 如字符串 “abc” 或整数1 ）， 通过 final 修饰， 可以实现类似 C 语言的编译时宏替换功能。 这样的话， 外部类和内部类各自访问自己的常量池， 各自执行各自的字节码指令， 看起来就像共同访问外部类方法中的局部变量， 这样就可以达到语义上的一致性。 由于存在内部类和外部类中的常量值是一样的， 并且是不可改变的，这样就可以达到数值访问的一致性。 2. 原因二当局部变量的值不是可在编译时确定的字面常量时（比如通过方法调用为它赋值）， 这种情况下， 编译器给内部类增加相同类型的成员变量， 并通过构造函数将外部类方法中的局部变量的值赋给这个新增的内部类成员量。 3. 基本数据类型如果这个局部变量是基本数据类型时， 直接拷贝数值给内部类成员变量。这样的话， 内部类和外部类各自访问自己的基本数据类型的变量， 他们的变量值一样， 并且不可修改， 这样就保证了语义上和数值访问上的一致性。 4. 引用类型如果这个局部变量是引用数据类型时， 拷贝外部类方法中的引用值给内部类对象的成员变量， 这样的话， 他们就指向了同一个对象。 由于这两个引用变量指向同一个对象， 所以通过引用访问的对象的数据是一样的， 由于他们都不能再指向其他对象（被 final 修饰）， 所以可以保证内部类和外部类数据访问的一致性。 4. 参考https://blog.csdn.net/zhangjg_blog/article/details/19996629]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中为什么内部类可以访问外部类的成员]]></title>
    <url>%2Fposts%2F8d9c98e3.html</url>
    <content type="text"><![CDATA[本文主要通过实例源码与反编译详细分析了Java中为什么内部类可以访问外部类的成员。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述内部类就是定义在一个类内部的类。 定义在类内部的类有两种情况： 一种是被static关键字修饰的， 叫做静态内部类. 另一种是不被static关键字修饰的， 就是普通内部类。 注：在下文中所提到的内部类都是指这种不被static关键字修饰的普通内部类 静态内部类虽然也定义在外部类的里面， 但是它只是在形式上（写法上）和外部类有关系， 其实在逻辑上和外部类并没有直接的关系。而一般的内部类，不仅在形式上和外部类有关系（写在外部类的里面）， 在逻辑上也和外部类有联系。 这种逻辑上的关系可以总结为以下两点： 1.内部类对象的创建依赖于外部类对象 2.内部类对象持有指向外部类对象的引用。 上边的第二条可以解释为什么在内部类中可以访问外部类的成员。就是因为内部类对象持有外部类对象的引用。 2. 测试2.1 测试类123456789public class Outer &#123; int outerField = 0; class Inner&#123; void InnerMethod()&#123; int i = outerField; &#125; &#125;&#125; 虽然这两个类写在同一个文件中， 但是编译完成后， 还是生成各自的class文件： 2.2 反编译这里我们的目的是探究内部类的行为， 所以只反编译内部类的 class 文件 Outer$Inner.class 。 在命令行中， 切换到工程的bin目录， 输入以下命令反编译这个类文件： 1javap -classpath . -v Outer$Inner -classpath . : 说明在当前目录下寻找要反编译的class文件-v : 加上这个参数输出的信息比较全面。包括常量池和方法内的局部变量表， 行号， 访问标志等等。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100D:\lillusory\Java\work_idea\java-learning\target\classes\jvm\innerclass&gt;javap -classpath . -v Outer$Inner警告: 二进制文件Outer$Inner包含jvm.innerclass.Outer$InnerClassfile /D:/lillusory/Java/work_idea/java-learning/target/classes/jvm/innerclass/Outer$Inner.class Last modified 2019-4-29; size 596 bytes MD5 checksum 1c7365a21e81dd01b3c6b115c1a72484 Compiled from "Outer.java" &lt;!--类信息--&gt;class jvm.innerclass.Outer$Inner minor version: 0 major version: 52 flags: ACC_SUPER &lt;!--常量池--&gt;Constant pool: #1 = Fieldref #4.#24 // jvm/innerclass/Outer$Inner.this$0:Ljvm/innerclass/Outer; #2 = Methodref #5.#25 // java/lang/Object."&lt;init&gt;":()V #3 = Fieldref #26.#27 // jvm/innerclass/Outer.outerField:I #4 = Class #28 // jvm/innerclass/Outer$Inner #5 = Class #29 // java/lang/Object #6 = Utf8 this$0 #7 = Utf8 Ljvm/innerclass/Outer; #8 = Utf8 &lt;init&gt; #9 = Utf8 (Ljvm/innerclass/Outer;)V #10 = Utf8 Code #11 = Utf8 LineNumberTable #12 = Utf8 LocalVariableTable #13 = Utf8 this #14 = Utf8 Inner #15 = Utf8 InnerClasses #16 = Utf8 Ljvm/innerclass/Outer$Inner; #17 = Utf8 MethodParameters #18 = Utf8 InnerMethod #19 = Utf8 ()V #20 = Utf8 i #21 = Utf8 I #22 = Utf8 SourceFile #23 = Utf8 Outer.java #24 = NameAndType #6:#7 // this$0:Ljvm/innerclass/Outer; #25 = NameAndType #8:#19 // "&lt;init&gt;":()V #26 = Class #30 // jvm/innerclass/Outer #27 = NameAndType #31:#21 // outerField:I #28 = Utf8 jvm/innerclass/Outer$Inner #29 = Utf8 java/lang/Object #30 = Utf8 jvm/innerclass/Outer #31 = Utf8 outerField &lt;!--从这里开始看--&gt;&#123; final jvm.innerclass.Outer this$0; descriptor: Ljvm/innerclass/Outer; flags: ACC_FINAL, ACC_SYNTHETIC jvm.innerclass.Outer$Inner(jvm.innerclass.Outer); descriptor: (Ljvm/innerclass/Outer;)V flags: Code: stack=2, locals=2, args_size=2 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Ljvm/innerclass/Outer; 5: aload_0 6: invokespecial #2 // Method java/lang/Object."&lt;init&gt;":()V 9: return LineNumberTable: line 9: 0 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Ljvm/innerclass/Outer$Inner; 0 10 1 this$0 Ljvm/innerclass/Outer; MethodParameters: Name Flags this$0 final mandated void InnerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: aload_0 1: getfield #1 // Field this$0:Ljvm/innerclass/Outer; 4: getfield #3 // Field jvm/innerclass/Outer.outerField:I 7: istore_1 8: return LineNumberTable: line 11: 0 line 12: 8 LocalVariableTable: Start Length Slot Name Signature 0 9 0 this Ljvm/innerclass/Outer$Inner; 8 1 1 i I&#125;SourceFile: "Outer.java"InnerClasses: #14= #4 of #26; //Inner=class jvm/innerclass/Outer$Inner of class jvm/innerclass/Outer 2.3 解析暂时不看常量池等其他信息，从50行开始，可以看到第一行信息如下： 1final jvm.innerclass.Outer this$0; 这句话的意思是， 在内部类Outer$Inner中， 存在一个名字为this$0 ， 类型为jvm.innerclass.Outer的成员变量， 并且这个变量是final的。 其实这个就是所谓的“在内部类对象中存在的指向外部类对象的引用”。 但是我们在定义这个内部类的时候， 并没有声明它， 所以这个成员变量是编译器加上的。 虽然编译器在创建内部类时为它加上了一个指向外部类的引用， 但是这个引用是怎样赋值的呢？毕竟必须先给他赋值，它才能指向外部类对象。 下面我们把注意力转移到构造函数上,下面这段输出是关于构造函数的信息: 1234567891011121314151617jvm.innerclass.Outer$Inner(jvm.innerclass.Outer); descriptor: (Ljvm/innerclass/Outer;)V flags: Code: stack=2, locals=2, args_size=2 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Ljvm/innerclass/Outer; 5: aload_0 6: invokespecial #2 // Method java/lang/Object."&lt;init&gt;":()V 9: return LineNumberTable: line 9: 0 LocalVariableTable: Start Length Slot Name Signature 0 10 0 this Ljvm/innerclass/Outer$Inner; 0 10 1 this$0 Ljvm/innerclass/Outer; 我们知道， 如果在一个类中， 不声明构造方法的话， 编译器会默认添加一个无参数的构造方法。 但是这句话在这里就行不通了， 因为我们明明看到， 这个构造函数有一个构造方法， 并且类型为Outer。 所以说，编译器会为内部类的构造方法添加一个参数， 参数的类型就是外部类的类型。 下面我们看看在构造参数中如何使用这个默认添加的参数。 我们来分析一下构造方法的字节码。 下面是每行字节码的意义： 1aload_0 ： 将局部变量表中的第一个引用变量加载到操作数栈。 这里有几点需要说明。 1.局部变量表中的变量在方法执行前就已经初始化完成； 2.局部变量表中的变量包括方法的参数； 3.操作数栈就是执行当前代码的栈； 4.成员方法的局部变量表中的第一个变量永远是this； 所以这句话的意思是： 将this引用从局部变量表加载到操作数栈。 1aload_1： 将局部变量表中的第二个引用变量加载到操作数栈。 这里加载的变量就是构造方法中的Outer类型的参数 . 1putfield #1 // Field this$0:Ljvm/innerclass/Outer; 使用操作数栈顶端的引用变量为指定的成员变量赋值。 这里的意思是将外面传入的Outer类型的参数赋给成员变量this$0 。 这一句putfield字节码就揭示了， 指向外部类对象的这个引用变量是如何赋值的。 后面几句如下： 1235: aload_06: invokespecial #2 // Method java/lang/Object."&lt;init&gt;":()V9: return 大致就是使用this引用调用父类（Object）的构造方法然后返回。 这也印证了上面所说的内部类和外部类逻辑关系的第一条： 内部类对象的创建依赖于外部类对象。 在内部类的 InnerMethod 方法中， 访问了外部类的成员变量 outerField， 下面的字节码揭示了访问是如何进行的： 1234567891011121314151617void InnerMethod(); descriptor: ()V flags: Code: stack=1, locals=2, args_size=1 0: aload_0 1: getfield #1 // Field this$0:Ljvm/innerclass/Outer; 4: getfield #3 // Field jvm/innerclass/Outer.outerField:I 7: istore_1 8: return LineNumberTable: line 11: 0 line 12: 8 LocalVariableTable: Start Length Slot Name Signature 0 9 0 this Ljvm/innerclass/Outer$Inner; 8 1 1 i I 1getfield #1 // Field this$0:Ljvm/innerclass/Outer; 将成员变量this$0加载到操作数栈上来 1getfield #3 // Field jvm/innerclass/Outer.outerField:I 使用上面加载的this$0引用， 将外部类的成员变量outerField加载到操作数栈 1istore_1 将操作数栈顶端的int类型的值保存到局部变量表中的第二个变量上（注意， 第一个局部变量被 this 占用， 第二个局部变量是 i）。操作数栈顶端的 int 型变量就是上一步加载的 outerField 变量。 所以， 这句字节码的含义就是： 使用outerField为i赋值。 上面三步就是内部类中是如何通过指向外部类对象的引用， 来访问外部类成员的。 3. 总结本文通过反编译内部类的字节码， 说明了内部类是如何访问外部类对象的成员的，除此之外， 我们也对编译器的行为有了一些了解， 编译器在编译时会自动加上一些逻辑， 这正是我们感觉困惑的原因。 关于内部类如何访问外部类的成员， 分析之后其实也很简单， 主要是通过以下几步做到的： 1.编译器自动为内部类添加一个成员变量， 这个成员变量的类型和外部类的类型相同， 这个成员变量就是指向外部类对象的引用； 2.编译器自动为内部类的构造方法添加一个参数， 参数的类型是外部类的类型， 在构造方法内部使用这个参数为1中添加的成员变量赋值； 3.在调用内部类的构造函数初始化内部类对象时， 会默认传入外部类的引用。 4. 参考https://blog.csdn.net/weixin_39214481/article/details/80372676]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门教程(七)---通过 Docker 安装 Redis]]></title>
    <url>%2Fposts%2F96375af.html</url>
    <content type="text"><![CDATA[本文主要记录了如何通过 Docker 来快速的安装部署 Redis。相比直接安装，通过 Docker 来安装极为方便。 Redis系列教程目录 Redis入门教程(一)—安装与配置 Redis入门教程(二)—五大基础数据类型与常用命令 Redis入门教程(三)—安全性、事务、发布订阅 Redis入门教程(四)—主从复制与持久化 Redis入门教程(五)—搭建Redis集群 Redis入门教程(六)—通过JavaApi(Jedis)操作Redis Redis入门教程(七)—通过 Docker 安装 Redis ……. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述最开始是通过 Redis 官网下载的文件安装的，这里使用 Docker 在安装部署一次。 主要分为3个步骤： 1.拉取 Redis 镜像 2.准备配置文件 3.启动容器 当然 需要提前安装 Docker。 2. 拉取 Redis 镜像1docker pull redis 一句话就可以从 Docker 镜像仓库中拉取 Redis 最新镜像到本地。 3. 准备配置文件一般启动时都手动配置，使用外部配置文件redis.conf，Redis 配置文件样例如下： 这里需要注意的是： 1.bind 127.0.0.1这个一定要注释掉，不让无法通过外部连接 2.daemonize yes这个后台运行也要注释掉，否则后面会无法启动容器。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426# Redis配置文件样例# Note on units: when memory size is needed, it is possible to specifiy# it in the usual form of 1k 5GB 4M and so forth:## 1k =&gt; 1000 bytes# 1kb =&gt; 1024 bytes# 1m =&gt; 1000000 bytes# 1mb =&gt; 1024*1024 bytes# 1g =&gt; 1000000000 bytes# 1gb =&gt; 1024*1024*1024 bytes## units are case insensitive so 1GB 1Gb 1gB are all the same.# Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程# 启用守护进程后，Redis会把pid写到一个pidfile中，在/var/run/redis.piddaemonize no# 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定pidfile /var/run/redis.pid# 指定Redis监听端口，默认端口为6379# 如果指定0端口，表示Redis不监听TCP连接port 6379# 绑定的主机地址# 你可以绑定单一接口，如果没有绑定，所有接口都会监听到来的连接# bind 127.0.0.1# Specify the path for the unix socket that will be used to listen for# incoming connections. There is no default, so Redis will not listen# on a unix socket when not specified.## unixsocket /tmp/redis.sock# unixsocketperm 755# 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能timeout 0# 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose# debug (很多信息, 对开发／测试比较有用)# verbose (many rarely useful info, but not a mess like the debug level)# notice (moderately verbose, what you want in production probably)# warning (only very important / critical messages are logged)loglevel verbose# 日志记录方式，默认为标准输出，如果配置为redis为守护进程方式运行，而这里又配置为标准输出，则日志将会发送给/dev/nulllogfile stdout# To enable logging to the system logger, just set 'syslog-enabled' to yes,# and optionally update the other syslog parameters to suit your needs.# syslog-enabled no# Specify the syslog identity.# syslog-ident redis# Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.# syslog-facility local0# 设置数据库的数量，默认数据库为0，可以使用select &lt;dbid&gt;命令在连接上指定数据库id# dbid是从0到‘databases’-1的数目databases 16################################ SNAPSHOTTING ################################## 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合# Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## 满足以下条件将会同步数据:# 900秒（15分钟）内有1个更改# 300秒（5分钟）内有10个更改# 60秒内有10000个更改# Note: 可以把所有“save”行注释掉，这样就取消同步操作了save 900 1save 300 10save 60 10000# 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes# 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb# 工作目录.# 指定本地数据库存放目录，文件名由上一个dbfilename配置项指定# # Also the Append Only File will be created inside this directory.# # 注意，这里只能指定一个目录，不能指定文件名dir ./################################# REPLICATION ################################## 主从复制。使用slaveof从 Redis服务器复制一个Redis实例。注意，该配置仅限于当前slave有效# so for example it is possible to configure the slave to save the DB with a# different interval, or to listen to another port, and so on.# 设置当本机为slav服务时，设置master服务的ip地址及端口，在Redis启动时，它会自动从master进行数据同步# slaveof &lt;masterip&gt; &lt;masterport&gt;# 当master服务设置了密码保护时，slav服务连接master的密码# 下文的“requirepass”配置项可以指定密码# masterauth &lt;master-password&gt;# When a slave lost the connection with the master, or when the replication# is still in progress, the slave can act in two different ways:## 1) if slave-serve-stale-data is set to 'yes' (the default) the slave will# still reply to client requests, possibly with out of data data, or the# data set may just be empty if this is the first synchronization.## 2) if slave-serve-stale data is set to 'no' the slave will reply with# an error "SYNC with master in progress" to all the kind of commands# but to INFO and SLAVEOF.#slave-serve-stale-data yes# Slaves send PINGs to server in a predefined interval. It's possible to change# this interval with the repl_ping_slave_period option. The default value is 10# seconds.## repl-ping-slave-period 10# The following option sets a timeout for both Bulk transfer I/O timeout and# master data or ping response timeout. The default value is 60 seconds.## It is important to make sure that this value is greater than the value# specified for repl-ping-slave-period otherwise a timeout will be detected# every time there is low traffic between the master and the slave.## repl-timeout 60################################## SECURITY #################################### Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.# 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过auth &lt;password&gt;命令提供密码，默认关闭# requirepass foobared# Command renaming.## It is possilbe to change the name of dangerous commands in a shared# environment. For instance the CONFIG command may be renamed into something# of hard to guess so that it will be still available for internal-use# tools but not available for general clients.## Example:## rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52## It is also possilbe to completely kill a command renaming it into# an empty string:## rename-command CONFIG ""################################### LIMITS ##################################### 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，# 如果设置maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max Number of clients reached错误信息# maxclients 128# Don't use more memory than the specified amount of bytes.# When the memory limit is reached Redis will try to remove keys with an# EXPIRE set. It will try to start freeing keys that are going to expire# in little time and preserve keys with a longer time to live.# Redis will also try to remove objects from free lists if possible.## If all this fails, Redis will start to reply with errors to commands# that will use more memory, like SET, LPUSH, and so on, and will continue# to reply to most read-only commands like GET.## WARNING: maxmemory can be a good idea mainly if you want to use Redis as a# 'state' server or cache, not as a real DB. When Redis is used as a real# database the memory usage will grow over the weeks, it will be obvious if# it is going to use too much memory in the long run, and you'll have the time# to upgrade. With maxmemory after the limit is reached you'll start to get# errors for write operations, and this may even lead to DB inconsistency.# 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，# 当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。# Redis新的vm机制，会把Key存放内存，Value会存放在swap区# maxmemory &lt;bytes&gt;# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached? You can select among five behavior:# # volatile-lru -&gt; remove the key with an expire set using an LRU algorithm# allkeys-lru -&gt; remove any key accordingly to the LRU algorithm# volatile-random -&gt; remove a random key with an expire set# allkeys-&gt;random -&gt; remove a random key, any key# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)# noeviction -&gt; don't expire at all, just return an error on write operations# # Note: with all the kind of policies, Redis will return an error on write# operations, when there are not suitable keys for eviction.## At the date of writing this commands are: set setnx setex append# incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd# sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby# zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby# getset mset msetnx exec sort## The default is:## maxmemory-policy volatile-lru# LRU and minimal TTL algorithms are not precise algorithms but approximated# algorithms (in order to save memory), so you can select as well the sample# size to check. For instance for default Redis will check three keys and# pick the one that was used less recently, you can change the sample size# using the following configuration directive.## maxmemory-samples 3############################## APPEND ONLY MODE ################################ # Note that you can have both the async dumps and the append only file if you# like (you have to comment the "save" statements above to disable the dumps).# Still if append only mode is enabled Redis will load the data from the# log file at startup ignoring the dump.rdb file.# 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。# 因为redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no# IMPORTANT: Check the BGREWRITEAOF to check how to rewrite the append# log file in background when it gets too big.appendonly no# 指定更新日志文件名，默认为appendonly.aof# appendfilename appendonly.aof# The fsync() call tells the Operating System to actually write data on disk# instead to wait for more data in the output buffer. Some OS will really flush # data on disk, some other OS will just try to do it ASAP.# 指定更新日志条件，共有3个可选值：# no:表示等操作系统进行数据缓存同步到磁盘（快）# always:表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）# everysec:表示每秒同步一次（折衷，默认值）appendfsync everysec# appendfsync no# When the AOF fsync policy is set to always or everysec, and a background# saving process (a background save or AOF log background rewriting) is# performing a lot of I/O against the disk, in some Linux configurations# Redis may block too long on the fsync() call. Note that there is no fix for# this currently, as even performing fsync in a different thread will block# our synchronous write(2) call.## In order to mitigate this problem it's possible to use the following option# that will prevent fsync() from being called in the main process while a# BGSAVE or BGREWRITEAOF is in progress.## This means that while another child is saving the durability of Redis is# the same as "appendfsync none", that in pratical terms means that it is# possible to lost up to 30 seconds of log in the worst scenario (with the# default Linux settings).# # If you have latency problems turn this to "yes". Otherwise leave it as# "no" that is the safest pick from the point of view of durability.no-appendfsync-on-rewrite no# Automatic rewrite of the append only file.# Redis is able to automatically rewrite the log file implicitly calling# BGREWRITEAOF when the AOF log size will growth by the specified percentage.# # This is how it works: Redis remembers the size of the AOF file after the# latest rewrite (or if no rewrite happened since the restart, the size of# the AOF at startup is used).## This base size is compared to the current size. If the current size is# bigger than the specified percentage, the rewrite is triggered. Also# you need to specify a minimal size for the AOF file to be rewritten, this# is useful to avoid rewriting the AOF file even if the percentage increase# is reached but it is still pretty small.## Specify a precentage of zero in order to disable the automatic AOF# rewrite feature.auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb################################## SLOW LOG #################################### The Redis Slow Log is a system to log queries that exceeded a specified# execution time. The execution time does not include the I/O operations# like talking with the client, sending the reply and so forth,# but just the time needed to actually execute the command (this is the only# stage of command execution where the thread is blocked and can not serve# other requests in the meantime).# # You can configure the slow log with two parameters: one tells Redis# what is the execution time, in microseconds, to exceed in order for the# command to get logged, and the other parameter is the length of the# slow log. When a new command is logged the oldest one is removed from the# queue of logged commands.# The following time is expressed in microseconds, so 1000000 is equivalent# to one second. Note that a negative number disables the slow log, while# a value of zero forces the logging of every command.slowlog-log-slower-than 10000# There is no limit to this length. Just be aware that it will consume memory.# You can reclaim memory used by the slow log with SLOWLOG RESET.slowlog-max-len 1024################################ VIRTUAL MEMORY ################################## WARNING! Virtual Memory is deprecated in Redis 2.4### The use of Virtual Memory is strongly discouraged.### WARNING! Virtual Memory is deprecated in Redis 2.4### The use of Virtual Memory is strongly discouraged.# Virtual Memory allows Redis to work with datasets bigger than the actual# amount of RAM needed to hold the whole dataset in memory.# In order to do so very used keys are taken in memory while the other keys# are swapped into a swap file, similarly to what operating systems do# with memory pages.# 指定是否启用虚拟内存机制，默认值为no，# VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中# 把vm-enabled设置为yes，根据需要设置好接下来的三个VM参数，就可以启动VM了vm-enabled no# vm-enabled yes# This is the path of the Redis swap file. As you can guess, swap files# can't be shared by different Redis instances, so make sure to use a swap# file for every redis process you are running. Redis will complain if the# swap file is already in use.## Redis交换文件最好的存储是SSD（固态硬盘）# 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享# *** WARNING *** if you are using a shared hosting the default of putting# the swap file under /tmp is not secure. Create a dir with access granted# only to Redis user and configure Redis to create the swap file there.vm-swap-file /tmp/redis.swap# With vm-max-memory 0 the system will swap everything it can. Not a good# default, just specify the max amount of RAM you can in bytes, but it's# better to leave some margin. For instance specify an amount of RAM# that's more or less between 60 and 80% of your free RAM.# 将所有大于vm-max-memory的数据存入虚拟内存，无论vm-max-memory设置多少，所有索引数据都是内存存储的（Redis的索引数据就是keys）# 也就是说当vm-max-memory设置为0的时候，其实是所有value都存在于磁盘。默认值为0vm-max-memory 0# Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的数据大小来设定的。# 建议如果存储很多小对象，page大小最后设置为32或64bytes；如果存储很大的对象，则可以使用更大的page，如果不确定，就使用默认值vm-page-size 32# 设置swap文件中的page数量由于页表（一种表示页面空闲或使用的bitmap）是存放在内存中的，在磁盘上每8个pages将消耗1byte的内存# swap空间总容量为 vm-page-size * vm-pages## With the default of 32-bytes memory pages and 134217728 pages Redis will# use a 4 GB swap file, that will use 16 MB of RAM for the page table.## It's better to use the smallest acceptable value for your application,# but the default is large in order to work in most conditions.vm-pages 134217728# Max number of VM I/O threads running at the same time.# This threads are used to read/write data from/to swap file, since they# also encode and decode objects from disk to memory or the reverse, a bigger# number of threads can help with big objects even if they can't help with# I/O itself as the physical device may not be able to couple with many# reads/writes operations at the same time.# 设置访问swap文件的I/O线程数，最后不要超过机器的核数，如果设置为0，那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟，默认值为4vm-max-threads 4############################### ADVANCED CONFIG ################################ Hashes are encoded in a special way (much more memory efficient) when they# have at max a given numer of elements, and the biggest element does not# exceed a given threshold. You can configure this limits with the following# configuration directives.# 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法hash-max-zipmap-entries 512hash-max-zipmap-value 64# Similarly to hashes, small lists are also encoded in a special way in order# to save a lot of space. The special representation is only used when# you are under the following limits:list-max-ziplist-entries 512list-max-ziplist-value 64# Sets have a special encoding in just one case: when a set is composed# of just strings that happens to be integers in radix 10 in the range# of 64 bit signed integers.# The following configuration setting sets the limit in the size of the# set in order to use this special memory saving encoding.set-max-intset-entries 512# Similarly to hashes and lists, sorted sets are also specially encoded in# order to save a lot of space. This encoding is only used when the length and# elements of a sorted set are below the following limits:zset-max-ziplist-entries 128zset-max-ziplist-value 64# Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in# order to help rehashing the main Redis hash table (the one mapping top-level# keys to values). The hash table implementation redis uses (see dict.c)# performs a lazy rehashing: the more operation you run into an hash table# that is rhashing, the more rehashing "steps" are performed, so if the# server is idle the rehashing is never complete and some more memory is used# by the hash table.# # The default is to use this millisecond 10 times every second in order to# active rehashing the main dictionaries, freeing memory when possible.## If unsure:# use "activerehashing no" if you have hard latency requirements and it is# not a good thing in your environment that Redis can reply form time to time# to queries with 2 milliseconds delay.# 指定是否激活重置哈希，默认为开启activerehashing yes################################## INCLUDES #################################### 指定包含其他的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各实例又拥有自己的特定配置文件# include /path/to/local.conf# include /path/to/other.conf 4. 启动容器这里也可以通过挂载数据卷的方式，使用外部文件。 比如数据存放在/usr/loacl/docker/redis/redis/data 1234567891011121314151617181920docker run -d \--privileged=true \-p 6379:6379 \-v /usr/loacl/docker/redis/redis.conf:/etc/redis/redis.conf \-v /usr/loacl/docker/redis/redis/data:/data \--name redis redis:latest \redis-server /etc/redis/redis.conf \--appendonly yes \//---说明---d 后台运行--privileged=true：容器内的root拥有真正root权限，否则容器内root只是外部普通用户权限-v /usr/loacl/docker/redis/redis.conf:/etc/redis/redis.conf ：映射配置文件-v /usr/loacl/docker/redis/redis/data:/data ：映射数据目录redis-server /etc/redis/redis.conf：指定配置文件启动redis-server进程--appendonly yes：开启数据持久化 5. 参考https://www.cnblogs.com/osbreak/p/9449760.html https://www.cnblogs.com/lysongbo/p/9506782.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker入门教程(一)---什么是Docker]]></title>
    <url>%2Fposts%2F9e614b5a.html</url>
    <content type="text"><![CDATA[本文主要介绍了什么是容器，接着对 Docker 做了详细介绍，最后对虚拟机与容器技术做了简单的对比 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 什么是容器一句话概括容器：容器就是将软件打包成标准化单元，以用于开发、交付和部署。 容器镜像是轻量的、可执行的独立软件包 ，包含软件运行所需的所有内容：代码、运行时环境、系统工具、系统库和设置。 容器化软件适用于基于Linux和Windows的应用，在任何环境中都能够始终如一地运行。 容器赋予了软件独立性 ，使其免受外在环境差异（例如，开发和预演环境的差异）的影响，从而有助于减少团队间在相同基础设施上运行不同软件时的冲突。 2. 什么是 Docker?说实话关于Docker是什么并太好说，下面我通过四点向你说明Docker到底是个什么东西。 Docker 是世界领先的软件容器平台。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核 的cgroup，namespace，以及AUFS类的UnionFS等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。 由于隔离的进程独立于宿主和其它的隔离的进 程，因此也称其为容器。Docke最初实现是基于 LXC. Docker 能够自动执行重复性任务，例如搭建和配置开发环境，从而解放了开发人员以便他们专注在真正重要的事情上：构建杰出的软件。 用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 2.1 Docker思想 集装箱 标准化： ①运输方式 ② 存储方式 ③ API接口 隔离 2.2 Docker 容器特点 轻量在一台机器上运行的多个 Docker 容器可以共享这台机器的操作系统内核；它们能够迅速启动，只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的，并共享一些公共文件。这样就能尽量降低磁盘用量，并能更快地下载镜像。 标准Docker 容器基于开放式标准，能够在所有主流 Linux 版本、Microsoft Windows 以及包括 VM、裸机服务器和云在内的任何基础设施上运行。 安全Docker 赋予应用的隔离性不仅限于彼此隔离，还独立于底层的基础设施。Docker 默认提供最强的隔离，因此应用出现问题，也只是单个容器的问题，而不会波及到整台机器。 3. 为什么要用 Docker ? 一致的运行环境 : Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 “这段代码在我机器上没问题啊” 这类问题。 更快速的启动时间 : 可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 隔离性 ： 避免公用的服务器，资源会容易受到其他用户的影响。 弹性伸缩，快速扩展： 善于处理集中爆发的服务器使用压力。 迁移方便 ： 可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 持续交付和部署 ： 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。 4. 虚拟机与容器 容器是一个应用层抽象，用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行 。与虚拟机相比， 容器占用的空间较少（容器镜像大小通常只有几十兆），瞬间就能完成启动 。 虚拟机 (VM) 是一个物理硬件层抽象，用于将一台服务器变成多台服务器。 管理程序允许多个 VM 在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源，因此 占用大量空间 。而且 VM 启动也十分缓慢 。 通过Docker官网，我们知道了这么多Docker的优势，但是大家也没有必要完全否定虚拟机技术，因为两者有不同的使用场景。虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而 Docker通常用于隔离不同的应用 ，例如前端，后端以及数据库。 5. Docker概念Docker 包括三个基本概念 镜像（Image） 容器（Container） 仓库（Repository） 理解了这三个概念，就理解了 Docker 的整个生命周期 5.1 镜像(Image):一个特殊的文件系统 操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而Docker 镜像（Image），就相当于是一个 root 文件系统。 Docker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。 Docker 设计时，就充分利用 Union FS的技术，将其设计为 分层存储的架构 。 镜像实际是由多层文件系统联合组成。 镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。 比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。 分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。 5.2 容器(Container):镜像运行时的实体 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等 。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。前面讲过镜像使用的是分层存储，容器也是如此。 容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据 ，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主(或网络存储)发生读写，其性能和稳定性更高。数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此， 使用数据卷后，容器可以随意删除、重新 run ，数据却不会丢失。 5.3 仓库(Repository):集中存放镜像文件的地方 镜像构建完成后，可以很容易的在当前宿主上运行，但是， 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。 一个 Docker Registry中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。所以说：镜像仓库是Docker用来集中存放镜像文件的地方类似于我们之前常用的代码仓库。 通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。我们可以通过&lt;仓库名&gt;:&lt;标签&gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签.。 6. Securely Build Share and Run如果你搜索Docker官网，会发现如下的字样：“Securely build, share and run any application, anywhere”。那么Build, Ship, and Run到底是在干什么呢？ Securely Build（安全构建镜像） ： 镜像就像是集装箱包括文件以及运行环境等等资源。 Share（分享镜像） ：可以把镜像放到镜像仓库用于分享。 Run （运行镜像） ：运行的镜像就是一个容器，容器就是运行程序的地方。 Docker 运行过程也就是去仓库把镜像拉到本地，然后用一条命令把镜像运行起来变成容器。所以，我们也常常将Docker称为码头工人或码头装卸工，这和Docker的中文翻译搬运工人如出一辙。 参考https://github.com/Snailclimb/JavaGuide/]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String字符串详解]]></title>
    <url>%2Fposts%2F91311934.html</url>
    <content type="text"><![CDATA[本文主要分析了 Java中的 String 字符串相关使用与优化方案，包括 String 类型相加的本质、String 字符串相关编译器优化、 StringBuilder 与 StringBuffer 选择、字符串拼接方法、基本类型转 String 类型等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. String对象String 对象是 Java 中重要的数据类型，在大部分情况下我们都会用到 String 对象。其实在 Java 语言中，其设计者也对 String 做了大量的优化工作，这些也是 String 对象的特点，它们就是:不变性，常量池优化和String类的final定义。 1.1 不变性String对象的状态在其被创建之后就不在发生变化。为什么说这点也是 Java 设计者所做的优化，在 Java 中，有一种模式叫不变模式：在一个对象被多线程共享，而且被频繁的访问时，可以省略同步和锁的时间，从而提高性能。而 String 的不变性，可泛化为不变模式。 1.2 常量池优化常量池优化指的是什么呢？那就是当两个 String 对象拥有同一个值的时候，他们都只是引用了常量池中的同一个拷贝。所以当程序中某个字符串频繁出现时，这个优化技术就可以节省大幅度的内存空间了。例如： 123456String s1 = "123";String s2 = "123";String s3 = new String("123");System.out.println(s1==s2); //trueSystem.out.println(s1==s3); //falseSystem.out.println(s1==s3.intern()); //true123456 以上代码中，s1 和 s2 引用的是相同的地址，故而第四行打印出的结果是 true ;而 s3 虽然只与 s1,s2 相等，但是 s3 是通过 new String(“123”) 创建的，重新开辟了内存空间，因引用的地址不同，所以第5行打印出 false ; String 的 intern() 方法返回的是 String 对象在常量池中的引用，所以最后一行打印出 true。 1.3 final的定义String 类以 final 进行了修饰，在系统中就不可能有 String 的子类，这一点也是出于对系统安全性的考虑。 2. 字符串操作中的常见优化方法2.1 split()方法优化 通常情况下，split() 方法带给我们很大的方便，但是其性能不是很好。建议结合使用 indexOf( )和 subString()方法进行自定义拆分，这样性能会有显著的提高。 2.2 String常量的累加操作优化方法示例代码: 1234567891011121314151617181920212223String s = "";long sBeginTime = System.currentTimeMillis();for (int i = 0; i &lt; 100000; i++) &#123; s+="s";&#125;long sEndTime = System.currentTimeMillis();System.out.println("s拼接100000遍s耗时: " + (sEndTime - sBeginTime) + "ms");StringBuffer s1 = new StringBuffer();long s1BeginTime = System.currentTimeMillis();for (int i = 0; i &lt; 100000; i++) &#123; s1.append("s");&#125;long s1EndTime = System.currentTimeMillis();System.out.println("s1拼接100000遍s耗时: " + (s1EndTime - s1BeginTime) + "ms");StringBuilder s2 = new StringBuilder();long s2BeginTime = System.currentTimeMillis();for (int i = 0; i &lt; 100000; i++) &#123; s2.append("s");&#125;long s2EndTime = System.currentTimeMillis();System.out.println("s2拼接100000遍s耗时: " + (s2EndTime - s2BeginTime) + "ms"); 结果如下： 123s拼接100000遍s耗时: 3426mss1拼接100000遍s耗时: 3mss2拼接100000遍s耗时: 1ms 上例所示，使用+号拼接字符串，其效率明显较低，而使用 StringBuffer 和 StringBuilder 的 append() 方法进行拼接，效率是使用+号拼接方式的百倍甚至千倍，而 StringBuffer 的效率比 StringBuilder 低些，这是由于StringBuffer 实现了线程安全，效率较低也是不可避免的。 所以在字符串的累加操作中，建议结合线程问题选择 StringBuffer 或 StringBuilder，应避免使用+号拼接字符串。 2.3 基本数据类型转化为 String 类型的优化方案示例代码: 123456789101112131415161718192021222324Integer num = 0;int loop = 10000000; // 将结果放大10000000倍，以便于观察结果long beginTime = System.currentTimeMillis();for (int i = 0; i &lt; loop; i++) &#123; String s = num+"";&#125;long endTime = System.currentTimeMillis();System.out.println("+\"\"的方式耗时: " + (endTime - beginTime) + "ms");beginTime = System.currentTimeMillis();for (int i = 0; i &lt; loop; i++) &#123; String s = String.valueOf(num);&#125;endTime = System.currentTimeMillis();System.out.println("String.valueOf()的方式耗时: " + (endTime - beginTime) + "ms");beginTime = System.currentTimeMillis();for (int i = 0; i &lt; loop; i++) &#123; String s = num.toString();&#125;endTime = System.currentTimeMillis();System.out.println("toString()的方式耗时: " + (endTime - beginTime) + "ms");1234567891011121314151617181920212223 以上示例中，String.valueOf() 直接调用了底层的 Integer.toString() 方法，不过其中会先判断是否为空；+”“由StringBuilder 实现，先 new StringBuilder() 然后调用了 append() 方法，最后调用了 toString() 方法返回 String 对象；num.toString() 直接调用了 Integer.toString() 方法。 以下是结果： 123+""的方式耗时: 120msString.valueOf()的方式耗时: 31mstoString()的方式耗时: 30ms 所以效率是： num.toString() 方法最快，其次是 String.valueOf(num )，num+”“的方式最满。 3. 编译器优化1234567891011121314/** * String类型优化测试 */private static void StringTest() &#123; String a = "hello illusory"; String b = "hello " + "illusory"; //true System.out.println(a == b); String c = "hello "; String d = "illusory"; String e = c + d; //false System.out.println(a == e);&#125; Java 中的变量和基本类型的值存放于栈，而 new 出来的对象本身存放于堆内存，指向对象的引用还是放在栈内存。 1String b = "hello " + "illusory"; 两个都是字符串，是固定值 所以编译器会自动优化为1String b = "hello illusory"; a、b 都指向常量池中的hello illusory所以 a==b 为 true 由于 String 的不可变性，对其进行操作的效率会大大降低，但对 “+”操作符,编译器也对其进行了优化123String c = "hello ";String d = "illusory";String e = c + d; 其中的1String e = c + d 当+号两边存在变量时(两边或任意一边)，在编译期是无法确定其值的，所以要等到运行期再进行处理 Java中对String 的相加其本质是 new 了 StringBuilder 对象进行 append 操作，拼接后调用 toString() 返回 String 对象。 1String e = new StringBuilder().append("hello ").append("illusory").toString(); StringBuilder的toString方法如下： 12345@Overridepublic String toString() &#123; // Create a copy, don't share the array return new String(value, 0, count);&#125; 所以e是指向new出来的一个 String 对象,而a指向常量池中的对象，a==e 为 false 反编译后如下：12345678910111213141516171819202122232425262728D:\lillusory\Java\work_idea\java-learning\target\classes\jvm\string&gt;javap -classpath . -v StringTest.classClassfile /D:/lillusory/Java/work_idea/java-learning/target/classes/jvm/string/StringTest.class Last modified 2019-5-5; size 946 bytes MD5 checksum 2d529fca114cf155ae7c647bfc733150 Compiled from "StringTest.java"public class jvm.string.StringTest minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #12.#35 // java/lang/Object."&lt;init&gt;":()V #2 = String #36 // hello illusory #3 = String #37 // hello #4 = String #38 // illusory #5 = Class #39 // java/lang/StringBuilder #6 = Methodref #5.#35 // java/lang/StringBuilder."&lt;init&gt;":()V #7 = Methodref #5.#40 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #8 = Methodref #5.#41 // java/lang/StringBuilder.toString:()Ljava/lang/String; #9 = Fieldref #42.#43 // java/lang/System.out:Ljava/io/PrintStream; #10 = Methodref #44.#45 // java/io/PrintStream.println:(Z)V #11 = Class #46 // jvm/string/StringTest #12 = Class #47 // java/lang/Object 可以看到确实是用到了StringBuilder 加上 final 有会如何呢?123456789101112/** * String类型优化测试 */ private static void StringTest() &#123; String a = "hello illusory"; final String c2 = "hello "; final String d2 = "illusory"; String e2 = c2 + d2; // true System.out.println(a == e2); &#125; 由于c2、d2都加了final修饰 所以被当作一个常量对待此时+号两边都是常量，在编译期就可以确定其值了类似于1String b = "hello " + "illusory"; 此时都指向常量池中的hello illusory所以a == e2为true 如果+号两边有一个不是常量那么结果都是false123456789101112131415/** * String类型优化测试 */ private static void StringTest() &#123; String a = "hello illusory"; final String c2 = "hello "; String f = c2 + getName(); // false System.out.println(a == f); &#125; private static String getName() &#123; return "illusory"; &#125; 其中c2是final 被当成常量 其值是固定的但是getName() 要运行时才能确定值 所以最后 f 也是 new 的一个对象 a == f结果为false 12345678/** * String类型优化测试 */ private static void StringTest() &#123; String a = "hello illusory"; String g = a.intern(); System.out.println(a == g); &#125; 当调用 String.intern() 方法时，如果常量池中已经存在该字符串，则返回池中的字符串引用；否则将此字符串添加到常量池中，并返回字符串的引用。这里g和a是都是指向常量池中的hello illusory，所以a == g为true 4. 总结最后总结一下 1.直接字符串相加，编译器会优化。 1String a = "hello " + "illusory";---&gt; String a = "hello illusory"; 2.String 用加号拼接本质是new了StringBuilder对象进行append操作，拼接后调用toString()返回String对象 12345 String c = "hello "; String d = "illusory"; String e = c + d;//实现如下String e = new StringBuilder().append("hello ").append("illusory").toString(); 3.+号两边都在编译期能确定的也会优化 123456789101112/** * String类型优化测试 */ private static void StringTest() &#123; String a = "hello illusory"; final String c2 = "hello "; final String d2 = "illusory"; String e2 = c2 + d2; // true System.out.println(a == e2); &#125; 4.在字符串的累加操作中，建议结合线程问题选择 StringBuffe r或 StringBuilder，应避免使用+号拼接字符串 5.基本数据类型转化为 String 类型，效率是: num.toString() 方法最快，其次是 String.valueOf(num)，最后是num+”“的方式 5. 参考https://blog.csdn.net/SEU_Calvin/article/details/52291082 https://www.cnblogs.com/vincentl/p/9600093.html https://www.cnblogs.com/will959/p/7537891.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring系列(三)---BeanFactory 与 ApplicationContext]]></title>
    <url>%2Fposts%2F53a05c34.html</url>
    <content type="text"><![CDATA[本文主要介绍了 Spring 框架中 BeanFactory 与 ApplicationContext 的区别。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. BeanFactory1.1 概述BeanFactory 是 Spring 的“心脏”。它就是 Spring IoC 容器的真面目。Spring 使用 BeanFactory 来实例化、配置和管理 Bean。 BeanFactory：是IOC容器的核心接口， 它定义了IOC的基本功能，我们看到它主要定义了getBean方法。getBean方法是IOC容器获取bean对象和引发依赖注入的起点。方法的功能是返回特定的名称的Bean。 BeanFactory 是初始化 Bean 和调用它们生命周期方法的“吃苦耐劳者”。注意，BeanFactory 只能管理单例（Singleton）Bean 的生命周期。它不能管理原型(prototype,非单例)Bean 的生命周期。这是因为原型 Bean 实例被创建之后便被传给了客户端,容器失去了对它们的引用。 1.2 源码分析BeanFactory 源码如下： 12345678910111213141516171819202122232425262728293031323334package org.springframework.beans.factory;public interface BeanFactory &#123; /** * 用来引用一个实例，或把它和工厂产生的Bean区分开，就是说，如果一个FactoryBean的名字为a，那么，&amp;a会得到那个Factory */ String FACTORY_BEAN_PREFIX = "&amp;"; /* * 四个不同形式的getBean方法，获取实例 */ Object getBean(String name) throws BeansException; &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException; Object getBean(String name, Object... args) throws BeansException; boolean containsBean(String name); // 是否存在 boolean isSingleton(String name) throws NoSuchBeanDefinitionException;// 是否为单实例 boolean isPrototype(String name) throws NoSuchBeanDefinitionException;// 是否为原型（多实例） boolean isTypeMatch(String name, Class&lt;?&gt; targetType) throws NoSuchBeanDefinitionException;// 名称、类型是否匹配 Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException; // 获取类型 String[] getAliases(String name);// 根据实例的名字获取实例的别名&#125; 1.3 方法列表 4个获取实例的方法。getBean的重载方法。 4个判断的方法。判断是否存在，是否为单例、原型，名称类型是否匹配。 1个获取类型的方法、1个获取别名的方法。根据名称获取类型、根据名称获取别名。 这10个方法，很明显，这是一个典型的工厂模式的工厂接口。 1.4 实例演示在 Spring 3.2 之前的版本中，BeanFactory最常见的实现类为XmlBeanFactory(已废弃)，建议使用 XmlBeanDefinitionReader 与 DefaultListableBeanFactory。可以从classpath或文件系统等获取资源。 拿前面的 Book 举例 12345public class Book &#123; private String type; private String name; //省略Getter/Setter和构造方法&#125; xml 配置文件 1234&lt;bean id="book" class="spring.Book"&gt; &lt;property name="name" value="think in java"&gt;&lt;/property&gt; &lt;property name="type" value="CS"&gt;&lt;/property&gt; &lt;/bean&gt; 使用 DefaultListableBeanFactory 与 XmlBeanDefinitionReader 来启动 IoC 容器 12345678910111213public static void main(String[] args) &#123; esourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); Resource resource = resolver.getResource("classpath:beans.xml"); System.out.println("getURL:" + resource.getURL()); DefaultListableBeanFactory factory = new DefaultListableBeanFactory(); XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory); reader.loadBeanDefinitions(resource); //ApplicationContext factory=new ClassPathXmlApplicationContext("applicationContext.xml"); Book book = factory.getBean("book",Book.class); System.out.println("boook对象已经初始化完成"); System.out.println(book.getName());&#125; 1.5 小结 XmlBeanFactory通过Resource装载Spring配置信息冰启动IoC容器，然后就可以通过factory.getBean从IoC容器中获取Bean了。 通过BeanFactory启动IoC容器时，并不会初始化配置文件中定义的Bean，初始化动作发生在第一个调用时。 对于单实例（singleton）的Bean来说，BeanFactory会缓存Bean实例，所以第二次使用getBean时直接从IoC容器缓存中获取Bean。 2. ApplicationContextApplicationContext由BeanFactory派生而来，提供了更多面向实际应用的功能。在BeanFactory中，很多功能需要以编程的方式实现，而在ApplicationContext中则可以通过配置实现。 BeanFactorty接口提供了配置框架及基本功能，但是无法支持spring的aop功能和web应用。而ApplicationContext接口作为BeanFactory的派生，因而提供BeanFactory所有的功能。而且ApplicationContext还在功能上做了扩展，相较于BeanFactorty，ApplicationContext还提供了以下的功能： （1）MessageSource, 提供国际化的消息访问（2）资源访问，如URL和文件（3）事件传播特性，即支持aop特性（4）载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层 ApplicationContext：是IOC容器另一个重要接口， 它继承了BeanFactory的基本功能， 同时也继承了容器的高级功能，如：MessageSource（国际化资源接口）、ResourceLoader（资源加载接口）、ApplicationEventPublisher（应用事件发布接口）等。 3. 二者区别3.1 bean 加载时机BeanFactroy 采用的是延迟加载形式来注入 Bean 的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的Spring的配置问题。ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。 3.2 Bean 注册BeanFactory 和 ApplicationContext 都支持 BeanPostProcessor、BeanFactoryPostProcessor 的使用。 但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册。 Applicationcontext比 beanFactory 加入了一些更好使用的功能。而且 beanFactory 的许多功能需要通过编程实现而 Applicationcontext 可以通过配置实现。 比如后处理 bean，ApplicationContext 直接配置在配置文件即可而 BeanFactory 这要在代码中显示的写出来才可以被容器识别。 3.3 使用场景BeanFactory 主要是面对与 Spring 框架的基础设施，面对 Spring 自己。 ApplicationContext 主要面对与 Spring 使用的开发者。 基本都会使用 ApplicationContext 并非 BeanFactory 。 4. 总结 1.BeanFactory 负责读取 bean 配置文档，管理 bean 的加载，实例化，维护 bean 之间的依赖关系，负责bean 的声明周期。 2.ApplicationContext 除了提供上述 BeanFactory 所能提供的功能之外，还提供了更完整的框架功能： a. 国际化支持(MessageSource) b. 资源访问(ResourceLoader) c.载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层 d.消息发送、响应机制（ApplicationEventPublisher） e.AOP（拦截器） 5. 参考https://www.cnblogs.com/xiaoxi/p/5846416.html https://www.jianshu.com/p/2808f7c4a24f]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring系列(二)---Spring 常用注解分析]]></title>
    <url>%2Fposts%2F6704df3d.html</url>
    <content type="text"><![CDATA[本文主要对 Spring 框架中经常用到的注解与配置进行了说明。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Bean相关的注解与SpringBean相关的注解有以下四大类： @Controller ：标注一个控制器组件类 Controller层 @Service：标注一个业务逻辑组件类 Service层 @Repository ：标注一个 DAO 组件类 DAO层 @Component ：标注一个普通的 Spring Bean 类 前面三个都不是但又想交给Spring管理就用这个 2. @Autowired与@Resource区别2.1 相同点@Resource的作用相当于@Autowired，均可标注在字段或属性的setter方法上。 2.2 不同点1. 提供方@Autowired 是 Spring 提供的注解； @Resource是J2EE提供的注解，javax.annotation 包下的注解，来自于JSR-250，需要JDK1.6及以上。 2. 注入方式@Autowired只按照Type 注入； @Resource 默认按Name自动注入，也提供按照Type 注入； 3. 属性@Autowired注解可用于为类的属性、构造器、方法进行注值。 默认情况下，其依赖的对象必须存在(bean可用)，如果需要改变这种默认方式，可以设置其 required 属性为false。@Autowired注解默认按照类型装配，如果容器中包含多个同一类型的Bean，那么启动容器时会报找不到指定类型bean的异常，解决办法是结合 @Qualifier 注解进行限定，指定注入的bean名称。 @Resource有两个中重要的属性：name和type。 name 属性指定 byName，如果没有指定 name 属性: 当注解标注在字段上，即默认取字段的名称作为 bean 名称寻找依赖对象，当注解标注在属性的setter方法上，即默认取属性名作为bean名称寻找依赖对象。@Resource如果没有指定name属性，并且按照默认的名称仍然找不到依赖对象时， @Resource注解会回退到按类型装配。但一旦指定了name属性，就只能按名称装配了。 4. 其他@Autowired注解进行装配容易抛出异常，特别是装配的 bean 类型有多个的时候,解决的办法是增加 @Qualifier 注解进行限定。 @Resource注解的使用性更为灵活，可指定名称，也可以指定类型； 3. context:annotation-config与context:component-scan3.1 context:annotation-config我们一般在含有 Spring 的项目中，可能会看到配置项中包含这个配置节点 1&lt;context:annotation-config&gt; 这条配置会向 Spring 容器中注册以下4个 BeanPostProcessor AutowiredAnnotationBeanPostProcessor CommonAnnotationBeanPostProcessor PersistenceAnnotationBeanPostProcessor RequiredAnnotationBeanPostProcessor 注册这4个 BeanPostProcessor 的作用，就是为了你的系统能够识别相应的注解。 如果想使用 @Resource 、@PostConstruct、@PreDestroy等注解就必须声明CommonAnnotationBeanPostProcessor。如果想使用@PersistenceContext注解，就必须声明PersistenceAnnotationBeanPostProcessor的Bean。如果想使用 @Autowired注解，那么就必须声明AutowiredAnnotationBeanPostProcessor的 Bean。如果想使用 @Required的注解，就必须声明RequiredAnnotationBeanPostProcessor的Bean。 所以如果不加一句context:annotation-config那么上面的这些注解就无法识别。 3.2 context:component-scancontext:component-scan包括了context:annotation-config的功能，即注册 BeanPostProcessor 使系统能够识别上面的注解。 同时还会自动扫描所配置的包下的 bean。即 扫描包下面有@Controller、@Service、@Repository、@Component这四个注解的类，自动放入 Spring 容器。 所以一般写context:component-scan就行了。 3. 实例演示就拿前面的 student 和 book 举例实体类这样写,使用注解进行属性注入 1234567891011121314public class Student &#123; @Value(value = "illusory") private String name; @Value(value = "23") private int age; @Autowired private Book book;&#125;public class Book &#123; @Value(value = "defaultType") private String type; @Value(value = "defaultName") private String name;&#125; 配置文件就不用写各种 property 属性注入了。 1&lt;property name="name" value="illusory"&gt;&lt;/property&gt; 使用@Autowired后也不用配置引用对象了。 1&lt;property name="book" ref="book"&gt;&lt;/property&gt; 但是还是需要在 xml配置 bean 的基本信息 123&lt;bean id="student" class="spring.Student"&gt;&lt;/bean&gt;&lt;bean id="book" class="spring.Book"&gt;&lt;/bean&gt; &lt;context:annotation-config /&gt; 如果在实体类加上@Component注解 123456789@Component(value = "student")public class Student &#123; @Value(value = "illusory") private String name; @Value(value = "23") private int age; @Autowired private Book book;&#125; 就不用在xml中配置bean了,只需要在xml中配置 1&lt;context:component-scan base-package="spring"/&gt; 系统可以识别到前面的注解，同时还会自动扫描包下的 bean。 这样xml中只要要一行就搞定了。 4. 自定义初始化与销毁方法init-method destroy-method属性对应的注解 @PostConstruct注解，在对象创建后调用 @PreDestroy注解，在对象销毁前调用 123456789@PostConstructpublic void init() &#123; System.out.println("init");&#125;@PreDestroypublic void destory() &#123; System.out.println("destory");&#125; 5. @Component和@Configuration 作为配置类的区别5.1 概述@Component和@Configuration都可以作为配置类,但还是有一定差别的。 123456@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Component //看这里！！！public @interface Configuration &#123; String value() default ""; Spring 中新的 Java 配置支持的核心就是 @Configuration 注解的类。 这些类主要包括 @Bean 注解的方法来为 Spring 的 IoC 容器管理的对象定义实例，配置和初始化逻辑。 使用 @Configuration 来注解类表示类可以被 Spring 的 IoC 容器所使用，作为 bean 定义的资源。 1234567@Configurationpublic class AppConfig &#123; @Bean public MyService myService() &#123; return new MyServiceImpl(); &#125;&#125; 这和 Spring 的 XML 文件中的非常类似 123&lt;beans&gt; &lt;bean id="myService" class="com.acme.services.MyServiceImpl"/&gt;&lt;/beans&gt; 5.2 实例演示123456789101112131415161718192021222324252627@Configurationpublic static class Config &#123; @Bean public SimpleBean simpleBean() &#123; return new SimpleBean(); &#125; @Bean public SimpleBeanConsumer simpleBeanConsumer() &#123; return new SimpleBeanConsumer(simpleBean()); &#125;&#125;@Componentpublic static class Config &#123; @Bean public SimpleBean simpleBean() &#123; return new SimpleBean(); &#125; @Bean public SimpleBeanConsumer simpleBeanConsumer() &#123; return new SimpleBeanConsumer(simpleBean()); &#125;&#125; 第一个代码正常工作，正如预期的那样，SimpleBeanConsumer 将会得到一个单例 SimpleBean 的链接。第二个配置是完全错误的，虽然 Spring 会创建一个 SimpleBean 的单例bean，但是 SimpleBeanConsumer 将获得另一个SimpleBean实例（也就是相当于直接调用new SimpleBean() ，这个bean是不归Spring管理的）。 5.3 原因使用 @Configuration 所有标记为@Bean的方法将被包装成一个 CGLIB包装器，它的工作方式就好像是这个方法的第一个调用，那么原始方法的主体将被执行，最终的对象将在 Spring上下文中注册。所有进一步的调用只返回从上下文检索的 bean。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) &#123; Map&lt;String, AbstractBeanDefinition&gt; configBeanDefs = new LinkedHashMap&lt;String, AbstractBeanDefinition&gt;(); for (String beanName : beanFactory.getBeanDefinitionNames()) &#123; BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName); //判断是否被@Configuration标注 if (ConfigurationClassUtils.isFullConfigurationClass(beanDef)) &#123; if (!(beanDef instanceof AbstractBeanDefinition)) &#123; throw new BeanDefinitionStoreException("Cannot enhance @Configuration bean definition '" + beanName + "' since it is not stored in an AbstractBeanDefinition subclass"); &#125; else if (logger.isWarnEnabled() &amp;&amp; beanFactory.containsSingleton(beanName)) &#123; logger.warn("Cannot enhance @Configuration bean definition '" + beanName + "' since its singleton instance has been created too early. The typical cause " + "is a non-static @Bean method with a BeanDefinitionRegistryPostProcessor " + "return type: Consider declaring such methods as 'static'."); &#125; configBeanDefs.put(beanName, (AbstractBeanDefinition) beanDef); &#125; &#125; if (configBeanDefs.isEmpty()) &#123; // nothing to enhance -&gt; return immediately return; &#125; ConfigurationClassEnhancer enhancer = new ConfigurationClassEnhancer(); for (Map.Entry&lt;String, AbstractBeanDefinition&gt; entry : configBeanDefs.entrySet()) &#123; AbstractBeanDefinition beanDef = entry.getValue(); // If a @Configuration class gets proxied, always proxy the target class beanDef.setAttribute(AutoProxyUtils.PRESERVE_TARGET_CLASS_ATTRIBUTE, Boolean.TRUE); try &#123; // Set enhanced subclass of the user-specified bean class Class&lt;?&gt; configClass = beanDef.resolveBeanClass(this.beanClassLoader); //生成代理的class Class&lt;?&gt; enhancedClass = enhancer.enhance(configClass, this.beanClassLoader); if (configClass != enhancedClass) &#123; if (logger.isDebugEnabled()) &#123; logger.debug(String.format("Replacing bean definition '%s' existing class '%s' with " + "enhanced class '%s'", entry.getKey(), configClass.getName(), enhancedClass.getName())); &#125; //替换class，将原来的替换为CGLIB代理的class beanDef.setBeanClass(enhancedClass); &#125; &#125; catch (Throwable ex) &#123; throw new IllegalStateException("Cannot load configuration class: " + beanDef.getBeanClassName(), ex); &#125; &#125; &#125; isFullConfigurationClass代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041//是否为配置类public static boolean isConfigurationCandidate(AnnotationMetadata metadata) &#123;return (isFullConfigurationCandidate(metadata) || isLiteConfigurationCandidate(metadata));&#125;//是否为完整配置类public static boolean isFullConfigurationCandidate(AnnotationMetadata metadata) &#123;return metadata.isAnnotated(Configuration.class.getName());&#125;//是否为精简配置类public static boolean isLiteConfigurationCandidate(AnnotationMetadata metadata) &#123; // Do not consider an interface or an annotation... if (metadata.isInterface()) &#123; return false; &#125; // Any of the typical annotations found? for (String indicator : candidateIndicators) &#123; if (metadata.isAnnotated(indicator)) &#123; return true; &#125; &#125; // Finally, let's look for @Bean methods... try &#123; return metadata.hasAnnotatedMethods(Bean.class.getName()); &#125; catch (Throwable ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Failed to introspect @Bean methods on class [" + metadata.getClassName() + "]: " + ex); &#125; return false; &#125;&#125;//精简配置类包含的注解static &#123; candidateIndicators.add(Component.class.getName()); candidateIndicators.add(ComponentScan.class.getName()); candidateIndicators.add(Import.class.getName()); candidateIndicators.add(ImportResource.class.getName());&#125; 6. 参考https://blog.csdn.net/long476964/article/details/80626930 https://www.jianshu.com/p/89f55286cf21]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring系列(一)---Spring IoC 分析]]></title>
    <url>%2Fposts%2Fb93580d5.html</url>
    <content type="text"><![CDATA[本文主要介绍了 Spring 框架，通过代码演示详细讲述了 Spring IoC 的具体流程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 概述Spring 是一个开源容器框架，可以接管 web 层，业务层，dao 层，持久层的组件，并且可以配置各种bean,和维护 bean 与 bean 之间的关系。其核心就是控制反转(IoC),和面向切面(AOP),简单的说就是一个分层的轻量级开源框架。 2. Spring 中的 IoC IoC：(Inverse of Control )控制反转，容器主动将资源推送给它所管理的组件，组件所做的是选择一种合理的方式接受资源。 简单的理解：把创建对象和维护之间的关系的权利由程序中转移到Spring容器的配置文件中。 DI : (Dependency Injection) 依赖注入，IoC 的另一种表现方式，组件以一种预先定义好的方式来接受容器注入的资源。 3. IoC 例子3.1 xml 配置文件方式1. 准备 bean 对象先准备两个简单的实体类 Student 和 Book，需要提供Getter/Setter 和有参数无参构造方法等。 Spring Bean是事物处理组件类和实体类（POJO）对象的总称，Spring Bean 被Spring IoC 容器初始化，装配和管理。 12345678910111213141516171819202122/** * @author illusory * @version 1.0.0 * @date 2019/4/18 0018 */public class Student &#123; private String name; private int age; private Book book; //省略Getter/Setter和构造方法&#125;/** * @author illusory * @version 1.0.0 * @date 2019/4/18 */public class Book &#123; private String type; private String name; //省略Getter/Setter和构造方法&#125; 2. 将 Bean 类添加到 Spring IoC 容器将 Bean 类添加到 Spring IoC 容器有三种方式。 一种方式是基于XML的配置文件； 一种方式是基于注解的配置； 一种方式是基于 Java 的配置。 1. Spring Bean 类的配置项Spring IoC 容器管理 Bean 时，需要了解 Bean 的类名、名称、依赖项、属性、生命周期及作用域等信息。为此，Spring IoC 提供了一系列配置项，用于 Bean 在 IoC 容器中的定义。 ① class 该配置项是强制项，用于指定创建 Bean 实例的 Bean 类的路径。 ② name 该配置项是强制项，用于指定 Bean 唯一的标识符，在基于 XML 的配置项中，可以使用 id和或 name 属性来指定 Bean 唯一标识符。 ③ scope 该配置项是可选项，用于设定创建 Bean 对象的作用域。 ④ constructor-arg 该配置项是可选项，用于指定通过构造函数注入依赖数据到 Bean。 ⑤ properties 该配置项是可选项，用于指定通过 set 方法注入依赖数据到 Bean。 ⑥ autowiring mode 该配置项是可选项，用于指定通过自动依赖方法注入依赖数据到 Bean。 ⑦ lazy-initialization mode 该配置项是可选项，用于指定 IoC 容器延迟创建 Bean，在用户请求时创建 Bean，而不要在启动时就创建 Bean。 ⑧ initialization 该配置项是可选项，用于指定 IoC 容器完成 Bean 必要的创建后，调用 Bean 类提供的回调方法对 Bean 实例进一步处理。 ⑨ destruction 该配置项是可选项，用于指定 IoC 容器在销毁 Bean 时，调用 Bean 类提供的回调方法。 2. Spring xml 配置文件下面主要介绍基于XML的配置方式，基于注解和基于Java的配置放在后面进行讨论，放在后面讨论的原因是一些其它重要的Spring概念还需要掌握。 123456789101112131415&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!-- bean的配置文件 --&gt; &lt;bean id="student" class="spring.Student"&gt; &lt;property name="name" value="illusory"&gt;&lt;/property&gt; &lt;property name="age" value="23"&gt;&lt;/property&gt; &lt;property name="book" ref="book"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="book" class="spring.Book"&gt; &lt;property name="name" value="think in java"&gt;&lt;/property&gt; &lt;property name="type" value="CS"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 3.2 注解方式使用注解需要在xml配置文件中开启组件扫描 12&lt;!--配置组件扫描--&gt;&lt;context:component-scan base-package="spring"/&gt; 1.定义 bean定义一个 bean 实体类或组件 123456@Component(value = "book")public class Book &#123; private String type; private String name; //省略Getter/Setter和构造方法&#125; 2. 配置 bean 基本配置 123456@Component(value = "book")public class Book &#123; private String type; private String name; //省略Getter/Setter和构造方法&#125; 其中@Component(value = &quot;book&quot;)相当于&lt;bean id=&quot;book&quot; class=&quot;spring.Book&quot;&gt;Bean实例的名称默认是Bean类的首字母小写，其他部分不变 属性注入 普通类型注入: @Value(value = &quot;illusory&quot;)引用类型注入: @Autowired/@Resources(name=&quot;&quot;) 1234567891011121314151617@Component(value = "student")public class Student &#123; @Value(value = "illusory") private String name; @Value(value = "23") private int age; @Autowired private Book book;&#125;@Component(value = "book")public class Book &#123; @Value(value = "defaultType") private String type; @Value(value = "defaultName") private String name;&#125; 3. 获取 bean123456789public static void main(String[] args) &#123; // 根据配置文件创建 IoC 容器 ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext.xml"); // 从容器中获取 bean 实例 Student student = (Student) ac.getBean("student"); // 使用bean System.out.println(student.getName()); //成功打印出 illusory&#125; 3.3 测试12345678910111213141516/** * @author illusory * @version 1.0.0 * @date 2019/4/18 */public class SpringTest &#123; public static void main(String[] args) &#123; // 根据配置文件创建 IoC 容器 ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext.xml"); // 从容器中获取 bean 实例 这里的名称就是配置文件中的id="student" Student student = (Student) ac.getBean("student"); // 使用bean System.out.println(student.getName()); //成功打印出 illusory &#125;&#125; 4. 简要分析4.1 创建Spring IoC 容器1ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext .xml") 执行这句代码时 Spring 容器对象被创建，同时 applicationContext .xml中配置的 bean 就会被创建到内存中。 4.2 Bean注入Bean 注入的方式有两种； 一种是在XML中配置，此时分别有属性注入、构造函数注入和工厂方法注入； 另一种则是使用注解的方式注入: @Autowired、@Resource、@Required。 1. 在xml文件中配置依赖注入 属性注入 属性注入即通过setXxx()方法注入Bean的属性值或依赖对象，属性注入要求Bean提供一个默认的构造函数，并为需要注入的属性提供对应的Setter方法。Spring先调用Bean的默认构造函数实例化Bean对象，然后通过反射的方式调用Setter方法注入属性值。 由于属性注入方式具有可选择性和灵活性高的优点，因此属性注入是实际应用中最常采用的注入方式。1234&lt;bean id="book" class="spring.Book"&gt; &lt;property name="name" value="think in java"&gt;&lt;/property&gt; &lt;property name="type" value="CS"&gt;&lt;/property&gt;&lt;/bean&gt; 例子中的这个就是属性注入。 构造方法注入 使用构造函数注入的前提是 Bean必须提供带参数的构造函数。 1234&lt;bean id="book" class="spring.Book"&gt; &lt;constructor-arg name="name" value="think in java"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="type" value="CS"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 工厂方法注入 有时候 bean 对象不能直接 new，只能通过工厂方法创建。 12345678910111213141516171819202122/** * @author illusory * @version 1.0.0 * @date 2019/4/18 0018 */public class BookFactory &#123; //非静态方法 public Book createBook() &#123; Book book = new Book(); book.setName("图解HTTP"); book.setType("HTTP"); return book; &#125; //静态方法 public static Book createBookStatic() &#123; Book book = new Book(); book.setName("大话数据结构"); book.setType("数据结构"); return book; &#125;&#125; 非静态方法：必须实例化工厂类（factory-bean）后才能调用工厂方法 12&lt;bean id="bookFactory" class="spring.BookFactory"&gt;&lt;/bean&gt;&lt;bean id="book" class="spring.Book" factory-bean="bookFactory" factory-method="createBook"&gt;&lt;/bean&gt; 静态方法：不用实例化工厂类（factory-bean）后才能调用工厂方法 1&lt;bean id="book" class="spring.Book" factory-method="createBookStatic"&gt;&lt;/bean&gt; 4.3 获取 bean 实例接着通过从 Spring 容器中根据名字获取对应的 bean 。 1Student student = (Student) ac.getBean("student"); 5. 小结5.1 大致流程 1.定义bean：定义一个 bean 实体类或组件 2.配置 bean 基本配置 xml 配置文件中注册这个 bean 属性注入 xml 配置文件中为这个 bean 注入属性 XML中配置 : 属性注入、构造方法注入、工厂方法注入 注解方式 : @Autowired、@Resource、@Required 3.获取 bean 实例：根据 name(即配置文件中的 bean id) 从 Spring 容器中获取 bean 实例 5.2 具体代码1. 定义 bean定义一个 bean 实体类或组件 12345public class Book &#123; private String type; private String name; //省略Getter/Setter和构造方法&#125; 2. 配置 bean 基本配置 12&lt;bean id="book" class="spring.Book"&gt;&lt;/bean&gt; 属性注入 1234&lt;bean id="book" class="spring.Book"&gt; &lt;property name="name" value="think in java"&gt;&lt;/property&gt; &lt;property name="type" value="CS"&gt;&lt;/property&gt;&lt;/bean&gt; 3. 获取 bean1234// 根据配置文件创建 IoC 容器 ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext.xml"); // 从容器中获取 bean 实例 Student student = (Student) ac.getBean("student"); 6. 参考https://blog.csdn.net/u010648555/article/details/76299467https://www.cnblogs.com/_popc/p/3972212.htmlhttps://www.cnblogs.com/wnlja/p/3907836.html]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC系列(一)---执行流程分析]]></title>
    <url>%2Fposts%2Fcf395c14.html</url>
    <content type="text"><![CDATA[本文主要通过源码详细分析了 SpringMVC 框架的执行流程，包括建立 url 和 controller 的关系，通过 url 找到具体的方法，通过反射执行 controller 中的方法等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Servlet 执行流程传统servlet的执行过程分为如下几步：1、浏览器向服务器发送请求http://localhost:8080/demo/hello2、服务器接受到请求，并从地址中得到项目名称webproject3、然后再从地址中找到名称hello，并与webproject下的web.xml文件进行匹配4、在web.xml中找到一个&lt;url-pattern&gt;hello&lt;/url-pattern&gt;的标签，并且通过他找到servlet-name进而找到&lt;servlet-class&gt;5、再拿到servlet-class之后，这个服务器便知道了这个servlet的全类名，通过反射创建这个类的对象，并且调用doGet/doPost方法 6、方法执行完毕，结果返回到浏览器。结束。 2. SpringMVC 执行流程SpringMVC 中也配置了一个 Servlet,配置的是 org.springframework.web.servlet.DispatcherServlet，所有的请求过来都会找这个 servlet (前端控制器)，DispatcherServlet 继承了 HttpServlet。 运行过程分析1、 用户发送请求至前端控制器DispatcherServlet。 2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器。 3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)HandlerExcutorChain并返回给 DispatcherServlet。 4、 DispatcherServlet调用HandlerAdapter处理器适配器。 5、 HandlerAdapter经过适配调用具体的处理器(就是我们写的 Controller )。 6、 Controller执行完成返回ModelAndView。 7、 HandlerAdapter将 Controller 执行结果ModelAndView返回给DispatcherServlet。 8、 DispatcherServlet将 ModelAndView 传给ViewReslover视图解析器。 9、 ViewReslover解析后返回具体View(这就是为什么reurn &quot;index&quot;会自动找到 index.html) 10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。 11、 DispatcherServlet响应用户。 3. 具体过程分析1. 建立 Map&lt;urls,Controller&gt; 的关系概述在容器初始化时会建立所有url 和 controller的对应关系,保存到Map&lt;url,controller&gt;中。 DispatcherServlet--&gt;initApplicationContext初始化容器 建立Map&lt;url,controller&gt;关系的部分 Tomcat启动时会通知 Spring 初始化容器(加载 bean 的定义信息和初始化所有单例 bean ),然后 SpringMVC 会遍历容器中的bean,获取每一个 Controller 中的所有方法访问的 url,然后将 url和 Controller 保存到一个 Map 中; 2.根据访问url 找到对应 Controller 中处理请求的方法概述DispatcherServlet--&gt;doDispatch() 有了前面的 Map 就可以根据 Request快速定位到 Controller,因为最终处理 Request 的是 Controller 中的方法,Map 中只保留了 url 和 Controller 中的对应关系,所以要根据 Request 的 url 进一步确认 Controller 中的 Method. 原理这一步工作的原理就是拼接 Controller 的 url(controller上@RequestMapping的值) 和方法的 url(method 上@RequestMapping的值),与 Request 的 url 进行匹配,找到匹配的那个方法; 3. 参数绑定确定处理请求的 Method 后,接下来的任务就是参数绑定,把 Request 中参数绑定到方法的形式参数上,这一步是整个请求处理过程中最复杂的一个步骤。SpringMVC 提供了两种 Request 参数与方法形参的绑定方法: 注解使用注解进行绑定,我们只要在方法参数前面声明 @RequestParam(&quot;a&quot;),就可以将 Request 中参数 a 的值绑定到方法的该参数上。 参数名称使用参数名称进行绑定的前提是必须要获取方法中参数的名称,Java 反射只提供了获取方法的参数的类型,并没有提供获取参数名称的方法。SpringMVC 解决这个问题的方法是用 asm 框架读取字节码文件,来获取方法的参数名称。asm 框架是一个字节码操作框架,关于a sm 更多介绍可以参考它的官网。 个人建议,使用注解来完成参数绑定,这样就可以省去 asm 框架的读取字节码的操作。 4. 源码分析1. 建立Map&lt;url,controller&gt;的关系我们首先看第一个步骤,也就是建立Map&lt;url,controller&gt;关系的部分.第一部分的入口类ApplicationObjectSupport的setApplicationContext方法.setApplicationContext方法中核心部分就是初始化容器initApplicationContext(context),子类AbstractDetectingUrlHandlerMapping实现了该方法,所以我们直接看子类中的初始化容器方法. 123456789101112131415161718192021222324252627//ApplicationObjectSupport类 @Override public final void setApplicationContext(@Nullable ApplicationContext context) throws BeansException &#123; if (context == null &amp;&amp; !isContextRequired()) &#123; // Reset internal context state. this.applicationContext = null; this.messageSourceAccessor = null; &#125; else if (this.applicationContext == null) &#123; // Initialize with passed-in context. if (!requiredContextClass().isInstance(context)) &#123; throw new ApplicationContextException( "Invalid application context: needs to be of type [" + requiredContextClass().getName() + "]"); &#125; this.applicationContext = context; this.messageSourceAccessor = new MessageSourceAccessor(context); initApplicationContext(context); &#125; else &#123; // Ignore reinitialization if same context passed in. if (this.applicationContext != context) &#123; throw new ApplicationContextException( "Cannot reinitialize with different application context: current one is [" + this.applicationContext + "], passed-in one is [" + context + "]"); &#125; &#125; &#125; 其中initApplicationContext(context)由子类AbstractDetectingUrlHandlerMapping实现,具体如下:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Calls the &#123;@link #detectHandlers()&#125; method in addition to the * superclass's initialization. */ @Override public void initApplicationContext() throws ApplicationContextException &#123; super.initApplicationContext(); detectHandlers(); &#125; /** 建立当前ApplicationContext中的所有controller和url的对应关系 * Register all handlers found in the current ApplicationContext. * &lt;p&gt;The actual URL determination for a handler is up to the concrete * &#123;@link #determineUrlsForHandler(String)&#125; implementation. A bean for * which no such URLs could be determined is simply not considered a handler. * @throws org.springframework.beans.BeansException if the handler couldn't be registered * @see #determineUrlsForHandler(String) */ protected void detectHandlers() throws BeansException &#123; ApplicationContext applicationContext = obtainApplicationContext(); String[] beanNames = (this.detectHandlersInAncestorContexts ? BeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class) : applicationContext.getBeanNamesForType(Object.class)); // 获取ApplicationContext容器中所有bean的Name // Take any bean name that we can determine URLs for. // 遍历beanNames,并找到这些bean对应的url for (String beanName : beanNames) &#123; // 找bean上的所有url(controller上的url+方法上的url),该方法由对应的子类实现 String[] urls = determineUrlsForHandler(beanName); if (!ObjectUtils.isEmpty(urls)) &#123; // URL paths found: Let's consider it a handler. // 保存urls和beanName的对应关系,put it to Map&lt;urls,beanName&gt;,该方法在父类AbstractUrlHandlerMapping中实现 registerHandler(urls, beanName); &#125; &#125; if ((logger.isDebugEnabled() &amp;&amp; !getHandlerMap().isEmpty()) || logger.isTraceEnabled()) &#123; logger.debug("Detected " + getHandlerMap().size() + " mappings in " + formatMappingName()); &#125; &#125; /** * Determine the URLs for the given handler bean. * @param beanName the name of the candidate bean * @return the URLs determined for the bean, or an empty array if none */ /** 获取controller中所有方法的url,由子类实现,典型的模板模式 **/ protected abstract String[] determineUrlsForHandler(String beanName); determineUrlsForHandler(String beanName)方法的作用是获取每个Controller中的url,不同的子类有不同的实现,这是一个典型的模板设计模式.因为开发中我们用的最多的就是用注解来配置Controller`中的url,BeanNameUrlHandlerMapping是AbstractDetectingUrlHandlerMapping的子类,我们看BeanNameUrlHandlerMapping是如何查beanName上所有映射的url`. 12345678910111213141516171819202122public class BeanNameUrlHandlerMapping extends AbstractDetectingUrlHandlerMapping &#123; /** * Checks name and aliases of the given bean for URLs, starting with "/". * 找出名字或者别名是以 / 开头的bean */ @Override protected String[] determineUrlsForHandler(String beanName) &#123; List&lt;String&gt; urls = new ArrayList&lt;&gt;(); if (beanName.startsWith("/")) &#123; urls.add(beanName); &#125; String[] aliases = obtainApplicationContext().getAliases(beanName); for (String alias : aliases) &#123; if (alias.startsWith("/")) &#123; urls.add(alias); &#125; &#125; return StringUtils.toStringArray(urls); &#125;&#125; 2. 根据访问url找到对应controller中处理请求的方法下面我们开始分析第二个步骤,第二个步骤是由请求触发的,所以入口为DispatcherServlet.DispatcherServlet的核心方法为doService(),doService()中的核心逻辑由doDispatch()实现,我们查看doDispatch()的源代码. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104/** * Process the actual dispatching to the handler. * &lt;p&gt;The handler will be obtained by applying the servlet's HandlerMappings in order. * The HandlerAdapter will be obtained by querying the servlet's installed HandlerAdapters * to find the first that supports the handler class. * &lt;p&gt;All HTTP methods are handled by this method. It's up to HandlerAdapters or handlers * themselves to decide which methods are acceptable. * @param request current HTTP request * @param response current HTTP response * @throws Exception in case of any kind of processing failure *//** 中央控制器,控制请求的转发 **/protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; // 1.检查是否是文件上传的请求 processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. // 2.取得处理当前请求的controller,这里也称为hanlder,处理器 // 第一个步骤的意义就在这里体现了.这里并不是直接返回controller, // 而是返回的HandlerExecutionChain请求处理器链对象, // 该对象封装了handler和interceptors. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. //3. 获取处理request的处理器适配器handler adapter HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. // 处理 last-modified 请求头 String method = request.getMethod(); boolean isGet = "GET".equals(method); if (isGet || "HEAD".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // 4.拦截器的预处理方法 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // Actually invoke the handler. // 5.实际的处理器处理请求,返回结果视图对象 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; // 结果视图对象的处理 applyDefaultViewName(processedRequest, mv); // 6.拦截器的后处理方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; // As of 4.3, we're processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException("Handler dispatch failed", err); &#125; //将结果解析为ModelAndView processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; // 请求成功响应之后的方法 triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException("Handler processing failed", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; // Instead of postHandle and afterCompletion if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; // Clean up any resources used by a multipart request. if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 第2步:getHandler(processedRequest)方法实际上就是从HandlerMapping中找到url和Controller的对应关系.这也就是第一个步骤:建立Map&lt;url,Controller&gt;的意义.我们知道,最终处理Request的是Controller中的方法,我们现在只是知道了Controller,还要进一步确认Controller中处理Request的方法.由于下面的步骤和第三个步骤关系更加紧密,直接转到第三个步骤. 3. 反射调用处理请求的方法,返回结果视图上面的方法中,第2步其实就是从第一个步骤中的Map&lt;urls,beanName&gt;中取得Controller,然后经过拦截器的预处理方法,到最核心的部分–第5步调用Controller的方法处理请求.在第2步中我们可以知道处理Request的Controller,第5步就是要根据url确定Controller中处理请求的方法,然后通过反射获取该方法上的注解和参数,解析方法和参数上的注解,最后反射调用方法获取ModelAndView结果视图。 第5步调用的就是RequestMappingHandlerAdapter的handle().handle()中的核心逻辑由invokeHandlerMethod(request, response, handler)实现。 handle().handle()–&gt;handleInternal(request, response, (HandlerMethod) handler)–&gt;invokeHandlerMethod(request, response, handlerMethod) RequestMappingHandlerAdapter类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * Invoke the &#123;@link RequestMapping&#125; handler method preparing a &#123;@link ModelAndView&#125; * if view resolution is required. * @since 4.2 * @see #createInvocableHandlerMethod(HandlerMethod) */ @Nullable protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; ServletWebRequest webRequest = new ServletWebRequest(request, response); try &#123; WebDataBinderFactory binderFactory = getDataBinderFactory(handlerMethod); ModelFactory modelFactory = getModelFactory(handlerMethod, binderFactory); //创建invocableMetho ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); if (this.argumentResolvers != null) &#123; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers); &#125; if (this.returnValueHandlers != null) &#123; invocableMethod.setHandlerMethodReturnValueHandlers(this.returnValueHandlers); &#125; invocableMethod.setDataBinderFactory(binderFactory); invocableMethod.setParameterNameDiscoverer(this.parameterNameDiscoverer); ModelAndViewContainer mavContainer = new ModelAndViewContainer(); mavContainer.addAllAttributes(RequestContextUtils.getInputFlashMap(request)); modelFactory.initModel(webRequest, mavContainer, invocableMethod); mavContainer.setIgnoreDefaultModelOnRedirect(this.ignoreDefaultModelOnRedirect); AsyncWebRequest asyncWebRequest = WebAsyncUtils.createAsyncWebRequest(request, response); asyncWebRequest.setTimeout(this.asyncRequestTimeout); WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); asyncManager.setTaskExecutor(this.taskExecutor); asyncManager.setAsyncWebRequest(asyncWebRequest); asyncManager.registerCallableInterceptors(this.callableInterceptors); asyncManager.registerDeferredResultInterceptors(this.deferredResultInterceptors); if (asyncManager.hasConcurrentResult()) &#123; Object result = asyncManager.getConcurrentResult(); mavContainer = (ModelAndViewContainer) asyncManager.getConcurrentResultContext()[0]; asyncManager.clearConcurrentResult(); LogFormatUtils.traceDebug(logger, traceOn -&gt; &#123; String formatted = LogFormatUtils.formatValue(result, !traceOn); return "Resume with async result [" + formatted + "]"; &#125;); invocableMethod = invocableMethod.wrapConcurrentResult(result); &#125; //执行ServletInvocableHandlerMethod的invokeAndHandle方法 invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) &#123; return null; &#125; // 封装结果视图 return getModelAndView(mavContainer, modelFactory, webRequest); &#125; finally &#123; webRequest.requestCompleted(); &#125; &#125; invocableMethod.setHandlerMethodArgumentResolvers(this.argumentResolvers);为参数绑定，后面说 其中invokeAndHandle如下： 12345678910111213141516171819202122232425262728293031323334353637/** * Invoke the method and handle the return value through one of the * configured &#123;@link HandlerMethodReturnValueHandler HandlerMethodReturnValueHandlers&#125;. * @param webRequest the current request * @param mavContainer the ModelAndViewContainer for this request * @param providedArgs "given" arguments matched by type (not resolved) */public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123; //执行请求对应的方法，并获得返回值 Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); if (returnValue == null) &#123; if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) &#123; mavContainer.setRequestHandled(true); return; &#125; &#125; else if (StringUtils.hasText(getResponseStatusReason())) &#123; mavContainer.setRequestHandled(true); return; &#125; mavContainer.setRequestHandled(false); Assert.state(this.returnValueHandlers != null, "No return value handlers"); try &#123; this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest); &#125; catch (Exception ex) &#123; if (logger.isTraceEnabled()) &#123; logger.trace(formatErrorForReturnValue(returnValue), ex); &#125; throw ex; &#125;&#125; invokeForRequest中的操作也是比较简单的，首先获取request中的参数，然后调用doInvoke(args)方法。 12345678910 public Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception &#123;//首先会获取请求的参数，其实就是Controller方法中的参数 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) &#123; logger.trace("Arguments: " + Arrays.toString(args)); &#125; //调用Controller中的方法 return doInvoke(args); &#125; doInvoke方法是在InvocableHandlerMethod`类中，最重要的是调用getBridgedMethod().invoke(getBean(),args)，通过反射机制完成对Controller`中的函数的调用。 12345678910111213141516171819202122232425262728293031323334//InvocableHandlerMethod类 /** * Invoke the handler method with the given argument values. */ @Nullable protected Object doInvoke(Object... args) throws Exception &#123; //反射之前 取消Java的权限控制检查 ReflectionUtils.makeAccessible(getBridgedMethod()); try &#123; //通过执行controller中的方法 return getBridgedMethod().invoke(getBean(), args); &#125; catch (IllegalArgumentException ex) &#123; assertTargetBean(getBridgedMethod(), getBean(), args); String text = (ex.getMessage() != null ? ex.getMessage() : "Illegal argument"); throw new IllegalStateException(formatInvokeError(text, args), ex); &#125; catch (InvocationTargetException ex) &#123; // Unwrap for HandlerExceptionResolvers ... Throwable targetException = ex.getTargetException(); if (targetException instanceof RuntimeException) &#123; throw (RuntimeException) targetException; &#125; else if (targetException instanceof Error) &#123; throw (Error) targetException; &#125; else if (targetException instanceof Exception) &#123; throw (Exception) targetException; &#125; else &#123; throw new IllegalStateException(formatInvokeError("Invocation failure", args), targetException); &#125; &#125; &#125; 注：桥接方法是 JDK 1.5 引入泛型后，为了使Java的泛型方法生成的字节码和 1.5 版本前的字节码相兼容，由编译器自动生成的方法。 反正最终就是通过反射来调用Controller中的方法。 4. 参数绑定resolveHandlerArguments方法实现代码比较长,它最终要实现的目的就是:完成request中的参数和方法参数上数据的绑定. springmvc中提供两种request参数到方法中参数的绑定方式: 注解使用注解进行绑定,我们只要在方法参数前面声明 @RequestParam(&quot;a&quot;),就可以将 Request 中参数 a 的值绑定到方法的该参数上。 参数名称使用参数名称进行绑定的前提是必须要获取方法中参数的名称,Java 反射只提供了获取方法的参数的类型,并没有提供获取参数名称的方法。SpringMVC 解决这个问题的方法是用 asm 框架读取字节码文件,来获取方法的参数名称。asm 框架是一个字节码操作框架,关于a sm 更多介绍可以参考它的官网。 个人建议,使用注解来完成参数绑定,这样就可以省去 asm 框架的读取字节码的操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139private Object[] resolveHandlerArguments(Method handlerMethod, Object handler, NativeWebRequest webRequest, ExtendedModelMap implicitModel) throws Exception &#123; // 1.获取方法参数类型的数组 Class[] paramTypes = handlerMethod.getParameterTypes(); // 声明数组,存参数的值 Object[] args = new Object[paramTypes.length]; //2.遍历参数数组,获取每个参数的值 for (int i = 0; i &lt; args.length; i++) &#123; MethodParameter methodParam = new MethodParameter(handlerMethod, i); methodParam.initParameterNameDiscovery(this.parameterNameDiscoverer); GenericTypeResolver.resolveParameterType(methodParam, handler.getClass()); String paramName = null; String headerName = null; boolean requestBodyFound = false; String cookieName = null; String pathVarName = null; String attrName = null; boolean required = false; String defaultValue = null; boolean validate = false; int annotationsFound = 0; Annotation[] paramAnns = methodParam.getParameterAnnotations(); // 处理参数上的注解 for (Annotation paramAnn : paramAnns) &#123; if (RequestParam.class.isInstance(paramAnn)) &#123; RequestParam requestParam = (RequestParam) paramAnn; paramName = requestParam.value(); required = requestParam.required(); defaultValue = parseDefaultValueAttribute(requestParam.defaultValue()); annotationsFound++; &#125; else if (RequestHeader.class.isInstance(paramAnn)) &#123; RequestHeader requestHeader = (RequestHeader) paramAnn; headerName = requestHeader.value(); required = requestHeader.required(); defaultValue = parseDefaultValueAttribute(requestHeader.defaultValue()); annotationsFound++; &#125; else if (RequestBody.class.isInstance(paramAnn)) &#123; requestBodyFound = true; annotationsFound++; &#125; else if (CookieValue.class.isInstance(paramAnn)) &#123; CookieValue cookieValue = (CookieValue) paramAnn; cookieName = cookieValue.value(); required = cookieValue.required(); defaultValue = parseDefaultValueAttribute(cookieValue.defaultValue()); annotationsFound++; &#125; else if (PathVariable.class.isInstance(paramAnn)) &#123; PathVariable pathVar = (PathVariable) paramAnn; pathVarName = pathVar.value(); annotationsFound++; &#125; else if (ModelAttribute.class.isInstance(paramAnn)) &#123; ModelAttribute attr = (ModelAttribute) paramAnn; attrName = attr.value(); annotationsFound++; &#125; else if (Value.class.isInstance(paramAnn)) &#123; defaultValue = ((Value) paramAnn).value(); &#125; else if ("Valid".equals(paramAnn.annotationType().getSimpleName())) &#123; validate = true; &#125; &#125; if (annotationsFound &gt; 1) &#123; throw new IllegalStateException("Handler parameter annotations are exclusive choices - " + "do not specify more than one such annotation on the same parameter: " + handlerMethod); &#125; if (annotationsFound == 0) &#123;// 如果没有注解 Object argValue = resolveCommonArgument(methodParam, webRequest); if (argValue != WebArgumentResolver.UNRESOLVED) &#123; args[i] = argValue; &#125; else if (defaultValue != null) &#123; args[i] = resolveDefaultValue(defaultValue); &#125; else &#123; Class paramType = methodParam.getParameterType(); // 将方法声明中的Map和Model参数,放到request中,用于将数据放到request中带回页面 if (Model.class.isAssignableFrom(paramType) || Map.class.isAssignableFrom(paramType)) &#123; args[i] = implicitModel; &#125; else if (SessionStatus.class.isAssignableFrom(paramType)) &#123; args[i] = this.sessionStatus; &#125; else if (HttpEntity.class.isAssignableFrom(paramType)) &#123; args[i] = resolveHttpEntityRequest(methodParam, webRequest); &#125; else if (Errors.class.isAssignableFrom(paramType)) &#123; throw new IllegalStateException("Errors/BindingResult argument declared " + "without preceding model attribute. Check your handler method signature!"); &#125; else if (BeanUtils.isSimpleProperty(paramType)) &#123; paramName = ""; &#125; else &#123; attrName = ""; &#125; &#125; &#125; // 从request中取值,并进行赋值操作 if (paramName != null) &#123; // 根据paramName从request中取值,如果没有通过RequestParam注解指定paramName,则使用asm读取class文件来获取paramName args[i] = resolveRequestParam(paramName, required, defaultValue, methodParam, webRequest, handler); &#125; else if (headerName != null) &#123; args[i] = resolveRequestHeader(headerName, required, defaultValue, methodParam, webRequest, handler); &#125; else if (requestBodyFound) &#123; args[i] = resolveRequestBody(methodParam, webRequest, handler); &#125; else if (cookieName != null) &#123; args[i] = resolveCookieValue(cookieName, required, defaultValue, methodParam, webRequest, handler); &#125; else if (pathVarName != null) &#123; args[i] = resolvePathVariable(pathVarName, methodParam, webRequest, handler); &#125; else if (attrName != null) &#123; WebDataBinder binder = resolveModelAttribute(attrName, methodParam, implicitModel, webRequest, handler); boolean assignBindingResult = (args.length &gt; i + 1 &amp;&amp; Errors.class.isAssignableFrom(paramTypes[i + 1])); if (binder.getTarget() != null) &#123; doBind(binder, webRequest, validate, !assignBindingResult); &#125; args[i] = binder.getTarget(); if (assignBindingResult) &#123; args[i + 1] = binder.getBindingResult(); i++; &#125; implicitModel.putAll(binder.getBindingResult().getModel()); &#125; &#125; // 返回参数值数组 return args; &#125; 5. 反射源码分析反射相关分析来源于：http://www.sczyh30.com/posts/Java/java-reflection-2/ 第三步中的invoke方法如下 12345678910111213141516171819@CallerSensitivepublic Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; if (!override) &#123; //quickCheckMemberAccess 检查方法是否为public 如果是的话跳出本步 if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; //如果不是public方法，那么用Reflection.getCallerClass()方法获取调用这个方法的Class对象，这是一个native方法: Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; MethodAccessor ma = methodAccessor; // read volatile if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; return ma.invoke(obj, args);&#125; getCallerClass()是一个native方法 12@CallerSensitive public static native Class&lt;?&gt; getCallerClass(); 在OpenJDK的源码中找到此方法的JNI入口(Reflection.c): 12345JNIEXPORT jclass JNICALL Java_sun_reflect_Reflection_getCallerClass__(JNIEnv *env, jclass unused)&#123; return JVM_GetCallerClass(env, JVM_CALLER_DEPTH);&#125; 获取了这个Class对象caller后用checkAccess方法做一次快速的权限校验，其实现为: 12345678910111213141516171819202122232425262728293031volatile Object securityCheckCache; void checkAccess(Class&lt;?&gt; caller, Class&lt;?&gt; clazz, Object obj, int modifiers) throws IllegalAccessException &#123; if (caller == clazz) &#123; // 快速校验 return; // 权限通过校验 &#125; Object cache = securityCheckCache; // read volatile Class&lt;?&gt; targetClass = clazz; if (obj != null &amp;&amp; Modifier.isProtected(modifiers) &amp;&amp; ((targetClass = obj.getClass()) != clazz)) &#123; // Must match a 2-list of &#123; caller, targetClass &#125;. if (cache instanceof Class[]) &#123; Class&lt;?&gt;[] cache2 = (Class&lt;?&gt;[]) cache; if (cache2[1] == targetClass &amp;&amp; cache2[0] == caller) &#123; return; // ACCESS IS OK &#125; // (Test cache[1] first since range check for [1] // subsumes range check for [0].) &#125; &#125; else if (cache == caller) &#123; // Non-protected case (or obj.class == this.clazz). return; // ACCESS IS OK &#125; // If no return, fall through to the slow path. slowCheckMemberAccess(caller, clazz, obj, modifiers, targetClass); &#125; 首先先执行一次快速校验，一旦调用方法的Class正确则权限检查通过。若未通过，则创建一个缓存，中间再进行一堆检查（比如检验是否为protected属性）。如果上面的所有权限检查都未通过，那么将执行更详细的检查，其实现为： 123456789101112131415161718// Keep all this slow stuff out of line:void slowCheckMemberAccess(Class&lt;?&gt; caller, Class&lt;?&gt; clazz, Object obj, int modifiers, Class&lt;?&gt; targetClass) throws IllegalAccessException&#123; Reflection.ensureMemberAccess(caller, clazz, obj, modifiers); // Success: Update the cache. Object cache = ((targetClass == clazz) ? caller : new Class&lt;?&gt;[] &#123; caller, targetClass &#125;); // Note: The two cache elements are not volatile, // but they are effectively final. The Java memory model // guarantees that the initializing stores for the cache // elements will occur before the volatile write. securityCheckCache = cache; // write volatile&#125; 大体意思就是，用Reflection.ensureMemberAccess方法继续检查权限，若检查通过就更新缓存，这样下一次同一个类调用同一个方法时就不用执行权限检查了，这是一种简单的缓存机制。由于JMM的happens-before规则能够保证缓存初始化能够在写缓存之前发生，因此两个cache不需要声明为volatile。到这里，前期的权限检查工作就结束了。如果没有通过检查则会抛出异常，如果通过了检查则会到下一步。 调用MethodAccessor的invoke方法Method.invoke()实际上并不是自己实现的反射调用逻辑，而是委托给sun.reflect.MethodAccessor来处理。首先要了解Method对象的基本构成，每个Java方法有且只有一个Method对象作为root，它相当于根对象，对用户不可见。当我们创建Method对象时，我们代码中获得的Method对象都相当于它的副本（或引用）。root对象持有一个MethodAccessor对象，所以所有获取到的Method对象都共享这一个MethodAccessor对象，因此必须保证它在内存中的可见性。root对象其声明及注释为： 12345678private volatile MethodAccessor methodAccessor;// For sharing of MethodAccessors. This branching structure is// currently only two levels deep (i.e., one root Method and// potentially many Method objects pointing to it.)//// If this branching structure would ever contain cycles, deadlocks can// occur in annotation code.private Method root; 那么MethodAccessor到底是个啥玩意呢？ 12345678910/** This interface provides the declaration for java.lang.reflect.Method.invoke(). Each Method object is configured with a (possibly dynamically-generated) class which implements this interface.*/ public interface MethodAccessor &#123; /** Matches specification in &#123;@link java.lang.reflect.Method&#125; */ public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException;&#125; 可以看到MethodAccessor是一个接口，定义了invoke方法。分析其Usage可得它的具体实现类有: sun.reflect.DelegatingMethodAccessorImpl sun.reflect.MethodAccessorImpl sun.reflect.NativeMethodAccessorImpl 第一次调用一个Java方法对应的Method对象的invoke()方法之前，实现调用逻辑的MethodAccessor对象还没有创建；等第一次调用时才新创建MethodAccessor并更新给root，然后调用MethodAccessor.invoke()完成反射调用： 12345678910111213141516171819// NOTE that there is no synchronization used here. It is correct// (though not efficient) to generate more than one MethodAccessor// for a given Method. However, avoiding synchronization will// probably make the implementation more scalable.private MethodAccessor acquireMethodAccessor() &#123; // First check to see if one has been created yet, and take it // if so MethodAccessor tmp = null; if (root != null) tmp = root.getMethodAccessor(); if (tmp != null) &#123; methodAccessor = tmp; &#125; else &#123; // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newMethodAccessor(this); setMethodAccessor(tmp); &#125; return tmp;&#125; 可以看到methodAccessor实例由reflectionFactory对象操控生成，它在AccessibleObject下的声明如下: 123456// Reflection factory used by subclasses for creating field,// method, and constructor accessors. Note that this is called// very early in the bootstrapping process.static final ReflectionFactory reflectionFactory = AccessController.doPrivileged( new sun.reflect.ReflectionFactory.GetReflectionFactoryAction()); 再研究一下sun.reflect.ReflectionFactory类的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596public class ReflectionFactory &#123; private static boolean initted = false; private static Permission reflectionFactoryAccessPerm = new RuntimePermission("reflectionFactoryAccess"); private static ReflectionFactory soleInstance = new ReflectionFactory(); // Provides access to package-private mechanisms in java.lang.reflect private static volatile LangReflectAccess langReflectAccess; // 这里设计得非常巧妙 // "Inflation" mechanism. Loading bytecodes to implement // Method.invoke() and Constructor.newInstance() currently costs // 3-4x more than an invocation via native code for the first // invocation (though subsequent invocations have been benchmarked // to be over 20x faster). Unfortunately this cost increases // startup time for certain applications that use reflection // intensively (but only once per class) to bootstrap themselves. // To avoid this penalty we reuse the existing JVM entry points // for the first few invocations of Methods and Constructors and // then switch to the bytecode-based implementations. // // Package-private to be accessible to NativeMethodAccessorImpl // and NativeConstructorAccessorImpl private static boolean noInflation = false; private static int inflationThreshold = 15; //...... //这是生成MethodAccessor的方法 public MethodAccessor newMethodAccessor(Method method) &#123; checkInitted(); if (noInflation &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; return new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); &#125; else &#123; NativeMethodAccessorImpl acc = new NativeMethodAccessorImpl(method); DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); acc.setParent(res); return res; &#125; &#125; //...... /** We have to defer full initialization of this class until after the static initializer is run since java.lang.reflect.Method's static initializer (more properly, that for java.lang.reflect.AccessibleObject) causes this class's to be run, before the system properties are set up. */ private static void checkInitted() &#123; if (initted) return; AccessController.doPrivileged( new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; // Tests to ensure the system properties table is fully // initialized. This is needed because reflection code is // called very early in the initialization process (before // command-line arguments have been parsed and therefore // these user-settable properties installed.) We assume that // if System.out is non-null then the System class has been // fully initialized and that the bulk of the startup code // has been run. if (System.out == null) &#123; // java.lang.System not yet fully initialized return null; &#125; String val = System.getProperty("sun.reflect.noInflation"); if (val != null &amp;&amp; val.equals("true")) &#123; noInflation = true; &#125; val = System.getProperty("sun.reflect.inflationThreshold"); if (val != null) &#123; try &#123; inflationThreshold = Integer.parseInt(val); &#125; catch (NumberFormatException e) &#123; throw new RuntimeException("Unable to parse property sun.reflect.inflationThreshold", e); &#125; &#125; initted = true; return null; &#125; &#125;); &#125;&#125; 观察前面的声明部分的注释，我们可以发现一些有趣的东西。就像注释里说的，实际的MethodAccessor实现有两个版本，一个是Java版本，一个是native版本，两者各有特点。初次启动时Method.invoke()和Constructor.newInstance()方法采用native方法要比Java方法快3-4倍，而启动后native方法又要消耗额外的性能而慢于Java方法。也就是说，Java实现的版本在初始化时需要较多时间，但长久来说性能较好；native版本正好相反，启动时相对较快，但运行时间长了之后速度就比不过Java版了。这是HotSpot的优化方式带来的性能特性，同时也是许多虚拟机的共同点：跨越native边界会对优化有阻碍作用，它就像个黑箱一样让虚拟机难以分析也将其内联，于是运行时间长了之后反而是托管版本的代码更快些。 为了尽可能地减少性能损耗，HotSpot JDK采用“inflation”的技巧：让Java方法在被反射调用时，开头若干次使用native版，等反射调用次数超过阈值时则生成一个专用的MethodAccessor实现类，生成其中的invoke()方法的字节码，以后对该Java方法的反射调用就会使用Java版本。 这项优化是从JDK 1.4开始的。 研究ReflectionFactory.newMethodAccessor()生产MethodAccessor对象的逻辑，一开始(native版)会生产NativeMethodAccessorImpl和DelegatingMethodAccessorImpl两个对象。DelegatingMethodAccessorImpl的源码如下： 1234567891011121314151617181920/** Delegates its invocation to another MethodAccessorImpl and can change its delegate at run time. */class DelegatingMethodAccessorImpl extends MethodAccessorImpl &#123; private MethodAccessorImpl delegate; DelegatingMethodAccessorImpl(MethodAccessorImpl delegate) &#123; setDelegate(delegate); &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; return delegate.invoke(obj, args); &#125; void setDelegate(MethodAccessorImpl delegate) &#123; this.delegate = delegate; &#125;&#125; 它其实是一个中间层，方便在native版与Java版的MethodAccessor之间进行切换。然后下面就是native版MethodAccessor的Java方面的声明：sun.reflect.NativeMethodAccessorImpl： 12345678910111213141516171819202122232425262728293031323334353637383940/** Used only for the first few invocations of a Method; afterward, switches to bytecode-based implementation */class NativeMethodAccessorImpl extends MethodAccessorImpl &#123; private Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method method) &#123; this.method = method; &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; // We can't inflate methods belonging to vm-anonymous classes because // that kind of class can't be referred to by name, hence can't be // found from the generated bytecode. if (++numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); &#125; return invoke0(method, obj, args); &#125; void setParent(DelegatingMethodAccessorImpl parent) &#123; this.parent = parent; &#125; private static native Object invoke0(Method m, Object obj, Object[] args);&#125; 每次NativeMethodAccessorImpl.invoke()方法被调用时，程序调用计数器都会增加1，看看是否超过阈值；一旦超过，则调用MethodAccessorGenerator.generateMethod()来生成Java版的MethodAccessor的实现类，并且改变DelegatingMethodAccessorImpl所引用的MethodAccessor为Java版。后续经由DelegatingMethodAccessorImpl.invoke()调用到的就是Java版的实现了。到这里，我们已经追寻到native版的invoke方法在Java一侧声明的最底层 - invoke0了，下面我们将深入到HotSpot JVM中去研究其具体实现。 寻根溯源 - 在JVM层面探究invoke0方法invoke0方法是一个native方法,它在HotSpot JVM里调用JVM_InvokeMethod函数: 12345JNIEXPORT jobject JNICALL Java_sun_reflect_NativeMethodAccessorImpl_invoke0(JNIEnv *env, jclass unused, jobject m, jobject obj, jobjectArray args)&#123; return JVM_InvokeMethod(env, m, obj, args);&#125; openjdk/hotspot/src/share/vm/prims/jvm.cpp 1234567891011121314151617181920212223JVM_ENTRY(jobject, JVM_InvokeMethod(JNIEnv *env, jobject method, jobject obj, jobjectArray args0)) JVMWrapper("JVM_InvokeMethod"); Handle method_handle; if (thread-&gt;stack_available((address) &amp;method_handle) &gt;= JVMInvokeMethodSlack) &#123; method_handle = Handle(THREAD, JNIHandles::resolve(method)); Handle receiver(THREAD, JNIHandles::resolve(obj)); objArrayHandle args(THREAD, objArrayOop(JNIHandles::resolve(args0))); oop result = Reflection::invoke_method(method_handle(), receiver, args, CHECK_NULL); jobject res = JNIHandles::make_local(env, result); if (JvmtiExport::should_post_vm_object_alloc()) &#123; oop ret_type = java_lang_reflect_Method::return_type(method_handle()); assert(ret_type != NULL, "sanity check: ret_type oop must not be NULL!"); if (java_lang_Class::is_primitive(ret_type)) &#123; // Only for primitive type vm allocates memory for java object. // See box() method. JvmtiExport::post_vm_object_alloc(JavaThread::current(), result); &#125; &#125; return res; &#125; else &#123; THROW_0(vmSymbols::java_lang_StackOverflowError()); &#125;JVM_END 其关键部分为Reflection::invoke_method: openjdk/hotspot/src/share/vm/runtime/reflection.cpp 1234567891011121314151617181920212223oop Reflection::invoke_method(oop method_mirror, Handle receiver, objArrayHandle args, TRAPS) &#123; oop mirror = java_lang_reflect_Method::clazz(method_mirror); int slot = java_lang_reflect_Method::slot(method_mirror); bool override = java_lang_reflect_Method::override(method_mirror) != 0; objArrayHandle ptypes(THREAD, objArrayOop(java_lang_reflect_Method::parameter_types(method_mirror))); oop return_type_mirror = java_lang_reflect_Method::return_type(method_mirror); BasicType rtype; if (java_lang_Class::is_primitive(return_type_mirror)) &#123; rtype = basic_type_mirror_to_basic_type(return_type_mirror, CHECK_NULL); &#125; else &#123; rtype = T_OBJECT; &#125; instanceKlassHandle klass(THREAD, java_lang_Class::as_Klass(mirror)); Method* m = klass-&gt;method_with_idnum(slot); if (m == NULL) &#123; THROW_MSG_0(vmSymbols::java_lang_InternalError(), "invoke"); &#125; methodHandle method(THREAD, m); return invoke(klass, method, receiver, override, ptypes, rtype, args, true, THREAD);&#125; 这里面又会涉及到Java的对象模型(klass和oop)，以后继续补充。笑容逐渐消失。 寻根溯源 - Java版的实现Java版MethodAccessor的生成使用MethodAccessorGenerator实现，由于代码太长，这里就不贴代码了，只贴一下开头的注释： 1234567/** Generator for sun.reflect.MethodAccessor and sun.reflect.ConstructorAccessor objects using bytecodes to implement reflection. A java.lang.reflect.Method or java.lang.reflect.Constructor object can delegate its invoke or newInstance method to an accessor using native code or to one generated by this class. (Methods and Constructors were merged together in this class to ensure maximum code sharing.) */ 这里又运用了asm动态生成字节码技术（sun.reflect.ClassFileAssembler)。 5. 小结大致流程如下： 1.建立 Map&lt;url,comtroller&gt; 的关系 2.根据 url 找到具体的处理方法 3.通过反射调用 controller 中的方法 4.通过注解或参数名称实现参数绑定 参考https://www.cnblogs.com/heavenyes/p/3905844.html#t1 sczyh30: http://www.sczyh30.com/posts/Java/java-reflection-2/]]></content>
      <categories>
        <category>SpringMVC</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis系列(一)---SQL 执行流程分析]]></title>
    <url>%2Fposts%2Faada1167.html</url>
    <content type="text"><![CDATA[本文主要通过源码详细分析了 Mybatis 框架中 SQL 语句的执行流程，包括加载解析核心配置文件，创建SqlSessionFactory对象，创建SqlSession对象，执行 SQL 操作。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Mybatis工作流程1.1 概述 1.读取mybatis全局配置文件：将定义好的mybatis全局配置文件进行读取，并包装成为一个InputStream对象2.解析配置文件：由SqlSessionFactoryBuilder类的bulid方法驱动，对包装好的XML文件进行解析。很容易看到，其具体的解析任务是交给XMLConfigBuilder对象完成.3.创建SqlSessionFactory对象4.创建SqlSession的对象5.执行SQL操作 Mybatis底层自定义了Executor执行器接口操作数据库，Executor接口有两个实现，一个是基本执行器BaseExecutor、一个是缓存执行器CachingExecutor。Mybatis底层封装了 Mapped Statement对象，它包装了mybatis配置信息及sql映射信息等。mapper.xml文件中一个sql对应一个Mapped Statement对象，sql的id即是Mapped statement的id。 Mapped Statement对sql执行输入参数进行定义，包括HashMap、基本类型、pojo，Executor通过 Mapped Statement在执行sql前将输入的java对象映射至sql中，输入参数映射就是jdbc编程中对preparedStatement设置参数。Mapped Statement对sql执行输出结果进行定义，包括HashMap、基本类型、pojo，Executor通过 Mapped Statement在执行sql后将输出结果映射至java对象中，输出结果映射过程相当于jdbc编程中对结果的解析处理过程。 1.2 实例代码1234567891011121314151617@Testpublic void testMybaits() throws IOException &#123; // 1. mybatis核心配置文件 以流的形式加载进来 String resources = "mybatis-config.xml"; InputStream resourceAsStream = Resources.getResourceAsStream(resources); // 2. 解析配置文件 根据配置文件创建SqlSessionFactory SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(resourceAsStream); // 3. 用SqlSessionFactory创建SqlSession SqlSession sqlSession = sqlSessionFactory.openSession(); // 直接执行SQL操作或者获取mapper对象都在操作 User user = sqlSession.selectOne("com.illusory.i.shiro.mapper.UserMapper.findUserByName", "张三"); System.out.println(user); // 4. SqlSession获取mapper UserMapper mapper = sqlSession.getMapper(UserMapper.class); // 5. 执行CRUD操作 User userByName = mapper.findUserByName("username");&#125; 2.原理分析2.1 读取mybatis全局配置文件 将定义好的mybatis全局配置文件进行读取，并包装称为一个InputStream对象。 123// 1. mybatis核心配置文件 以流的形式加载进来String resources = "mybatis-config.xml";InputStream resourceAsStream = Resources.getResourceAsStream(resources); Resources.class是 Mybatis 提供的一个加载资源文件的工具类。 getResourceAsStream(String resource) 1234567891011//Resources类/* * Returns a resource on the classpath as a Stream object * * @param resource The resource to find * @return The resource * @throws java.io.IOException If the resource cannot be found or read */ public static InputStream getResourceAsStream(String resource) throws IOException &#123; return getResourceAsStream(null, resource); &#125; getResourceAsStream() 123456789101112131415/* * Returns a resource on the classpath as a Stream object * * @param loader The classloader used to fetch the resource * @param resource The resource to find * @return The resource * @throws java.io.IOException If the resource cannot be found or read */public static InputStream getResourceAsStream(ClassLoader loader, String resource) throws IOException &#123; InputStream in = classLoaderWrapper.getResourceAsStream(resource, loader); if (in == null) &#123; throw new IOException("Could not find resource " + resource); &#125; return in;&#125; 获取到自身的 ClassLoader 对象，然后交给 ClassLoade r(lang包下的)来加载: getResourceAsStream() 1234567891011121314151617181920212223242526272829303132333435363738//ClassLoaderWrapper /* * Get a resource from the classpath, starting with a specific class loader * * @param resource - the resource to find * @param classLoader - the first class loader to try * @return the stream or null */ public InputStream getResourceAsStream(String resource, ClassLoader classLoader) &#123; return getResourceAsStream(resource, getClassLoaders(classLoader)); &#125; /* * Try to get a resource from a group of classloaders * * @param resource - the resource to get * @param classLoader - the classloaders to examine * @return the resource or null */ InputStream getResourceAsStream(String resource, ClassLoader[] classLoader) &#123; for (ClassLoader cl : classLoader) &#123; if (null != cl) &#123; // try to find the resource as passed InputStream returnValue = cl.getResourceAsStream(resource); // now, some class loaders want this leading "/", so we'll add it and try again if we didn't find the resource if (null == returnValue) &#123; returnValue = cl.getResourceAsStream("/" + resource); &#125; if (null != returnValue) &#123; return returnValue; &#125; &#125; &#125; return null; &#125; 值的注意的是，它返回了一个InputStream对象。 2.2 解析配置文件 由SqlSessionFactoryBuilder类的bulid方法驱动，对包装好的XML文件进行解析。很容易看到，其具体的解析任务是交给XMLConfigBuilder对象完成. SqlSessionFactory.build() 123public SqlSessionFactory build(InputStream inputStream) &#123; return build(inputStream, null, null);&#125; SqlSessionFactoryBuilder.build() 123456789101112131415public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &#123; try &#123; XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); return build(parser.parse()); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException("Error building SqlSession.", e); &#125; finally &#123; ErrorContext.instance().reset(); try &#123; inputStream.close(); &#125; catch (IOException e) &#123; // Intentionally ignore. Prefer previous error. &#125; &#125;&#125; 首先通过 Document 对象来解析，然后返回 InputStream 对象，然后交给 XMLConfigBuilder 构造成org.apache.ibatis.session.Configuration 对象， 2.3 创建方法构造成SqlSessionFactory对象将前面解析配置文件构造出来的Configuration对象交给SqlSessionFactoryBuilder.build()方法构造成SqlSessionFactory。 build方法如下： 123public SqlSessionFactory build(Configuration config) &#123; return new DefaultSqlSessionFactory(config);&#125; 最终返回的是DefaultSqlSessionFactory对象 2.4 创建SqlSessionSqlSession 完全包含了面向数据库执行 SQL 命令所需的所有方法。你可以通过 SqlSession 实例来直接执行已映射的 SQL 语句。 12// 3. 用SqlSessionFactory创建SqlSessionSqlSession sqlSession = sqlSessionFactory.openSession(); DefaultSqlSessionFactory.openSession() 1234@Overridepublic SqlSession openSession() &#123; return openSessionFromDataSource(configuration.getDefaultExecutorType(), null, false);&#125; 最终也是返回的一个DefaultSqlSession对象。12345678910111213141516171819private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; //根据Configuration的Environment属性来创建事务工厂 final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); //通过事务工厂创建事务，默认level=null autoCommit=false tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); //创建执行器 真正执行sql语句的对象 final Executor executor = configuration.newExecutor(tx, execType); //根据执行器返回对象 SqlSess return new DefaultSqlSession(configuration, executor, autoCommit); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException("Error opening session. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 构建步骤： Environment–&gt;TransactionFactory+autoCommit+tx-level–&gt;Transaction+ExecType–&gt;Executor+Configuration+autoCommit–&gt;SqlSession 其中，Environment是Configuration中的属性。 2.5 执行SQL操作SQL语句的执行才是MyBatis的重要职责，该过程就是通过封装JDBC进行操作，然后使用Java反射技术完成JavaBean对象到数据库参数之间的相互转换，这种映射关系就是有TypeHandler对象来完成的，在获取数据表对应的元数据时，会保存该表所有列的数据库类型，大致逻辑如下所示： 12User user = sqlSession.selectOne("com.illusory.i.shiro.mapper.UserMapper.findUserByName", "张三"); System.out.println(user); 调用selectOne方法进行SQL查询，selectOne方法最后调用的是selectList，在selectList中，会查询configuration中存储的MappedStatement对象，mapper文件中一个sql语句的配置对应一个MappedStatement对象，然后调用执行器进行查询操作。 DefaultSqlSession.selectOne(); 123456789101112@Overridepublic &lt;T&gt; T selectOne(String statement, Object parameter) &#123; // Popular vote was to return null on 0 results and throw exception on too many. List&lt;T&gt; list = this.&lt;T&gt;selectList(statement, parameter); if (list.size() == 1) &#123; return list.get(0); &#125; else if (list.size() &gt; 1) &#123; throw new TooManyResultsException("Expected one result (or null) to be returned by selectOne(), but found: " + list.size()); &#125; else &#123; return null; &#125;&#125; DefaultSqlSession.selectList(); 12345678910111213141516@Overridepublic &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter) &#123; return this.selectList(statement, parameter, RowBounds.DEFAULT);&#125;@Overridepublic &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement); return executor.query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException("Error querying database. Cause: " + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 执行器在query操作中，优先会查询缓存是否命中，命中则直接返回，否则从数据库中查询。 CachingExecutor.query() 123456789101112131415161718192021222324252627@Overridepublic &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler) throws SQLException &#123; BoundSql boundSql = ms.getBoundSql(parameterObject); CacheKey key = createCacheKey(ms, parameterObject, rowBounds, boundSql); return query(ms, parameterObject, rowBounds, resultHandler, key, boundSql);&#125; @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; Cache cache = ms.getCache(); if (cache != null) &#123; flushCacheIfRequired(ms); if (ms.isUseCache() &amp;&amp; resultHandler == null) &#123; ensureNoOutParams(ms, boundSql); @SuppressWarnings("unchecked") List&lt;E&gt; list = (List&lt;E&gt;) tcm.getObject(cache, key); if (list == null) &#123; list = delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); tcm.putObject(cache, key, list); // issue #578 and #116 &#125; return list; &#125; &#125; //BaseExecutor.query() return delegate.&lt;E&gt; query(ms, parameterObject, rowBounds, resultHandler, key, boundSql); &#125; BaseExecutor.query() 1234567891011121314151617181920212223242526272829303132333435@SuppressWarnings("unchecked") @Override public &lt;E&gt; List&lt;E&gt; query(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; ErrorContext.instance().resource(ms.getResource()).activity("executing a query").object(ms.getId()); if (closed) &#123; throw new ExecutorException("Executor was closed."); &#125; if (queryStack == 0 &amp;&amp; ms.isFlushCacheRequired()) &#123; clearLocalCache(); &#125; List&lt;E&gt; list; try &#123; queryStack++; list = resultHandler == null ? (List&lt;E&gt;) localCache.getObject(key) : null; if (list != null) &#123; handleLocallyCachedOutputParameters(ms, key, parameter, boundSql); &#125; else &#123; list = queryFromDatabase(ms, parameter, rowBounds, resultHandler, key, boundSql); &#125; &#125; finally &#123; queryStack--; &#125; if (queryStack == 0) &#123; for (DeferredLoad deferredLoad : deferredLoads) &#123; deferredLoad.load(); &#125; // issue #601 deferredLoads.clear(); if (configuration.getLocalCacheScope() == LocalCacheScope.STATEMENT) &#123; // issue #482 clearLocalCache(); &#125; &#125; return list; &#125; BaseExecutor.queryFromDatabase() 123456789101112131415161718192021222324252627private &lt;E&gt; List&lt;E&gt; queryFromDatabase(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, CacheKey key, BoundSql boundSql) throws SQLException &#123; List&lt;E&gt; list; /** * 先往localCache中插入一个占位对象，这个地方 */ localCache.putObject(key, EXECUTION_PLACEHOLDER); try &#123; list = doQuery(ms, parameter, rowBounds, resultHandler, boundSql); &#125; finally &#123; localCache.removeObject(key); &#125; /* 往缓存中写入数据，也就是缓存查询结果 */ localCache.putObject(key, list); if (ms.getStatementType() == StatementType.CALLABLE) &#123; localOutputParameterCache.putObject(key, parameter); &#125; return list;&#125;protected Connection getConnection(Log statementLog) throws SQLException &#123; Connection connection = transaction.getConnection(); if (statementLog.isDebugEnabled()) &#123; return ConnectionLogger.newInstance(connection, statementLog, queryStack); &#125; else &#123; return connection; &#125;&#125; 最后的doQuery由SimpleExecutor代理来完成，该方法中有2个子流程，一个是SQL参数的设置，另一个是SQL查询操作和结果集的封装。 SimpleExecutor.doQuery()方法如下: 1234567891011121314@Overridepublic &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); /* 子流程1: SQL查询参数的设置 */ stmt = prepareStatement(handler, ms.getStatementLog()); /* 子流程2: SQL查询操作和结果集封装 */ return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125;&#125; 子流程1 SQL查询参数的设置首先获取数据库connection连接，然后准备statement，然后就设置SQL查询中的参数值。打开一个connection连接，在使用完后不会close，而是存储下来，当下次需要打开连接时就直接返回。 12345678910111213// SimpleExecutor类private Statement prepareStatement(StatementHandler handler, Log statementLog) throws SQLException &#123; Statement stmt; /* 获取Connection连接 */ Connection connection = getConnection(statementLog); /* 准备Statement */ stmt = handler.prepare(connection, transaction.getTimeout()); /* 设置SQL查询中的参数值 */ handler.parameterize(stmt); return stmt;&#125; 子流程2 SQL查询结果集的封装1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// SimpleExecutor类public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; PreparedStatement ps = (PreparedStatement) statement; // 执行查询操作 ps.execute(); // 执行结果集封装 return resultSetHandler.&lt;E&gt; handleResultSets(ps);&#125;// DefaultReseltSetHandler类public List&lt;Object&gt; handleResultSets(Statement stmt) throws SQLException &#123; ErrorContext.instance().activity("handling results").object(mappedStatement.getId()); final List&lt;Object&gt; multipleResults = new ArrayList&lt;Object&gt;(); int resultSetCount = 0; /** * 获取第一个ResultSet，同时获取数据库的MetaData数据，包括数据表列名、列的类型、类序号等。 * 这些信息都存储在了ResultSetWrapper中了 */ ResultSetWrapper rsw = getFirstResultSet(stmt); List&lt;ResultMap&gt; resultMaps = mappedStatement.getResultMaps(); int resultMapCount = resultMaps.size(); validateResultMapsCount(rsw, resultMapCount); while (rsw != null &amp;&amp; resultMapCount &gt; resultSetCount) &#123; ResultMap resultMap = resultMaps.get(resultSetCount); handleResultSet(rsw, resultMap, multipleResults, null); rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; String[] resultSets = mappedStatement.getResultSets(); if (resultSets != null) &#123; while (rsw != null &amp;&amp; resultSetCount &lt; resultSets.length) &#123; ResultMapping parentMapping = nextResultMaps.get(resultSets[resultSetCount]); if (parentMapping != null) &#123; String nestedResultMapId = parentMapping.getNestedResultMapId(); ResultMap resultMap = configuration.getResultMap(nestedResultMapId); handleResultSet(rsw, resultMap, null, parentMapping); &#125; rsw = getNextResultSet(stmt); cleanUpAfterHandlingResultSet(); resultSetCount++; &#125; &#125; return collapseSingleResultList(multipleResults); &#125; ResultSetWrapper 是 ResultSet 的包装类，调用 getFirstResultSet 方法获取第一个 ResultSet，同时获取数据库的 MetaData 数据，包括数据表列名、列的类型、类序号等，这些信息都存储在 ResultSetWrapper 类中了。然后调用handleResultSet 方法来来进行结果集的封装。 12345678910111213141516171819// DefaultResultSetHandler类private void handleResultSet(ResultSetWrapper rsw, ResultMap resultMap, List&lt;Object&gt; multipleResults, ResultMapping parentMapping) throws SQLException &#123; try &#123; if (parentMapping != null) &#123; handleRowValues(rsw, resultMap, null, RowBounds.DEFAULT, parentMapping); &#125; else &#123; if (resultHandler == null) &#123; DefaultResultHandler defaultResultHandler = new DefaultResultHandler(objectFactory); handleRowValues(rsw, resultMap, defaultResultHandler, rowBounds, null); multipleResults.add(defaultResultHandler.getResultList()); &#125; else &#123; handleRowValues(rsw, resultMap, resultHandler, rowBounds, null); &#125; &#125; &#125; finally &#123; // issue #228 (close resultsets) closeResultSet(rsw.getResultSet()); &#125;&#125; 这里调用handleRowValues方法进行结果值的设置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// DefaultResultSetHandler类public void handleRowValues(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler&lt;?&gt; resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException &#123; if (resultMap.hasNestedResultMaps()) &#123; ensureNoRowBounds(); checkResultHandler(); handleRowValuesForNestedResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping); &#125; else &#123; // 封装数据 handleRowValuesForSimpleResultMap(rsw, resultMap, resultHandler, rowBounds, parentMapping); &#125;&#125;private void handleRowValuesForSimpleResultMap(ResultSetWrapper rsw, ResultMap resultMap, ResultHandler&lt;?&gt; resultHandler, RowBounds rowBounds, ResultMapping parentMapping) throws SQLException &#123; DefaultResultContext&lt;Object&gt; resultContext = new DefaultResultContext&lt;Object&gt;(); skipRows(rsw.getResultSet(), rowBounds); while (shouldProcessMoreRows(resultContext, rowBounds) &amp;&amp; rsw.getResultSet().next()) &#123; ResultMap discriminatedResultMap = resolveDiscriminatedResultMap(rsw.getResultSet(), resultMap, null); Object rowValue = getRowValue(rsw, discriminatedResultMap); storeObject(resultHandler, resultContext, rowValue, parentMapping, rsw.getResultSet()); &#125;&#125;private Object getRowValue(ResultSetWrapper rsw, ResultMap resultMap) throws SQLException &#123; final ResultLoaderMap lazyLoader = new ResultLoaderMap(); // createResultObject为新创建的对象，数据表对应的类 Object rowValue = createResultObject(rsw, resultMap, lazyLoader, null); if (rowValue != null &amp;&amp; !hasTypeHandlerForResultObject(rsw, resultMap.getType())) &#123; final MetaObject metaObject = configuration.newMetaObject(rowValue); boolean foundValues = this.useConstructorMappings; if (shouldApplyAutomaticMappings(resultMap, false)) &#123; // 这里把数据填充进去，metaObject中包含了resultObject信息 foundValues = applyAutomaticMappings(rsw, resultMap, metaObject, null) || foundValues; &#125; foundValues = applyPropertyMappings(rsw, resultMap, metaObject, lazyLoader, null) || foundValues; foundValues = lazyLoader.size() &gt; 0 || foundValues; rowValue = (foundValues || configuration.isReturnInstanceForEmptyRow()) ? rowValue : null; &#125; return rowValue;&#125;private boolean applyAutomaticMappings(ResultSetWrapper rsw, ResultMap resultMap, MetaObject metaObject, String columnPrefix) throws SQLException &#123; List&lt;UnMappedColumnAutoMapping&gt; autoMapping = createAutomaticMappings(rsw, resultMap, metaObject, columnPrefix); boolean foundValues = false; if (autoMapping.size() &gt; 0) &#123; // 这里进行for循环调用，因为user表中总共有7列，所以也就调用7次 for (UnMappedColumnAutoMapping mapping : autoMapping) &#123; // 这里将esultSet中查询结果转换为对应的实际类型 final Object value = mapping.typeHandler.getResult(rsw.getResultSet(), mapping.column); if (value != null) &#123; foundValues = true; &#125; if (value != null || (configuration.isCallSettersOnNulls() &amp;&amp; !mapping.primitive)) &#123; // gcode issue #377, call setter on nulls (value is not 'found') metaObject.setValue(mapping.property, value); &#125; &#125; &#125; return foundValues;&#125; mapping.typeHandler.getResult会获取查询结果值的实际类型，比如我们user表中id字段为int类型，那么它就对应Java中的Integer类型，然后通过调用statement.getInt(“id”)来获取其int值，其类型为Integer。metaObject.setValue方法会把获取到的Integer值设置到Java类中的对应字段。 123456789101112131415161718// MetaObject类public void setValue(String name, Object value) &#123; PropertyTokenizer prop = new PropertyTokenizer(name); if (prop.hasNext()) &#123; MetaObject metaValue = metaObjectForProperty(prop.getIndexedName()); if (metaValue == SystemMetaObject.NULL_META_OBJECT) &#123; if (value == null &amp;&amp; prop.getChildren() != null) &#123; // don't instantiate child path if value is null return; &#125; else &#123; metaValue = objectWrapper.instantiatePropertyValue(name, prop, objectFactory); &#125; &#125; metaValue.setValue(prop.getChildren(), value); &#125; else &#123; objectWrapper.set(prop, value); &#125;&#125; metaValue.setValue方法最后会调用到Java类中对应数据域的set方法，这样也就完成了SQL查询结果集的Java类封装过程 3. MyBatis缓存 MyBatis提供查询缓存，用于减轻数据库压力，提高性能。MyBatis提供了一级缓存和二级缓存。 3.1 一级缓存 一级缓存是 SqlSession 级别的缓存，每个 SqlSession 对象都有一个哈希表用于缓存数据，不同 SqlSession 对象之间缓存不共享。 同一个 SqlSession 对象对象执行2遍相同的 SQL 查询，在第一次查询执行完毕后将结果缓存起来，这样第二遍查询就不用向数据库查询了， 直接返回缓存结果即可。MyBatis默认是开启一级缓存的。 简单说就是SQL语句作为key，查询结果作为value，根据key去查找value，如果查询语句相同就能直接返回value。 3.2 二级缓存 二级缓存是mapper 级别的缓存，二级缓存是跨 SqlSession 的，多个 SqlSession 对象可以共享同一个二级缓存。不同的 SqlSession 对象执行两次相同的 SQL 语句， 第一次会将查询结果进行缓存，第二次查询直接返回二级缓存中的结果即可。MyBatis 默认是不开启二级缓存的，可以在配置文件中使用如下配置来开启二级缓存： 123&lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt;&lt;/settings&gt; ​ 当SQL语句进行更新操作(删除/添加/更新)时，会清空对应的缓存，保证缓存中存储的都是最新的数据。 4. 参考https://www.cnblogs.com/dongying/p/4142476.html http://www.mybatis.org/mybatis-3/zh/getting-started.html]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro安全框架(三)---Shiro组件详解]]></title>
    <url>%2Fposts%2Ff8844037.html</url>
    <content type="text"><![CDATA[本文主要讲述了Shiro安全框架的各大组件及其作用，同时使用实例代码做出简单演示。 Shiro安全框架系列文章目录 Shiro安全框架(一)—什么是Shiro Shiro安全框架(二)—SpringBoot整合Shiro Shiro安全框架(三)—Shiro组件详解 源码下载：GItHub 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Authentication 用户认证1.1 身份和凭 需要提供身份和凭证给 Shiro。 Princirpals ：用户身份信息，是 Subject 标识信息，能够标识唯一 subject 。如电话、邮箱、身份证号码等。 Credentials : 凭证，就是密码，是只被subject知道的秘密值，可以是密码也可以是数字证书等。 Princirpals/Credentials的常见组合：账号+密码。在 Shiro 中使用UsernamePasswordToken来指定身份信息和凭证。 1.2 认证流程 1.把用户输入的账号密码封装成 Token 给 Subject 2.Subject 把 Token 给 SecurityManager 3.SecurityManager 调用 Authenticator 认证器 4.Authenticator 根据配置的策略去调用 对应Realms 获取相对应的数据 5.最后返回认证结果 1.3 实例代码1. Controller获取用户输入的账号密码 然后交给Subject去登录 123456789101112131415@RequestMapping(value = "/login")public String login(HttpServletRequest request,User inuser,String uname,String upwd) &#123; System.out.println("用户名和密码是" + uname + upwd + " User--&gt;" + inuser.toString()); UsernamePasswordToken usernamePasswordToken = new UsernamePasswordToken(uname,upwd); Subject subject = SecurityUtils.getSubject(); try &#123; //登录 subject.login(usernamePasswordToken); User user = (User) subject.getPrincipal(); request.getSession().setAttribute("user", user); return "index"; &#125; catch (AuthenticationException e) &#123; return "login"; &#125;&#125; 根据前面的步骤，Subject 获取到 Token 后会交给SecurityManager，最后 Authenticator 去 Realms 中获取数据并进行登录认证。 2. Realm123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class AuthRealmTest extends AuthorizingRealm &#123; @Autowired private UserService userService; /** * 授权 * * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; //1.获取session中的用户 User user = (User) principalCollection.fromRealm(this.getClass().getName()).iterator().next(); //2.去数据库查询当前user的权限 List&lt;String&gt; strings = userService.selectPermissionByUserId(user.getUid()); //3.将权限放入shiro中. SimpleAuthorizationInfo simpleAuthorizationInfo = new SimpleAuthorizationInfo(); simpleAuthorizationInfo.addStringPermissions(strings); //4.返回授权信息AuthorizationInfo return simpleAuthorizationInfo; &#125; /** * 登录认证 * * @param authenticationToken * @return * @throws AuthenticationException ex * 密码校验在&#123;@link CredentialsMatcherTest#doCredentialsMatch(AuthenticationToken, AuthenticationInfo)&#125; */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; //1.将用户输入的token 就是authenticationToken强转为UsernamePasswordToken UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) authenticationToken; //2.获取用户名 String username = usernamePasswordToken.getUsername(); //3.数据库中查询出user对象 User user = userService.findUserByName(username); //4.查询出这个user的权限 Set&lt;Role&gt; roles = user.getRoles(); for (Role r : roles) &#123; Set&lt;Permission&gt; permissions = r.getPermissions(); for (Permission p : permissions) &#123; String permission = p.getPermission(); System.out.println("权限--》" + permission); &#125; &#125; //5.返回认证信息AuthenticationInfo 这里是没进行密码校验的 密码校验在CredentialsMatcherTest类中 return new SimpleAuthenticationInfo(user, user.getUpwd(), this.getClass().getName()); &#125;&#125; 其中 doGetAuthenticationInfo方法中的Token就是用户前面输入的账号密码，我们还需要些一个类用来校验密码： 123456789101112131415161718192021222324252627/** * 密码校验类 */public class CredentialsMatcherTest extends SimpleCredentialsMatcher &#123; /** * 校验密码 * * @param token * @param info * @return 密码校验结果 * &#123;@link AuthRealmTest#doGetAuthenticationInfo(AuthenticationToken)&#125; */ @Override public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) &#123; //1.强转 UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) token; //2.获取用户输入的密码 char[] password = usernamePasswordToken.getPassword(); String pwd = new String(password); //3.获取数据库中的真实密码 //这个info就是前面AuthRealmTest类中的doGetAuthenticationInfo返回的info String relPwd = (String) info.getCredentials(); //4.返回校验结果 return this.equals(pwd, relPwd); &#125;&#125; 到这里就算是认证成功了，但是还没有授权。 1.4 小结认证流程： 1.用户输入账号密码，Controller中调subject.login去认证 2.认证方法就是自定义realm中的doGetAuthenticationInfo 3.认证过程中需要校验密码，就是自定义的CredentialsMatcherTest 2. RealmRealm 是一个接口，在接口中定义了 Token 获得认证信息的方法，Shiro 内实现了一系列的 Realm，这些不同的Realm 提供了不同的功能，AuthenticatingRealm实现了获取身份信息的功能，AuthorizingRealm实现了获取权限信息的功能且继承了AuthenticatingRealm,自定义realm时要继承AuthorizingRealm,这样既可以提供身份认证的自定义方法，也可以实现授权的自定义方法。shiro只实现了功能，并不维护数据，所以自定义realm中也只是从数据库中查询数据然后和用户输入进行对比，其中密码校验是单独的 2.1 实例代码自定义Realm，继承AuthorizingRealm并实现授权方法doGetAuthorizationInfo和身份认证方法doGetAuthenticationInfo。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class AuthRealm extends AuthorizingRealm &#123; @Autowired private UserServiceImpl userService; /** * 授权 * * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; //获取session中的用户 User user = (User) principalCollection.fromRealm(this.getClass().getName()).iterator().next(); //查询权限 List&lt;String&gt; strings = userService.selectPermissionByUserId(user.getUid()); SimpleAuthorizationInfo simpleAuthorizationInfo = new SimpleAuthorizationInfo(); //将权限放入shiro中. simpleAuthorizationInfo.addStringPermissions(strings);// System.out.println("添加时的权限" + permission.toString()); System.out.println("-------------授权-------------"); return simpleAuthorizationInfo; &#125; /** * 完成身份认证并返回认证信息 * 认证失败则返回空 * * @param authenticationToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; //用户输入的token UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) authenticationToken; String username = usernamePasswordToken.getUsername(); User user = userService.findUserByName(username); //放入shiro.调用CredentialsMatcher检验密码 System.out.println("获取到的密码" + user.getUpwd());// ByteSource salt = ByteSource.Util.bytes(user.getSalt());// System.out.println(salt); return new SimpleAuthenticationInfo(user, user.getUpwd(),this.getClass().getName()); &#125;&#125; 3. Authentication Strategy 认证策略在 Shiro 中有三种认证策略： AtLeatOneSuccessfulStrategy(默认策略) :只要有一个Realm验证成功即可，和FirstSuccessfulStrategy不同，将返回所有Realm身份校验成功的认证信息。 FirstSuccessfulStrategy :只要有一个Realm验证成功即可，只返回第一个Realm身份验证成功的认证信息，其他的忽略。 AllSuccessfulStrategy :所有Realm验证成功才算成功，且返回所有Realm身份认证成功的认证信息，如 果有一个失败就失败了。 具体配置 123456789101112/** * 认证策略配置 * * @return modularRealmAuthenticator */@Beanpublic ModularRealmAuthenticator modularRealmAuthenticator() &#123; ModularRealmAuthenticator modularRealmAuthenticator = new ModularRealmAuthenticator(); AuthenticationStrategy atLeastOneSuccessfulStrategy = new AtLeastOneSuccessfulStrategy(); modularRealmAuthenticator.setAuthenticationStrategy(atLeastOneSuccessfulStrategy); return modularRealmAuthenticator;&#125; 4. CredentialsMatcher 凭证匹配器1. CredentialsMatcherHash自定义凭证匹配器,用来校验密码，其中数据库保存的密码是Hash后的，匹配是也需要Hash后进行对比。 1234567891011121314151617public class CredentialsMatcher extends SimpleCredentialsMatcher &#123; @Override public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) &#123; //强转 获取token UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) token; //获取用户输入的密码 char[] password = usernamePasswordToken.getPassword(); String inputPassword = new String(password); Md5Hash md5Hash = new Md5Hash(inputPassword); //获取数据库中的密码 String realPassword = (String) info.getCredentials(); System.out.println("输入的密码"+md5Hash); System.out.println("数据库中的密码"+realPassword); //对比 return this.equals(md5Hash, realPassword); &#125;&#125; 2. CredentialsMatcherLimit同时可以在凭证匹配器中设定登录次数，多次登录失败后限制一段时间内不让登录。 123456789101112131415161718192021222324252627282930313233public class CredentialsMatcherLimit extends SimpleCredentialsMatcher &#123; /** * 当前登录次数 放在缓存中10分钟后清空 即连续登录失败后要等一段时间 */ private AtomicInteger tryTime; /** * 短时间内最大登录次数 */ private static final int MAX_TIMES = 5; @Override public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) &#123; if (tryTime.get() &lt; MAX_TIMES) &#123; int currentTime = tryTime.getAndIncrement(); System.out.println("登录次数：" + currentTime); //强转 获取token UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) token; //获取用户输入的密码 char[] password = usernamePasswordToken.getPassword(); String inputPassword = new String(password); Md5Hash md5Hash = new Md5Hash(inputPassword); //获取数据库中的密码 String realPassword = (String) info.getCredentials(); System.out.println("输入的密码" + md5Hash); System.out.println("数据库中的密码" + realPassword); //对比 return this.equals(md5Hash, realPassword); &#125; else &#123; System.out.println("登录次数过多，请稍后重试"); return false; &#125; &#125;&#125; 5. Authorization 授权 5.1 简介 授权 ：给身份认证通过的人，授予某些权限。 权限粒度 ：分为粗粒度和细粒度， 粗粒度 ：对某张表的操作，如对user表的crud。 细粒度 ：对表中某条记录的操作，如：只能对user表中ID为1的记录进行curd，shiro一般管理的是粗粒度的权限，比如：菜单、URL，细粒度的权限控制通过业务来实现。 角色 ：权限的集合 权限表现规则：格式: 资源:操作:实例(可以用通配符表示) user:add 对user有add权限 user:* 对user有所有操作 user:add:1 对ID为1的user有add操作 5.2 流程 Shiro中权限检测方式有三种： 1.编程式 业务代码前手动检测 subject.checkPermission(&quot;delete&quot;);/subject.hasRole(&quot;admin&quot;); 2.注解式 方法上添加注解 @RequiresPermissions(value = &quot;add&quot;)/@RequiresRoles(&quot;admin&quot;) 3.标签式 写在html中 &lt;p shiro:hasPermission=&quot;add&quot;&gt;添加用户&lt;/p&gt; 需要在html页面中引入 xmlns:shiro=&quot;http://www.pollix.at/thymeleaf/shiro&quot; 具体流程 1.获取 Subject 主体 2.判断 Subject 主体是否通过认证 2.Subject 调用 isPermitted()/hasRole() 方法开始授权 3.SecurityManager执行授权，通过 ModularRealmAuthorizer 执行授权 4.调用自定义 Realm 的授权方法：doGetAuthorizationInfo 5.返回授权结果 实例代码1234567891011121314151617181920 /** * 授权 * * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; //1.获取principalCollection中的用户 User user = (User) principalCollection.fromRealm(this.getClass().getName()).iterator().next(); //2.通过数据库查询当前userde权限 List&lt;String&gt; permissions = userService.selectPermissionByUserId(user.getUid()); SimpleAuthorizationInfo simpleAuthorizationInfo = new SimpleAuthorizationInfo(); //3.将权限放入shiro中. simpleAuthorizationInfo.addStringPermissions(permissions);// System.out.println("添加时的权限" + permission.toString()); System.out.println("-------------授权-------------"); //4.返回 return simpleAuthorizationInfo; &#125; 6. 散列算法(加密)6.1 简介为了提高应用系统的安全性，在身份认证过程中往往会涉及加密，这里主要关注shiro提供的密码服务模块；通过shiro进行散列算法操作，常见的有两个MD5，SHA-1等。 如1111的MD5为b59c67bf196a4758191e42f76670ceba,但是这个b59c67bf196a4758191e42f76670ceba很容易就会被破解，轻松就能获取到加密前的数据。 6.2 加盐但是1111+userName进行加密，这样就不容易被破解了，破解难度增加。 例如: qwer的MD5为962012d09b8170d912f0669f6d7d9d07qwer加盐illusory后的MD5为6aee9c0e35ad7a12e59ff67b663a32ca 用户在注册的时候就把加密后的密码和盐值存到数据库，用户登录时就先根据用户名查询盐值，然后把用户输入的密码加密后在和数据库中的密码做对比。 代码如下：自定义密码校验,shiro也提供了一下内置的加密密码校验器 1.根据name查询user 然后获取到盐值2.然后把输入的密码加密3.最后在于数据库中的密码对比 1234567891011121314151617181920212223242526public class CredentialsMatcherHash extends SimpleCredentialsMatcher &#123; @Autowired UserService service; @Override public boolean doCredentialsMatch(AuthenticationToken token, AuthenticationInfo info) &#123; //强转 获取token UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) token; //获取用户输入的密码 char[] password = usernamePasswordToken.getPassword(); String inputPassword = new String(password); String username = usernamePasswordToken.getUsername(); User userByName = service.findUserJustByName(username); String salt = userByName.getSalt(); //这个盐值是从数据库查出来的 Md5Hash md5Hash = new Md5Hash(inputPassword, salt); String inputMD5Hash = new String(String.valueOf(md5Hash)); //获取数据库中的密码 String realPassword = (String) info.getCredentials(); System.out.println("输入的密码" + inputPassword); System.out.println("输入的密码加密" + md5Hash); System.out.println("数据库中的密码" + realPassword); //对比 return this.equals(inputMD5Hash, realPassword); &#125;&#125; 7. 缓存每次检查都会去数据库中获取权限，这样效率很低，可以通过设置缓存来解决问题。如Ehcache 或者 Redis。 这里使用Redis。 7.1 引入依赖12345&lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 7.2 重写方法使用 Redis 作为缓存需要 Shiro重写 Cache、cacheManager CacheManager123456789101112131415161718/** * Cachemanager * * @author illusoryCloud */public class ShiroRedisCacheManager extends AbstractCacheManager &#123; private RedisTemplate&lt;byte[], byte[]&gt; redisTemplate; public ShiroRedisCacheManager(RedisTemplate redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; //为了个性化配置redis存储时的key，我们选择了加前缀的方式，所以写了一个带名字及redis操作的构造函数的Cache类 @Override protected Cache createCache(String name) throws CacheException &#123; return new ShiroRedisCache(redisTemplate, name); &#125;&#125; RedisCache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132/** * Shiro缓存 * * @author illusoryCloud */public class ShiroRedisCache&lt;K, V&gt; implements Cache&lt;K, V&gt; &#123; /** * redis操作对象 */ private RedisTemplate redisTemplate; /** * key 前缀 */ private String prefix = "shiro_redis"; public String getPrefix() &#123; return prefix + ":"; &#125; public void setPrefix(String prefix) &#123; this.prefix = prefix; &#125; public ShiroRedisCache(RedisTemplate redisTemplate) &#123; this.redisTemplate = redisTemplate; &#125; public ShiroRedisCache(RedisTemplate redisTemplate, String prefix) &#123; this(redisTemplate); this.prefix = prefix; &#125; /** * get方法 * @param k redis中的key * @return redis中的value * @throws CacheException */ @Override public V get(K k) throws CacheException &#123; if (k == null) &#123; return null; &#125; byte[] bytes = getBytesKey(k); return (V) redisTemplate.opsForValue().get(bytes); &#125; /** * put方法 * @param k key * @param v value * @return * @throws CacheException */ @Override public V put(K k, V v) throws CacheException &#123; if (k == null || v == null) &#123; return null; &#125; byte[] bytes = getBytesKey(k); redisTemplate.opsForValue().set(bytes, v); return v; &#125; /** * delete方法 * @param k * @return * @throws CacheException */ @Override public V remove(K k) throws CacheException &#123; if (k == null) &#123; return null; &#125; byte[] bytes = getBytesKey(k); V v = (V) redisTemplate.opsForValue().get(bytes); redisTemplate.delete(bytes); return v; &#125; /** * 清除数据库 * @throws CacheException */ @Override public void clear() throws CacheException &#123; redisTemplate.getConnectionFactory().getConnection().flushDb(); &#125; @Override public int size() &#123; return redisTemplate.getConnectionFactory().getConnection().dbSize().intValue(); &#125; /** * 查询所有的key * key * @return */ @Override public Set&lt;K&gt; keys() &#123; byte[] bytes = (getPrefix() + "*").getBytes(); Set&lt;byte[]&gt; keys = redisTemplate.keys(bytes); Set&lt;K&gt; sets = new HashSet&lt;&gt;(); for (byte[] key : keys) &#123; sets.add((K) key); &#125; return sets; &#125; /** * 查询所有的value * @return */ @Override public Collection&lt;V&gt; values() &#123; Set&lt;K&gt; keys = keys(); List&lt;V&gt; values = new ArrayList&lt;&gt;(keys.size()); for (K k : keys) &#123; values.add(get(k)); &#125; return values; &#125; private byte[] getBytesKey(K key) &#123; String prekey = this.getPrefix() + key; return prekey.getBytes(); &#125; 7.3 Shiro配置缓存管理器在 ShiroConfiguration 中配置 ShiroRedisCacheManager。 1234567891011121314151617181920212223242526 @Bean public ShiroRedisCacheManager cacheManager(RedisTemplate redisTemplate) &#123; return new ShiroRedisCacheManager(redisTemplate); &#125; //配置核心安全事务管理器 @Bean(name = "securityManager") public SecurityManager securityManager(@Qualifier("authRealm") AuthRealm authRealm, @Qualifier("authRealm2") AuthRealm authRealm2, @Qualifier("authRealm3") AuthRealm authRealm3 , RedisTemplate&lt;Object, Object&gt; template) &#123; System.err.println("----------------------------shiro已经加载---------------------------"); DefaultWebSecurityManager manager = new DefaultWebSecurityManager(); //配置缓存 必须放在realm前面 manager.setCacheManager(cacheManager(template)); //配置两个测试一下认证策略AllSuccessfulStrategy// manager.setRealm(authRealm);// manager.setRealm(authRealm2); //测试一下密码加密 manager.setRealm(authRealm3); manager.setSessionManager(sessionManager());// manager.setCacheManager(ehCacheManager); return manager; &#125; 到这里就ok了 Shiro 在认证时会首先去 Redis 缓存中查询，缓存中没有才会去去查询数据库。 8. SessionShiro 中的 Session 特性 基于POJO/J2SE：shiro中session相关的类都是基于接口实现的简单的java对象（POJO），兼容所有java对象的配置方式，扩展也更方便，完全可以定制自己的会话管理功能 。 简单灵活的会话存储/持久化：因为shiro中的session对象是基于简单的java对象的，所以你可以将session存储在任何地方，例如，文件，各种数据库，内存中等。 容器无关的集群功能：shiro中的session可以很容易的集成第三方的缓存产品完成集群的功能。例如，Ehcache + Terracotta, Coherence, GigaSpaces等。你可以很容易的实现会话集群而无需关注底层的容器实现。 异构客户端的访问：可以实现web中的session和非web项目中的session共享。 会话事件监听：提供对对session整个生命周期的监听。 保存主机地址：在会话开始session会存用户的ip地址和主机名，以此可以判断用户的位置。 会话失效/过期的支持：用户长时间处于不活跃状态可以使会话过期，调用touch()方法，可以主动更新最后访问时间，让会话处于活跃状态。 透明的Web支持：shiro全面支持Servlet 2.5中的session规范。这意味着你可以将你现有的web程序改为shiro会话，而无需修改代码。 单点登录的支持：shiro session基于普通java对象，使得它更容易存储和共享，可以实现跨应用程序共享。可以根据共享的会话，来保证认证状态到另一个程序。从而实现单点登录。 8.2 SessionListener123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 监听session变化 * * @author illusoryCloud */public class ShiroSessionListener implements SessionListener &#123; /** * 统计在线人数 * juc包下线程安全自增 */ private final AtomicInteger sessionCount = new AtomicInteger(0); /** * 会话创建时触发 * * @param session */ @Override public void onStart(Session session) &#123; //会话创建，在线人数加一 sessionCount.incrementAndGet(); &#125; /** * 退出会话时触发 * * @param session */ @Override public void onStop(Session session) &#123; //会话退出,在线人数减一 sessionCount.decrementAndGet(); &#125; /** * 会话过期时触发 * * @param session */ @Override public void onExpiration(Session session) &#123; //会话过期,在线人数减一 sessionCount.decrementAndGet(); &#125; /** * 获取在线人数使用 * * @return */ public AtomicInteger getSessionCount() &#123; return sessionCount; &#125;&#125; 8.3 ShiroConfiguration 配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * 配置session监听 * * @return */ @Bean("sessionListener") public ShiroSessionListener sessionListener() &#123; ShiroSessionListener sessionListener = new ShiroSessionListener(); return sessionListener; &#125; /** * 配置会话ID生成器 * * @return */ @Bean public SessionIdGenerator sessionIdGenerator() &#123; return new JavaUuidSessionIdGenerator(); &#125; /** * SessionDAO的作用是为Session提供CRUD并进行持久化的一个shiro组件 * MemorySessionDAO 直接在内存中进行会话维护 * EnterpriseCacheSessionDAO 提供了缓存功能的会话维护，默认情况下使用MapCache实现，内部使用ConcurrentHashMap保存缓存的会话。 * * @return */ @Bean public SessionDAO sessionDAO() &#123; EnterpriseCacheSessionDAO enterpriseCacheSessionDAO = new EnterpriseCacheSessionDAO(); //使用ehCacheManager enterpriseCacheSessionDAO.setCacheManager(cacheManager(new RedisTemplate())); //设置session缓存的名字 默认为 shiro-activeSessionCache enterpriseCacheSessionDAO.setActiveSessionsCacheName("shiro-activeSessionCache"); //sessionId生成器 enterpriseCacheSessionDAO.setSessionIdGenerator(sessionIdGenerator()); return enterpriseCacheSessionDAO; &#125; @Bean("sessionManager") public SessionManager sessionManager() &#123; DefaultWebSessionManager sessionManager = new DefaultWebSessionManager(); Collection&lt;SessionListener&gt; listeners = new ArrayList&lt;SessionListener&gt;(); //配置监听 listeners.add(sessionListener()); sessionManager.setSessionListeners(listeners); sessionManager.setSessionIdCookie(sessionIdCookie()); sessionManager.setSessionDAO(sessionDAO()); //全局会话超时时间（单位毫秒），默认30分钟 暂时设置为10秒钟 用来测试 sessionManager.setGlobalSessionTimeout(1800000); //是否开启删除无效的session对象 默认为true sessionManager.setDeleteInvalidSessions(true); //是否开启定时调度器进行检测过期session 默认为true sessionManager.setSessionValidationSchedulerEnabled(true); //设置session失效的扫描时间, 清理用户直接关闭浏览器造成的孤立会话 默认为 1个小时 //设置该属性 就不需要设置 ExecutorServiceSessionValidationScheduler 底层也是默认自动调用ExecutorServiceSessionValidationScheduler //暂时设置为 5秒 用来测试 sessionManager.setSessionValidationInterval(3600000); return sessionManager; &#125; /** * 配置保存sessionId的cookie * 注意：这里的cookie 不是上面的记住我 cookie 记住我需要一个cookie session管理 也需要自己的cookie * * @return */ @Bean("sessionIdCookie") public SimpleCookie sessionIdCookie() &#123; //这个参数是cookie的名称 SimpleCookie simpleCookie = new SimpleCookie("sid"); //setcookie的httponly属性如果设为true的话，会增加对xss防护的安全系数。它有以下特点： //setcookie()的第七个参数 //设为true后，只能通过http访问，javascript无法访问 //防止xss读取cookie simpleCookie.setHttpOnly(true); simpleCookie.setPath("/"); //maxAge=-1表示浏览器关闭时失效此Cookie simpleCookie.setMaxAge(-1); return simpleCookie; &#125; 9. RememberMeShiroConfiguration 配置123456789101112131415@Beanpublic RememberMeManager rememberMeManager() &#123; CookieRememberMeManager cookieRememberMeManager = new CookieRememberMeManager(); cookieRememberMeManager.setCookie(rememberMeCookie()); //rememberMe cookie加密的密钥 建议每个项目都不一样 默认AES算法 密钥长度(128 256 512 位) cookieRememberMeManager.setCipherKey(Base64.decode("2AvVhdsgUs0FSA3SDFAdag==")); return cookieRememberMeManager;&#125;@Beanpublic SimpleCookie rememberMeCookie() &#123; SimpleCookie simpleCookie = new SimpleCookie("rememberMe"); simpleCookie.setMaxAge(259200); return simpleCookie;&#125; 2. Controller前端页面传过来一个Boolean变量，然后存放在UsernamePasswordToken中就可以了,不过User对象因为要序列化所以要实现Serializable接口，同样的还有User对象引用的permission和role对象都要实现这个。 123456789101112131415@RequestMapping(value = "/login")public String login(HttpServletRequest request, User inuser, String uname, String upwd,Boolean rememberMe) &#123; System.out.println("用户名和密码是" + uname + upwd + " User--&gt;" + inuser.toString()); UsernamePasswordToken usernamePasswordToken = new UsernamePasswordToken(uname, upwd, rememberMe); Subject subject = SecurityUtils.getSubject(); try &#123; //登录 subject.login(usernamePasswordToken); User user = (User) subject.getPrincipal(); return "index"; &#125; catch (AuthenticationException e) &#123; usernamePasswordToken.clear(); return "login"; &#125;&#125; 10. 参考https://blog.csdn.net/yangwenxue_admin/article/details/73936803 官方文档：http://shiro.apache.org/documentation.html]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro安全框架(二)---SpringBoot整合Shiro]]></title>
    <url>%2Fposts%2Ffd462737.html</url>
    <content type="text"><![CDATA[本文主要介绍了如何在SpringBoot项目中整合Shiro安全框架，包括详细步骤和具体实例代码。 Shiro安全框架系列文章目录 Shiro安全框架(一)—什么是Shiro Shiro安全框架(二)—SpringBoot整合Shiro Shiro安全框架(三)—Shiro组件详解 源码下载：GItHub 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 添加依赖普通项目引入方式： 123456&lt;!--shiro--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;/dependency&gt; SpringBoot引入方式： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt;&lt;/dependency&gt; 2. 数据准备2.1 Entity一共有三个对象，User用户，Role角色，Permission权限。 将权限分配给角色，不同的角色拥有不同的权限，然后给用户分配不同的角色，这样就达到了权限管理的效果。 这里用了lombok插件 编译时自动生成getter/setter等方法 1234567891011121314151617181920212223242526272829303132333435/** * @author illusory * 权限实体类 */@Datapublic class Permission &#123; private Integer pid; private String permission; private Set&lt;Role&gt; roles = new HashSet&lt;&gt;();&#125;/** * @author illusory * 角色实体类 */@Datapublic class Role &#123; private Integer rid; private String rname; private Set&lt;User&gt; users = new HashSet&lt;&gt;(); private Set&lt;Permission&gt; permissions = new HashSet&lt;&gt;();&#125;/** * @author illusory * 用户实体类 */@Datapublic class User &#123; private Integer uid; private String uname; private String upwd; private String salt; private Set&lt;Role&gt; roles=new HashSet&lt;&gt;();&#125; 2.2 DataBase这里主要涉及到五张表:用户表,角色表(用户所拥有的角色),权限表(角色所涉及到的权限),用户-角色表(用户和角色是多对多的),角色-权限表(角色和权限是多对多的).表结构建立的sql语句如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253-- 新建一个数据库CREATE DATABASE shiro;USE shiro;-- 用户表DROP TABLE IF EXISTS USER;CREATE TABLE USER(id INT PRIMARY KEY AUTO_INCREMENT,NAME VARCHAR(4),pwd VARCHAR(8) );INSERT INTO USER VALUES(NULL,&apos;张三&apos;,&apos;qwer&apos;),(NULL,&apos;李四&apos;,&apos;qwer&apos;);-- 权限表DROP TABLE IF EXISTS permission;CREATE TABLE permission(id INT PRIMARY KEY AUTO_INCREMENT,permission VARCHAR(10));INSERT INTO permission VALUES(NULL,&apos;add&apos;),(NULL,&apos;delete&apos;),(NULL,&apos;update&apos;),(NULL,&apos;query&apos;);-- 角色表DROP TABLE IF EXISTS role;CREATE TABLE role(id INT PRIMARY KEY AUTO_INCREMENT,NAME VARCHAR(10));INSERT INTO role VALUES(NULL,&apos;admin&apos;),(NULL,&apos;customer&apos;);-- 权限-角色表DROP TABLE IF EXISTS permission_role;CREATE TABLE permission_role(pid INT(3),CONSTRAINT fk_permission FOREIGN KEY(pid) REFERENCES permission(id),rid INT(3),CONSTRAINT fk_role FOREIGN KEY(rid) REFERENCES role(id));-- 管理员有4个权限 用户只有查询权限INSERT INTO permission_role VALUES(1,1),(2,1),(3,1),(4,1),(4,2);-- 用户-角色表DROP TABLE IF EXISTS user_role;CREATE TABLE user_role(uid INT(3),CONSTRAINT fk_user FOREIGN KEY(uid) REFERENCES USER(id),rid INT(3),CONSTRAINT fk_roles FOREIGN KEY(rid) REFERENCES role(id));-- 张三为管理员 李四为用户INSERT INTO user_role VALUES(1,1),(2,2); 3 Mapper3.1 UserMapper.java1234567public interface UserMapper &#123; User findUserByName(String name); User findUserJustByName(String name); List&lt;String&gt; selectPermissionByUserId(Integer id);&#125; 3.2 UserMapper.xml12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.example.shiro.mapper.UserMapper"&gt; &lt;resultMap type="User" id="userMap"&gt; &lt;id property="uid" column="id" /&gt; &lt;result property="uname" column="name" /&gt; &lt;result property="upwd" column="pwd" /&gt; &lt;collection property="roles" ofType="Role"&gt; &lt;id property="rid" column="id" /&gt; &lt;result property="rname" column="name" /&gt; &lt;collection property="permissions" ofType="Permission"&gt; &lt;id property="pid" column="id" /&gt; &lt;result property="permission" column="permission" /&gt; &lt;/collection&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id="findUserByName" parameterType="string" resultMap="userMap"&gt; SELECT u.*,r.*,p.* FROM USER u INNER JOIN user_role ur ON ur.uid = u.id INNER JOIN role r ON r.id = ur.rid INNER JOIN permission_role pr ON pr.rid = r.id INNER JOIN permission p ON pr.pid = p.id WHERE u.name = #&#123;name&#125;; &lt;/select&gt; &lt;select id="selectPermissionByUserId" parameterType="integer" resultType="string"&gt;SELECT permission FROM permission p INNER JOIN permission_role pr ON p.id=pr.pidINNER JOIN user_role ur ON ur.rid=pr.ridWHERE ur.uid=#&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt; 4. Service4.1 UserService1234567public interface UserService &#123; User findUserByName(String name); User findUserJustByName(String name); List&lt;String&gt; selectPermissionByUserId(Integer id);&#125; 4.2 UserServiceImpl1234567891011121314151617181920@Servicepublic class UserServiceImpl implements UserService &#123; @Resource private UserMapper userMapper; @Override public User findUserByName(String name) &#123; return userMapper.findUserByName(name); &#125; @Override public User findUserJustByName(String name) &#123; return userMapper.findUserJustByName(name); &#125; @Override public List&lt;String&gt; selectPermissionByUserId(Integer id) &#123; return userMapper.selectPermissionByUserId(id); &#125;&#125; 5. Shiro配置(重点)Shiro中唯一需要配置的就是Realm,完成根据用户名去数据库的查询,并且将用户信息放入Shiro中。 5.1 Realm12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * @author illusory */public class AuthRealm extends AuthorizingRealm &#123; @Autowired private UserServiceImpl userService; /** * 授权 * * @param principalCollection * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; // 1.获取principalCollection中的用户 User user = (User) principalCollection.fromRealm(this.getClass().getName()).iterator().next(); // 2.通过数据库查询当前userde权限 List&lt;String&gt; permissions = userService.selectPermissionByUserId(user.getUid()); SimpleAuthorizationInfo simpleAuthorizationInfo = new SimpleAuthorizationInfo(); // 3.将权限放入shiro中. simpleAuthorizationInfo.addStringPermissions(permissions); System.out.println("-------------授权-------------"); // 4.返回 return simpleAuthorizationInfo; &#125; /** * 完成身份认证并返回认证信息 * 认证失败则返回空 * * @param authenticationToken * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; // 1.用户输入的token UsernamePasswordToken usernamePasswordToken = (UsernamePasswordToken) authenticationToken; String username = usernamePasswordToken.getUsername(); User user = userService.findUserByName(username); System.out.println("获取到的密码" + user.getUpwd()); // 2.返回 return new SimpleAuthenticationInfo(user, user.getUpwd(), this.getClass().getName()); &#125;&#125; 5.2 Bean注册1. ShiroRealm将实现好的 ShiroRealm 注册为Bean，并初始化 WebSecurityManager 1234567891011121314@Configurationpublic class ShiroConfiguration &#123; @Bean public Realm realm() &#123; return new AuthRealm(); &#125; @Bean public DefaultWebSecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); securityManager.setRealm(realm()); return securityManager; &#125;&#125; 2. URL配置12345678910111213141516171819202122232425262728293031323334353637383940@Configurationpublic class ShiroConfiguration &#123; @Bean(name = "shiroFilterFactoryBean ") public ShiroFilterFactoryBean shiroFilterFactoryBean(@Qualifier("securityManager") SecurityManager manager) &#123; ShiroFilterFactoryBean bean = new ShiroFilterFactoryBean(); bean.setSecurityManager(manager); //1.定义URL拦截链 LinkedHashMap&lt;String, String&gt; filterChainDefinitionMap = new LinkedHashMap&lt;&gt;(); // authc:所有url都必须认证通过才可以访问; anon:所有url都都可以匿名访问 filterChainDefinitionMap.put("/login.*", "anon"); filterChainDefinitionMap.put("/logout*", "anon"); filterChainDefinitionMap.put("/hello", "anon"); filterChainDefinitionMap.put("/defaultKaptcha", "anon"); filterChainDefinitionMap.put("/index.*", "authc"); bean.setFilterChainDefinitionMap(filterChainDefinitionMap); //2.配置用于登录的url和登录成功的url bean.setLoginUrl("/login"); bean.setSuccessUrl("/index"); bean.setUnauthorizedUrl("/403"); return bean; &#125; //url配置 @Bean public ShiroFilterChainDefinition shiroFilterChainDefinition() &#123; DefaultShiroFilterChainDefinition chainDefinition = new DefaultShiroFilterChainDefinition(); // logged in users with the 'admin' role chainDefinition.addPathDefinition("/admin/**", "authc, roles[admin]"); // logged in users with the 'document:read' permission chainDefinition.addPathDefinition("/docs/**", "authc, perms[document:read]"); // all other paths require a logged in user chainDefinition.addPathDefinition("/**", "authc"); return chainDefinition; &#125;&#125; 3. 404问题123456789101112131415161718@Configurationpublic class ShiroConfiguration &#123;/** * 解决spring aop和注解配置一起使用的bug。如果您在使用shiro注解配置的同时，引入了spring aop的starter， * 会有一个奇怪的问题，导致shiro注解的请求，不能被映射，需加入这个配置 */ @Bean public static DefaultAdvisorAutoProxyCreator getDefaultAdvisorAutoProxyCreator() &#123; DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); /** * setUsePrefix(false)用于解决一个奇怪的bug。在引入spring aop的情况下。 * 在@Controller注解的类的方法中加入@RequiresRole等shiro注解，会导致该方法无法映射请求，导致返回404。 * 加入这项配置能解决这个bug */ defaultAdvisorAutoProxyCreator.setUsePrefix(true); return defaultAdvisorAutoProxyCreator; &#125;&#125; 6. 页面6.1 login.html1234567891011121314&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;用户登陆&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form&gt; 用户名:&lt;input type="text" name="uname"&gt;&lt;br/&gt; 密码:&lt;input type="password" name="upwd"&gt;&lt;br/&gt; &lt;input type="submit" value="登陆"&gt;&lt;br/&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 6.2 index.html123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html xmlns:th="http://www.thymeleaf.org" xmlns:shiro="http://www.pollix.at/thymeleaf/shiro"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;首页&lt;/title&gt;&lt;/head&gt;&lt;body&gt;欢迎您，&lt;span th:text="$&#123;user.uname&#125;"&gt;&lt;/span&gt;&lt;div&gt; &lt;p shiro:hasPermission="add"&gt;添加用户&lt;/p&gt; &lt;p shiro:hasPermission="delete"&gt;删除用户&lt;/p&gt; &lt;p shiro:hasPermission="update"&gt;更新用户&lt;/p&gt; &lt;p shiro:hasPermission="query"&gt;查询用户&lt;/p&gt;&lt;/div&gt;&lt;a th:href="@&#123;logout&#125;"&gt;点我注销&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 7. Controller1. UserController12345678910111213141516171819202122232425262728@Controllerpublic class UserController &#123; @RequestMapping(value = "/login") public String login(HttpServletRequest request, User inuser, String uname, String upwd) &#123; UsernamePasswordToken usernamePasswordToken = new UsernamePasswordToken(uname, upwd); Subject subject = SecurityUtils.getSubject(); try &#123; //登录 subject.login(usernamePasswordToken); User user = (User) subject.getPrincipal(); request.getSession().setAttribute("user", user); return "index"; &#125; catch (AuthenticationException e) &#123; return "login"; &#125; &#125; @RequestMapping(value = "/logout") public String logout(HttpServletRequest request) &#123; Subject subject = SecurityUtils.getSubject(); // 执行注销 if (subject.isAuthenticated()) &#123; subject.logout(); &#125; request.getSession().removeAttribute("user"); return "login"; &#125;&#125; 2. 异常处理些常见的登录异常如下表，可按业务需要使用： 异常 描述 UnknownAccountException 找不到用户 IncorrectCredentialsException 用户名密码不正确 LockedAccountException 用户被锁定 ExcessiveAttemptsException 密码重试超过次数 ExpiredCredentialsException 密钥已经过期 注意 ：需要模糊处理账户或密码错误等情况。 8. Thymeleaf引入Shiro标签8.1 引入thymeleaf-extras-shiro在pom.xml中添加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.github.theborakompanioni&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-extras-shiro&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 8.2 Shiro配置文件修改引入依赖后，需要在ShiroConfig中配置该方言标签： 12345678910@Configurationpublic class ShiroConfiguration &#123; /** * Thymeleaf中使用shiro标签 */ @Bean public ShiroDialect shiroDialect() &#123; return new ShiroDialect(); &#125;&#125; 8.3 使用1. html中引入12&lt;html xmlns:th="http://www.thymeleaf.org" xmlns:shiro="http://www.pollix.at/thymeleaf/shiro"&gt; 2. 使用1&lt;p shiro:hasPermission="add"&gt;添加用户&lt;/p&gt; 有add权限时才会显示添加用户 3. 例子12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html xmlns:th="http://www.thymeleaf.org" xmlns:shiro="http://www.pollix.at/thymeleaf/shiro"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;首页&lt;/title&gt;&lt;/head&gt;&lt;body&gt;欢迎您，&lt;span th:text="$&#123;user.uname&#125;"&gt;&lt;/span&gt;&lt;div&gt; &lt;p shiro:hasPermission="add"&gt;添加用户&lt;/p&gt; &lt;p shiro:hasPermission="delete"&gt;删除用户&lt;/p&gt; &lt;p shiro:hasPermission="update"&gt;更新用户&lt;/p&gt; &lt;p shiro:hasPermission="query"&gt;查询用户&lt;/p&gt;&lt;/div&gt;&lt;a th:href="@&#123;logout&#125;"&gt;点我注销&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 9. 测试运行程序后进入登录页面，登录用户张三可以看到 1234添加用户删除用户更新用户查询用户 所有的四个操作。 登录用户李四只能看到 1查询用户 说明Shiro权限控制配置成功了。 10. 参考官方文档：http://shiro.apache.org/documentation.html https://mrbird.cc/Spring-Boot-Themeleaf%20Shiro%20tag.html]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro安全框架(一)---什么是Shiro]]></title>
    <url>%2Fposts%2F7dd8d38.html</url>
    <content type="text"><![CDATA[本文主要讲述了什么是RBAC权限控制，同时对Shiro安全框架做了简单介绍。 Shiro安全框架系列文章目录 Shiro安全框架(一)—什么是Shiro Shiro安全框架(二)—SpringBoot整合Shiro Shiro安全框架(三)—Shiro组件详解 源码下载：GItHub 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. RBAC权限控制RBAC：Role-Based Access Control基于角色的访问控制 1.1 RBAC1.0用户表 角色表 菜单表(权限表) 和两个中间表 用户-角色表 角色-菜单表。 菜单表中存放所有的功能，角色表中设置多种角色(职位)，权限赋给角色，然后在将角色关联到用户上，这样就不用给每个用户都赋值权限了。 1.2 RBAC2.0随着项目的扩大，人数特别特别多了，给每个用户赋角色都很麻烦，然后又添加了一个用户组表,对用户进行分组，如果角色也特别特别多，那么在加一个角色组表，用户组与用户管理，角色组与角色关联，最后用户组再与角色组关联。 2. Shiro2.1 简介Java中安全管理框架有spring security和shiro，其中spring security依赖于spring，且比较复杂，学习曲线比较该，shiro比较简单且独立，java se单机环境都可以使用。 2.2 名词解释 Shiro是一个强大易用的Java安全框架,提供了认证、授权、加密和会话管理等功能。 Authentication：身份认证/登录，验证用户是不是拥有相应的身份； Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限； Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通JavaSE环境的，也可以是如Web环境的； Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储； Web Support：Web支持，可以非常容易的集成到Web环境； Caching：缓存，比如用户登录后，其用户信息、拥有的角色/权限不必每次去查，这样可以提高效率； Concurrency：shiro支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去； Testing：提供测试支持； Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问； Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。 记住一点，Shiro不会去维护用户、维护权限；这些需要我们自己去设计提供；然后通过相应的接口注入给Shiro即可。 可以看到：应用代码直接交互的对象是Subject，也就是说Shiro的对外API核心就是Subject；其每个API的含义： Subject：主体，代表了当前“用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是Subject，如网络爬虫，机器人等；即一个抽象概念；所有Subject都绑定到SecurityManager，与Subject的所有交互都会委托给SecurityManager；可以把Subject认为是一个门面；SecurityManager才是实际的执行者； SecurityManager：安全管理器；即所有与安全有关的操作都会与SecurityManager交互；且它管理着所有Subject；可以看出它是Shiro的核心，它负责与后边介绍的其他组件进行交互，如果学习过SpringMVC，你可以把它看成DispatcherServlet前端控制器； Realm：域，Shiro从从Realm获取安全数据（如用户、角色、权限），就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法；也需要从Realm得到用户相应的角色/权限进行验证用户是否能进行操作；可以把Realm看成DataSource，即安全数据源。 2.3 具体架构 Subject：主体，可以看到主体可以是任何可以与应用交互的“用户”； SecurityManager：相当于SpringMVC中的DispatcherServlet或者Struts2中的FilterDispatcher；是Shiro的心脏；所有具体的交互都通过SecurityManager进行控制；它管理着所有Subject、且负责进行认证和授权、及会话、缓存的管理。 Authenticator：认证器，负责主体认证的，这是一个扩展点，如果用户觉得Shiro默认的不好，可以自定义实现；其需要认证策略（Authentication Strategy），即什么情况下算用户认证通过了； Authrizer：授权器，或者访问控制器，用来决定主体是否有权限进行相应的操作；即控制着用户能访问应用中的哪些功能； Realm：可以有1个或多个Realm，可以认为是安全实体数据源，即用于获取安全实体的；可以是JDBC实现，也可以是LDAP实现，或者内存实现等等；由用户提供；注意：Shiro不知道你的用户/权限存储在哪及以何种格式存储；所以我们一般在应用中都需要实现自己的Realm； SessionManager：如果写过Servlet就应该知道Session的概念，Session呢需要有人去管理它的生命周期，这个组件就是SessionManager；而Shiro并不仅仅可以用在Web环境，也可以用在如普通的JavaSE环境、EJB等环境；所有呢，Shiro就抽象了一个自己的Session来管理主体与应用之间交互的数据；这样的话，比如我们在Web环境用，刚开始是一台Web服务器；接着又上了台EJB服务器；这时想把两台服务器的会话数据放到一个地方，这个时候就可以实现自己的分布式会话（如把数据放到Memcached服务器）； SessionDAO：DAO大家都用过，数据访问对象，用于会话的CRUD，比如我们想把Session保存到数据库，那么可以实现自己的SessionDAO，通过如JDBC写到数据库；比如想把Session放到Memcached中，可以实现自己的Memcached SessionDAO；另外SessionDAO中可以使用Cache进行缓存，以提高性能； CacheManager：缓存控制器，来管理如用户、角色、权限等的缓存的；因为这些数据基本上很少去改变，放到缓存中后可以提高访问的性能 Cryptography：密码模块，Shiro提高了一些常见的加密组件用于如密码加密/解密的。 3. 参考https://blog.csdn.net/yangwenxue_admin/article/details/73936803 官方文档：http://shiro.apache.org/documentation.html]]></content>
      <categories>
        <category>Shiro</category>
      </categories>
      <tags>
        <tag>Shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(九)---服务监控 Spring Boot Admin]]></title>
    <url>%2Fposts%2F14927f8f.html</url>
    <content type="text"><![CDATA[随着开发周期的推移，项目会不断变大，切分出的服务也会越来越多，这时一个个的微服务构成了错综复杂的系统，各个服务的信息收集与监控变得十分艰难。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述对于各个微服务系统的健康状态、会话数量、并发数、服务资源、延迟等度量信息的收集就成为了一个挑战。Spring Boot Admin 应运而生，它正式基于这些需求开发出的一套功能强大的监控管理系统。 Spring Boot Admin 有两个角色组成，一个是 Spring Boot Admin Server，一个是 Spring Boot Admin Client。 2. Spring Boot Admin 服务端创建一个工程名为 hello-spring-cloud-admin 的项目作为服务端。 2.1 pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-admin&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-admin&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.admin.AdminApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 2 个依赖，org.jolokia:jolokia-core、de.codecentric:spring-boot-admin-starter-server 12345678&lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-server&lt;/artifactId&gt;&lt;/dependency&gt; 其中 spring-boot-admin-starter-server 的版本号为：2.0.0，这里没写版本号是因为我已将版本号托管到 dependencies 项目中 2.2 Application通过 @EnableAdminServer 注解开启 Admin 功能 123456789101112131415package com.illusory.hello.spring.cloud.admin;import de.codecentric.boot.admin.server.config.EnableAdminServer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableEurekaClient@EnableAdminServerpublic class AdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(AdminApplication.class, args); &#125;&#125; 2.3 application.yml设置端口号为：8084 12345678910111213141516171819202122spring: application: name: hello-spring-cloud-admin zipkin: base-url: http://localhost:9411server: port: 8084management: endpoint: health: show-details: always endpoints: web: exposure: include: health,infoeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 主要增加了 Spring Boot Admin Server 的相关配置 12345678management: endpoint: health: show-details: always endpoints: web: exposure: include: health,info 2.4. 测试访问监控中心打开浏览器访问：http://localhost:8084 3. Spring Boot Admin 客户端创建一个工程名为 hello-spring-cloud-admin-client 的项目作为客户端。 3.1 pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-admin-client&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-admin-client&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.admin.client.AdminClientApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 2 个依赖，org.jolokia:jolokia-core、de.codecentric:spring-boot-admin-starter-client 12345678&lt;dependency&gt; &lt;groupId&gt;org.jolokia&lt;/groupId&gt; &lt;artifactId&gt;jolokia-core&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;de.codecentric&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-admin-starter-client&lt;/artifactId&gt;&lt;/dependency&gt; 其中 spring-boot-admin-starter-client 的版本号为：2.0.0，这里没写版本号是因为我已将版本号托管到 dependencies 项目中 3.2 application.yml设置端口号为：8085，并设置 Spring Boot Admin 的服务端地址 1234567891011121314151617spring: application: name: hello-spring-cloud-admin-client boot: admin: client: url: http://localhost:8084 zipkin: base-url: http://localhost:9411server: port: 8085eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 主要增加了 Spring Boot Admin Client 相关配置 12345spring: boot: admin: client: url: http://localhost:8084 3.3 测试重启服务后再次去访问服务端，若能看到新增的服务则说明成功. 4. 小结本章节我们主要搭建了Spring-Boot-Admin项目的服务端和客户端，实现了对服务的动态监控。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(八)---服务链路追踪 ZipKin]]></title>
    <url>%2Fposts%2Fc9420366.html</url>
    <content type="text"><![CDATA[微服务架构是通过业务来划分服务的，使用 REST 调用。对外暴露的一个接口，可能需要很多个服务协同才能完成这个接口功能，如果链路上任何一个服务出现问题或者网络超时，都会形成导致接口调用失败。随着业务的不断扩张，服务之间互相调用会越来越复杂。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub SpringCloud入门系列文章目录 1. 概述ZipKin 是一个开放源代码的分布式跟踪系统，由 Twitter 公司开源，它致力于收集服务的定时数据，以解决微服务架构中的延迟问题，包括数据的收集、存储、查找和展现。它的理论模型来自于 Google Dapper 论文。 每个服务向 ZipKin 报告计时数据，ZipKin 会根据调用关系通过 ZipKin UI 生成依赖关系图，显示了多少跟踪请求通过每个服务，该系统让开发者可通过一个 Web 前端轻松的收集和分析数据，例如用户每次请求服务的处理时间等，可方便的监测系统中存在的瓶颈。 2. 创建 ZipKin 服务端创建一个工程名为 hello-spring-cloud-zipkin 的项目 2.1 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-zipkin&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-zipkin&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.zipkin.ZipKinApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 3 个依赖，io.zipkin.java:zipkin、io.zipkin.java:zipkin-server、io.zipkin.java:zipkin-autoconfigure-ui 123456789101112&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.zipkin.java&lt;/groupId&gt; &lt;artifactId&gt;zipkin-autoconfigure-ui&lt;/artifactId&gt;&lt;/dependency&gt; 注意版本号为：2.10.1，这里没写版本号是因为我已将版本号托管到 dependencies 项目中 2.2 Application通过 @EnableZipkinServer 注解开启 Zipkin Server 功能 123456789101112131415package com.illusory.hello.spring.cloud.zipkin;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import zipkin.server.internal.EnableZipkinServer;@SpringBootApplication@EnableEurekaClient@EnableZipkinServerpublic class ZipKinApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZipKinApplication.class, args); &#125;&#125; 2.3 application.yml设置端口号为：9411，该端口号为 Zipkin Server 的默认端口号 1234567891011121314151617spring: application: name: hello-spring-cloud-zipkinserver: port: 9411eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ management: metrics: web: server: auto-time-requests: false 3. 追踪服务在 所有需要被追踪的项目（大部分需要被追踪，包括 Eureka Server） 中增加 spring-cloud-starter-zipkin 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 在这些项目的 application.yml 配置文件中增加 Zipkin Server 的地址即可 123spring: zipkin: base-url: http://localhost:9411 4. 测试追踪启动全部项目，打开浏览器访问：http://localhost:9411/能看到各个服务的具体调用流程。 5. 小结本章我们主要使用ZipKin组件实现了服务的链路追踪，方便的统计服务之间的调用情况等信息。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(七)---分布式配置中心 Spring Cloud Config]]></title>
    <url>%2Fposts%2F68aa18ee.html</url>
    <content type="text"><![CDATA[在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述在 Spring Cloud 中，有分布式配置中心组件 Spring Cloud Config ，它支持配置服务放在配置服务的内存中（即本地），也支持放在远程 Git 仓库中。在 Spring Cloud Config 组件中，分两个角色，一是 Config Server，二是 Config Client。 2. 搭建分布式配置中心服务端创建一个工程名为 hello-spring-cloud-config 的项目 2.1 pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-config&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-config&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.config.ConfigApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要增加了 spring-cloud-config-server 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt;&lt;/dependency&gt; 2.2 Application通过 @EnableConfigServer 注解，开启配置服务器功能 123456789101112131415package com.illusory.hello.spring.cloud.config;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.config.server.EnableConfigServer;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableConfigServer@EnableEurekaClientpublic class ConfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigApplication.class, args); &#125;&#125; 2.3 application.yml增加 Config 相关配置，并设置端口号为：8888 1234567891011121314151617181920spring: application: name: hello-spring-cloud-config cloud: config: label: master server: git: uri: https://github.com/topsale/spring-cloud-config search-paths: respo username: password:server: port: 8888eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 相关配置说明，如下： spring.cloud.config.label：配置仓库的分支 spring.cloud.config.server.git.uri：配置 Git 仓库地址（GitHub、GitLab、码云 …） spring.cloud.config.server.git.search-paths：配置仓库路径（存放配置文件的目录） spring.cloud.config.server.git.username：访问 Git 仓库的账号 spring.cloud.config.server.git.password：访问 Git 仓库的密码 注意事项： 如果使用 GitLab 作为仓库的话，git.uri 需要在结尾加上 .git，GitHub 则不用 附：HTTP 请求地址和资源文件映射 http://ip:port/{application}/{profile}[/{label}] http://ip:port/{application}-{profile}.yml http://ip:port/{label}/{application}-{profile}.yml http://ip:port/{application}-{profile}.properties http://ip:port/{label}/{application}-{profile}.properties 2.4 测试浏览器端访问：http://localhost:8888/config-client/dev/master显示如下： 123456789101112131415161718&lt;Environment&gt; &lt;name&gt;config-client&lt;/name&gt; &lt;profiles&gt; &lt;profiles&gt;dev&lt;/profiles&gt; &lt;/profiles&gt; &lt;label&gt;master&lt;/label&gt; &lt;version&gt;9646007f931753d7e96a6dcc9ae34838897a91df&lt;/version&gt; &lt;state/&gt; &lt;propertySources&gt; &lt;propertySources&gt; &lt;name&gt;https://github.com/test/spring-cloud-config/respo/config-client-dev.yml&lt;/name&gt; &lt;source&gt; &lt;foo&gt;foo version 1&lt;/foo&gt; &lt;demo.message&gt;Hello Spring Config&lt;/demo.message&gt; &lt;/source&gt; &lt;/propertySources&gt; &lt;/propertySources&gt; &lt;/Environment&gt; 证明配置服务中心可以从远程程序获取配置信息 3. 搭建分布式配置中心客户端3.1 pom.xml其他项目就可以作为客户端，在pom.xml中增加 spring-cloud-starter-config 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt;&lt;/dependency&gt; 3.2 application.yml增加 Config Client 相关配置，并设置端口号为：8889 1234567891011121314151617spring: application: name: hello-spring-cloud-config-client cloud: config: uri: http://localhost:8888 name: config-client label: master profile: devserver: port: 8889eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 相关配置说明，如下： spring.cloud.config.uri：配置服务中心的网址 spring.cloud.config.name：配置文件名称的前缀 spring.cloud.config.label：配置仓库的分支 spring.cloud.config.profile ：配置文件的环境标识 dev：表示开发环境 test：表示测试环境 prod：表示生产环境 注意事项： 配置服务器的默认端口为 8888，如果修改了默认端口，则客户端项目就不能在 application.yml 或 application.properties 中配置 spring.cloud.config.uri，必须在 bootstrap.yml 或是 bootstrap.properties 中配置，原因是 bootstrap 开头的配置文件会被优先加载和配置，切记。 附：开启 Spring Boot Profile我们在做项目开发的时候，生产环境和测试环境的一些配置可能会不一样，有时候一些功能也可能会不一样，所以我们可能会在上线的时候手工修改这些配置信息。但是 Spring 中为我们提供了 Profile 这个功能。我们只需要在启动的时候添加一个虚拟机参数，激活自己环境所要用的 Profile 就可以了。 操作起来很简单，只需要为不同的环境编写专门的配置文件，如：application-dev.yml、application-prod.yml， 启动项目时只需要增加一个命令参数 --spring.profiles.active=环境配置 即可，启动命令如下： 1java -jar hello-spring-cloud-web-admin-feign-1.0.0-SNAPSHOT.jar --spring.profiles.active=pro 4. 小结本章记录了SpringCloudConfig分布式配置中心的搭建及其具体使用过程与Spring Boot Profile多环境配置。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(六)---路由网关 Zuul]]></title>
    <url>%2Fposts%2Fabd301c1.html</url>
    <content type="text"><![CDATA[在微服务架构中，需要几个基础的服务治理组件，包括服务注册与发现、服务消费、负载均衡、熔断器、智能路由、配置管理等，由这几个基础组件相互协作，共同组建了一个简单的微服务系统。SpringCloud中路由网关使用的是Zuul。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述在 Spring Cloud 微服务系统中，一种常见的负载均衡方式是，客户端的请求首先经过负载均衡（Zuul、Ngnix），再到达服务网关（Zuul 集群），然后再到具体的服。服务统一注册到高可用的服务注册中心集群，服务的所有的配置文件由配置服务管理，配置服务的配置文件放在 GIT 仓库，方便开发人员随时改配置。 Zuul 的主要功能是路由转发和过滤器。路由功能是微服务的一部分，比如 /api/user 转发到到 User 服务，/api/shop 转发到到 Shop 服务。Zuul默认和 Ribbon 结合实现了负载均衡的功能。 2. 使用路由网关统一访问接口2.1 创建路由网关项目1. pom.xml 文件如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-zuul&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-zuul&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--指向启动类 用于jar包方式运行--&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.zuul.ZuulApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要是增加了 Zuul 的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 2. Application增加 @EnableZuulProxy 注解开启 Zuul 功能 123456789101112131415package com.illusory.hello.spring.cloud.zuul;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;@SpringBootApplication@EnableEurekaClient@EnableZuulProxypublic class ZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication.class, args); &#125;&#125; 3. application.yml 设置端口号为：8769 增加 Zuul 配置 123456789101112131415161718192021spring: application: name: hello-spring-cloud-zuulserver: port: 8769eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/zuul: routes: #api-a api-b是自定义的名字 api-a: path: /api/a/** serviceId: hello-spring-cloud-web-admin-ribbon api-b: path: /api/b/** serviceId: hello-spring-cloud-web-admin-feign 路由说明： 以 /api/a 开头的请求都转发给 hello-spring-cloud-web-admin-ribbon 服务 以 /api/b 开头的请求都转发给 hello-spring-cloud-web-admin-feign 服务 2.2 测试访问依次运行Eureka、Provider、Consumer、Zuul 打开浏览器访问：http://localhost:8769/api/a/hi?message=HelloZuul 浏览器显示 1Hi，your message is :&quot;HelloZuul&quot; i am from port：8763 打开浏览器访问：http://localhost:8769/api/b/hi?message=HelloZuul浏览器显示 1Hi，your message is :&quot;HelloZuul&quot; i am from port：8763 至此说明 Zuul 的路由功能配置成功 2.3 配置网关路由失败时的回调1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package com.illusory.hello.spring.cloud.zuul.fallback;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.cloud.netflix.zuul.filters.route.FallbackProvider;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.client.ClientHttpResponse;import org.springframework.stereotype.Component;import java.io.ByteArrayInputStream;import java.io.IOException;import java.io.InputStream;import java.util.HashMap;import java.util.Map;/** * 路由 hello-spring-cloud-web-admin-feign 失败时的回调 */@Componentpublic class WebAdminFeignFallbackProvider implements FallbackProvider &#123; @Override public String getRoute() &#123; // ServiceId，如果需要所有调用都支持回退，则 return "*" 或 return null return "hello-spring-cloud-web-admin-feign"; &#125; /** * 如果请求服务失败，则返回指定的信息给调用者 * @param route * @param cause * @return */ @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) &#123; return new ClientHttpResponse() &#123; /** * 网关向 api 服务请求失败了，但是消费者客户端向网关发起的请求是成功的， * 不应该把 api 的 404,500 等问题抛给客户端 * 网关和 api 服务集群对于客户端来说是黑盒 * @return * @throws IOException */ @Override public HttpStatus getStatusCode() throws IOException &#123; return HttpStatus.OK; &#125; @Override public int getRawStatusCode() throws IOException &#123; return HttpStatus.OK.value(); &#125; @Override public String getStatusText() throws IOException &#123; return HttpStatus.OK.getReasonPhrase(); &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put("status", 200); map.put("message", "无法连接，请检查您的网络"); return new ByteArrayInputStream(objectMapper.writeValueAsString(map).getBytes("UTF-8")); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); // 和 getBody 中的内容编码一致 headers.setContentType(MediaType.APPLICATION_JSON_UTF8); return headers; &#125; &#125;; &#125;&#125; 3. 使用路由网关的服务过滤功能Zuul 不仅仅只是路由，还有很多强大的功能，例如它的服务过滤功能，比如用在安全验证方面。 3.1 创建服务过滤器继承 ZuulFilter 类并在类上增加 @Component 注解就可以使用服务过滤功能了，非常简单方便 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.illusory.hello.spring.cloud.zuul.filter;import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.context.RequestContext;import com.netflix.zuul.exception.ZuulException;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import javax.servlet.http.HttpServletRequest;import java.io.IOException;@Componentpublic class LoginFilter extends ZuulFilter &#123; private static final Logger logger = LoggerFactory.getLogger(LoginFilter.class); /** * 配置过滤类型，有四种不同生命周期的过滤器类型 * 1. pre：路由之前 * 2. routing：路由之时 * 3. post：路由之后 * 4. error：发送错误调用 * @return */ @Override public String filterType() &#123; return "pre"; &#125; /** * 配置过滤的顺序 * @return */ @Override public int filterOrder() &#123; return 0; &#125; /** * 配置是否需要过滤：true/需要，false/不需要 * @return */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * 过滤器的具体业务代码 * @return * @throws ZuulException */ @Override public Object run() throws ZuulException &#123; RequestContext context = RequestContext.getCurrentContext(); HttpServletRequest request = context.getRequest(); logger.info("&#123;&#125; &gt;&gt;&gt; &#123;&#125;", request.getMethod(), request.getRequestURL().toString()); String token = request.getParameter("token"); if (token == null) &#123; logger.warn("Token is empty"); context.setSendZuulResponse(false); context.setResponseStatusCode(401); try &#123; context.getResponse().getWriter().write("Token is empty"); &#125; catch (IOException e) &#123; &#125; &#125; else &#123; logger.info("OK"); &#125; return null; &#125;&#125; 3.2 名词解释1. filterType返回一个字符串代表过滤器的类型，在 Zuul 中定义了四种不同生命周期的过滤器类型 pre：路由之前 routing：路由之时 post： 路由之后 error：发送错误调用 2. filterOrder过滤的顺序 3. shouldFilter是否需要过滤，这里是 true，需要过滤 4. run过滤器的具体业务代码 3.3 测试过滤器浏览器访问：http://localhost:8769/api/a/hi?message=HelloZuul 网页显示 1Token is empty 浏览器访问：http://localhost:8769/api/b/hi?message=HelloZuul&amp;token=123 网页显示 1Hi，your message is :&quot;HelloZuul&quot; i am from port：8763 4. 小结到此为止我们使用Zuul路由网关成功实现了统一访问接口和服务过滤功能。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(五)---服务熔断 Hystrix]]></title>
    <url>%2Fposts%2F3cc75bae.html</url>
    <content type="text"><![CDATA[在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC 相互调用,为了实现服务的高可用业界提出了熔断器模型。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述在微服务架构中，根据业务来拆分成一个个的服务，服务与服务之间可以通过 RPC 相互调用，在 Spring Cloud 中可以用 RestTemplate + Ribbon 和 Feign 来调用。为了保证其高可用，单个服务通常会集群部署。由于网络原因或者自身的原因，服务并不能保证 100% 可用，如果单个服务出现问题，调用这个服务就会出现线程阻塞，此时若有大量的请求涌入，Servlet 容器的线程资源会被消耗完毕，导致服务瘫痪。服务与服务之间的依赖性，故障会传播，会对整个微服务系统造成灾难性的严重后果，这就是服务故障的 “雪崩” 效应。 为了解决这个问题，业界提出了熔断器模型。 Netflix 开源了 Hystrix 组件，实现了熔断器模式，Spring Cloud 对这一组件进行了整合。 较底层的服务如果出现故障，会导致连锁故障。当对特定的服务的调用的不可用达到一个阀值（Hystrix 是 5 秒 20 次） 熔断器将会被打开。 熔断器打开后，为了避免连锁故障，通过 fallback 方法可以直接返回一个固定值,提示访问出错。 2. Ribbon 中使用熔断器对hello-spring-cloud-web-admin-ribbon项目进行修改。 2.1 pom.xml在 pom.xml 中增加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 2.2 Application在 Application 中增加 @EnableHystrix 注解 123456789101112131415package com.illusory.hello.spring.cloud.web.admin.ribbon;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.netflix.hystrix.EnableHystrix;@SpringBootApplication@EnableDiscoveryClient@EnableHystrixpublic class WebAdminRibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebAdminRibbonApplication.class, args); &#125;&#125; 2.3 Service在 Service 中增加 @HystrixCommand 注解 在 Ribbon 调用方法上增加 @HystrixCommand 注解并指定 fallbackMethod 熔断方法 12345678910111213141516171819202122package com.illusory.hello.spring.cloud.web.admin.ribbon.service;import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.web.client.RestTemplate;@Servicepublic class AdminService &#123; @Autowired private RestTemplate restTemplate; @HystrixCommand(fallbackMethod = "hiError") public String sayHi(String message) &#123; return restTemplate.getForObject("http://HELLO-SPRING-CLOUD-SERVICE-ADMIN/hi?message=" + message, String.class); &#125; public String hiError(String message) &#123; return "Hi，your message is :\"" + message + "\" but request error."; &#125;&#125; 2.4 测试熔断器此时我们关闭服务提供者，再次请求 http://localhost:8764/hi?message=HelloRibbon 浏览器会显示： 1Hi，your message is :&quot;HelloRibbon&quot; but request error. 3. Feign 中使用熔断器对hello-spring-cloud-web-admin-feign项目进行修改。 3.1 application.ymlapplication.yml中开启熔断 Feign 是自带熔断器的，但默认是关闭的。需要在配置文件中配置打开它，在配置文件增加以下代码： 123feign: hystrix: enabled: true 3.2 Service在 Service 中增加 fallback 指定类 1234567891011121314package com.illusory.hello.spring.cloud.web.admin.feign.service;import com.illusory.hello.spring.cloud.web.admin.feign.service.hystrix.AdminServiceHystrix;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;@FeignClient(value = "hello-spring-cloud-service-admin", fallback = AdminServiceHystrix.class)public interface AdminService &#123; @RequestMapping(value = "hi", method = RequestMethod.GET) public String sayHi(@RequestParam(value = "message") String message);&#125; 3.3 AdminServiceHystrix创建熔断器类并实现对应的 Feign 接口 12345678910111213package com.illusory.hello.spring.cloud.web.admin.feign.service.hystrix;import com.funtl.hello.spring.cloud.web.admin.feign.service.AdminService;import org.springframework.stereotype.Component;@Componentpublic class AdminServiceHystrix implements AdminService &#123; @Override public String sayHi(String message) &#123; return "Hi，your message is :\"" + message + "\" but request error."; &#125;&#125; 3.4 测试熔断器此时我们关闭服务提供者，再次请求 http://localhost:8765/hi?message=HelloFeign 浏览器会显示： 1Hi，your message is :&quot;HelloFeign&quot; but request error. 到这里服务熔断搭建成功。 4. 开启熔断仪表盘分别对对hello-spring-cloud-web-admin-feign和对hello-spring-cloud-web-admin-ribbon项目进行修改，增加熔断仪表盘功能。 4.1 pom.xml在 pom.xml 中增加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; 4.2 Application在 Application 中增加 @EnableHystrixDashboard 注解 123456789@SpringBootApplication@EnableDiscoveryClient@EnableHystrix@EnableHystrixDashboardpublic class WebAdminRibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebAdminRibbonApplication.class, args); &#125;&#125; 4.3 HystrixDashboardConfiguration创建 hystrix.stream 的 Servlet 配置 Spring Boot 2.x 版本开启 Hystrix Dashboard 与 Spring Boot 1.x 的方式略有不同，需要增加一个 HystrixMetricsStreamServlet 的配置，代码如下： 1234567891011121314151617181920package com.illusory.hello.spring.cloud.web.admin.ribbon.config;import com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class HystrixDashboardConfiguration &#123; @Bean public ServletRegistrationBean getServlet() &#123; HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings("/hystrix.stream"); registrationBean.setName("HystrixMetricsStreamServlet"); return registrationBean; &#125;&#125; 4.4 测试 Hystrix Dashboard浏览器端访问http://localhost:8764/hystrix 附：Hystrix 说明fallback 触发条件 名字 描述 触发fallback EMIT 值传递 NO SUCCESS 执行完成，没有错误 NO FAILURE 执行抛出异常 YES TIMEOUT 执行开始，但没有在允许的时间内完成 YES BAD_REQUEST 执行抛出HystrixBadRequestException NO SHORT_CIRCUITED 断路器打开，不尝试执行 YES THREAD_POOL_REJECTED 线程池拒绝，不尝试执行 YES SEMAPHORE_REJECTED 信号量拒绝，不尝试执行 YES fallback 抛出异常 名字 描述 抛异常 FALLBACK_EMIT Fallback值传递 NO FALLBACK_SUCCESS Fallback执行完成，没有错误 NO FALLBACK_FAILURE Fallback执行抛出出错 YES FALLBACK_REJECTED Fallback信号量拒绝，不尝试执行 YES FALLBACK_MISSING 没有Fallback实例 YES Hystrix 常用配置信息超时时间（默认1000ms，单位：ms） hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds：在调用方配置，被该调用方的所有方法的超时时间都是该值，优先级低于下边的指定配置 hystrix.command.HystrixCommandKey.execution.isolation.thread.timeoutInMilliseconds：在调用方配置，被该调用方的指定方法（HystrixCommandKey 方法名）的超时时间是该值 线程池核心线程数 hystrix.threadpool.default.coreSize：默认为 10 Queue hystrix.threadpool.default.maxQueueSize：最大排队长度。默认 -1，使用 SynchronousQueue。其他值则使用 LinkedBlockingQueue。如果要从 -1 换成其他值则需重启，即该值不能动态调整，若要动态调整，需要使用到下边这个配置 hystrix.threadpool.default.queueSizeRejectionThreshold：排队线程数量阈值，默认为 5，达到时拒绝，如果配置了该选项，队列的大小是该队列 注意： 如果 maxQueueSize=-1 的话，则该选项不起作用 断路器 hystrix.command.default.circuitBreaker.requestVolumeThreshold：当在配置时间窗口内达到此数量的失败后，进行短路。默认 20 个（10s 内请求失败数量达到 20 个，断路器开） hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds：短路多久以后开始尝试是否恢复，默认 5s hystrix.command.default.circuitBreaker.errorThresholdPercentage：出错百分比阈值，当达到此阈值后，开始短路。默认 50% fallback hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests：调用线程允许请求 HystrixCommand.GetFallback() 的最大数量，默认 10。超出时将会有异常抛出，注意：该项配置对于 THREAD 隔离模式也起作用 5. 小结本章节中我们对Ribbon和Feign两个服务消费者项目进行了改造,添加Hystrix组件完成了服务熔断功能，接着添加Hystrix DashBoard组件实现了服务熔断仪表盘功能，方便监控服务熔断相关信息。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(四)---服务消费者 Consumer]]></title>
    <url>%2Fposts%2Fbf9c3958.html</url>
    <content type="text"><![CDATA[本文主要介绍了SpringCloud-Netflix系列微服务解决方案之服务消费者。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述在微服务架构中，业务都会被拆分成一个独立的服务，服务与服务的通讯是基于 HTTP Restful的。Spring Cloud 有两种服务调用方式，一种是 ribbon + restTemplate，另一种是 feign。 2. RibbonRibbon 是一个负载均衡客户端，可以很好的控制 http 和 tcp 的一些行为。 创建使用Ribbon的项目hello-spring-cloud-web-admin-ribbon作为服务消费者。 2.1 pom.mxl1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-web-admin-ribbon&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-web-admin-ribbon&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- 解决 thymeleaf 模板引擎一定要执行严格的 html5 格式校验问题 --&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--指向启动类 用于jar包方式运行--&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.web.admin.ribbon.WebAdminRibbonApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要是增加了 Ribbon 的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;&lt;/dependency&gt; 2.2 Application通过 @EnableDiscoveryClient 注解注册到服务中心 12345678910111213package com.illusory.hello.spring.cloud.web.admin.ribbon;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;@SpringBootApplication@EnableDiscoveryClientpublic class WebAdminRibbonApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebAdminRibbonApplication.class, args); &#125;&#125; 2.3 application.yml设置程序端口号为：8764 1234567891011121314151617spring: application: name: hello-spring-cloud-web-admin-ribbon thymeleaf: cache: false mode: LEGACYHTML5 encoding: UTF-8 servlet: content-type: text/htmlserver: port: 8764eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 2.4 Configuration配置注入 RestTemplate 的 Bean，并通过 @LoadBalanced 注解表明开启负载均衡功能 12345678910111213141516package com.illusory.hello.spring.cloud.web.admin.ribbon.config;import org.springframework.cloud.client.loadbalancer.LoadBalanced;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.web.client.RestTemplate;@Configurationpublic class RestTemplateConfiguration &#123; @Bean @LoadBalanced public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; 2.5 Service这里直接用的程序名替代了具体的URL 地址，在 Ribbon 中它会根据服务名来选择具体的服务实例，根据服务实例在请求的时候会用具体的 URL 替换掉服务名，代码如下： service不在调用dao层而是远程调用服务提供者对外提供的服务。 12345678910111213141516package com.illusory.hello.spring.cloud.web.admin.ribbon.service;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.web.client.RestTemplate;@Servicepublic class AdminService &#123; @Autowired private RestTemplate restTemplate; public String sayHi(String message) &#123; return restTemplate.getForObject("http://HELLO-SPRING-CLOUD-SERVICE-ADMIN/hi?message=" + message, String.class); &#125;&#125; 2.6 Controller1234567891011121314151617181920package com.illusory.hello.spring.cloud.web.admin.ribbon.controller;import com.illusory.hello.spring.cloud.web.admin.ribbon.service.AdminService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class AdminController &#123; @Autowired private AdminService adminService; @RequestMapping(value = "hi", method = RequestMethod.GET) public String sayHi(@RequestParam String message) &#123; return adminService.sayHi(message); &#125;&#125; 2.7 测试访问在浏览器上多次访问 http://localhost:8764/hi?message=HelloRibbon 3. FeignFeign 是一个声明式的伪 Http 客户端，它使得写 Http 客户端变得更简单。使用 Feign，只需要创建一个接口并注解。它具有可插拔的注解特性，可使用 Feign 注解和 JAX-RS 注解。Feign 支持可插拔的编码器和解码器。Feign 默认集成了 Ribbon，并和 Eureka 结合，默认实现了负载均衡的效果 Feign 采用的是基于接口的注解 Feign 整合了 ribbon 创建使用Feign的项目hello-spring-cloud-web-admin-feign作为服务消费者。 3.1 pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-web-admin-feign&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-web-admin-feign&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;!-- 解决 thymeleaf 模板引擎一定要执行严格的 html5 格式校验问题 --&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--指向启动类 用于jar包方式运行--&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.web.admin.feign.WebAdminFeignApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 主要是增加了 Feign 的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 3.2 Application通过 @EnableFeignClients 注解开启 Feign 功能 123456789101112131415package com.illusory.hello.spring.cloud.web.admin.feign;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.cloud.openfeign.EnableFeignClients;@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class WebAdminFeignApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(WebAdminFeignApplication.class, args); &#125;&#125; 3.3 application.yml设置程序端口号为：8765 1234567891011121314151617spring: application: name: hello-spring-cloud-web-admin-feign thymeleaf: cache: false mode: LEGACYHTML5 encoding: UTF-8 servlet: content-type: text/htmlserver: port: 8765eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 3.4 创建 Feign 接口通过 @FeignClient(value = &quot;服务名&quot;) 注解来指定调用哪个服务。代码如下： 12345678910111213package com.illusory.hello.spring.cloud.web.admin.feign.service;import org.springframework.cloud.openfeign.FeignClient;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;@FeignClient(value = "hello-spring-cloud-service-admin")public interface AdminService &#123; @RequestMapping(value = "hi", method = RequestMethod.GET) public String sayHi(@RequestParam(value = "message") String message);&#125; 3.5 Controller1234567891011121314151617181920package com.illusory.hello.spring.cloud.web.admin.feign.controller;import com.funtl.hello.spring.cloud.web.admin.feign.service.AdminService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class AdminController &#123; @Autowired private AdminService adminService; @RequestMapping(value = "hi", method = RequestMethod.GET) public String sayHi(@RequestParam String message) &#123; return adminService.sayHi(message); &#125;&#125; 3.6 测试访问在浏览器上多次访问 http://localhost:8765/hi?message=HelloFeign 4. 小结本章节我们分别使用Ribbon和Feign搭建了一个服务消费者项目。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(三)---服务提供者 Provider]]></title>
    <url>%2Fposts%2Fcc38b97d.html</url>
    <content type="text"><![CDATA[本文主要介绍了SpringCloud-Netflix系列微服务解决方案之服务提供者。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述当 Eureka Client 向 Eureka Server 注册时，它会提供一些元数据，例如主机和端口，URL，主页等。Eureka Server 从每个 Client 实例接收心跳消息。 如果心跳超时，则通常将该实例从注册 Server 中删除。这与ZooKeeper注册中心很像。 2. 创建服务提供者项目创建一个项目hello-spring-cloud-service-admin作为服务提供者。 2.1 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-service-admin&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-service-admin&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--指向启动类 用于jar包方式运行--&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.service.admin.ServiceAdminApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.2 Application通过注解 @EnableEurekaClient 表明自己是一个 Eureka Client. 12345678910111213package com.illusory.hello.spring.cloud.service.admin;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.EnableEurekaClient;@SpringBootApplication@EnableEurekaClientpublic class ServiceAdminApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ServiceAdminApplication.class, args); &#125;&#125; 2.3 application.yml1234567891011spring: application: name: hello-spring-cloud-service-adminserver: port: 8762eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 注意： 需要指明 spring.application.name，这个很重要，这在以后的服务与服务之间相互调用一般都是根据这个name。 2.4 Controller对外提供服务 12345678910111213141516171819package com.illusory.hello.spring.cloud.service.admin.controller;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class AdminController &#123; @Value("$&#123;server.port&#125;") private String port; @RequestMapping(value = "hi", method = RequestMethod.GET) public String sayHi(@RequestParam(value = "message") String message) &#123; return String.format("Hi，your message is : %s i am from port : %s", message, port); &#125;&#125; 3. 小结到这里一个简单的服务提供者就搭建成功了，接下来搭建一个服务消费者。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(二)---服务注册与发现]]></title>
    <url>%2Fposts%2F8735f06d.html</url>
    <content type="text"><![CDATA[本文主要介绍了SpringCloud-Netflix系列微服务解决方案之服务注册于发现中心Eureka。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述在这里，我们需要用的组件是 Spring Cloud Netflix 的 Eureka，Eureka 是一个服务注册和发现模块。 2. 创建服务注册于发现项目创建一个项目hello-spring-cloud-eureka作为注册中心。 2.1 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../hello-spring-cloud-dependencies/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;artifactId&gt;hello-spring-cloud-eureka&lt;/artifactId&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-eureka&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;dependencies&gt; &lt;!-- Spring Boot Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot End --&gt; &lt;!-- Spring Cloud Begin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud End --&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--指向启动类 用于jar包方式运行--&gt; &lt;mainClass&gt;com.illusory.hello.spring.cloud.eureka.EurekaApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.2 Application启动一个服务注册中心，只需要一个注解 @EnableEurekaServer 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaApplication.class, args); &#125;&#125; 2.3 application.ymlEureka 是一个高可用的组件，它没有后端缓存，每一个实例注册之后需要向注册中心发送心跳（因此可以在内存中完成），在默认情况下 Erureka Server 也是一个 Eureka Client ,必须要指定一个 Server。 123456789101112131415161718spring: application: name: hello-spring-cloud-eureka boot: admin: client: url: http://localhost:8084server: port: 8761eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 通过 eureka.client.registerWithEureka:false 和 fetchRegistry:false 来表明自己是一个 Eureka Server. 3. 测试Eureka Server 是有界面的，启动工程，打开浏览器访问： http://localhost:8761 4. 小结本章我们主要使用Eureka组件建立了我们的注册中心。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud入门系列(一)---统一依赖管理 Dependencies]]></title>
    <url>%2Fposts%2Fc41e9ac1.html</url>
    <content type="text"><![CDATA[本文主要介绍了SpringCloud-Netflix系列微服务解决方案之创建一个依赖统一管理项目。 SpringCloud入门系列文章目录 SpringCloud入门系列(一)—统一依赖管理 Dependencies SpringCloud入门系列(二)—服务注册与发现 SpringCloud入门系列(三)—服务提供者 Provider SpringCloud入门系列(四)—服务消费者 Consumer SpringCloud入门系列(五)—服务熔断 Hystrix SpringCloud入门系列(六)—路由网关 Zuul SpringCloud入门系列(七)—分布式配置中心 Spring Cloud Config SpringCloud入门系列(八)—服务链路追踪 ZipKin SpringCloud入门系列(九)—服务监控 Spring Boot Admin 更多文章欢迎访问我的个人博客–&gt;幻境云图 Demo下载：GItHub 1. 概述Spring Cloud 项目都是基于 Spring Boot 进行开发，并且都是使用 Maven 做项目管理工具。在实际开发中，我们一般都会创建一个依赖管理项目作为 Maven 的 Parent 项目使用，这样做可以极大的方便我们对 Jar 包版本的统一管理。 我们所有的项目都会依赖这个 dependencies 项目，整个项目周期中的所有第三方依赖的版本也都由该项目进行管理。 parent：继承了 Spring Boot 的 Parent，表示我们是一个 Spring Boot 工程 package：pom，表示该项目仅当做依赖项目，没有具体的实现代码 spring-cloud-dependencies：在 properties 配置中预定义了版本号为 Finchley.RC1 ，表示我们的 Spring Cloud 使用的是 F 版 build：配置了项目所需的各种插件 repositories：配置项目下载依赖时的第三方库 2. 创建依赖统一管理项目pom.xml 文件如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;com.lixueduan&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;hello-spring-cloud-dependencies&lt;/name&gt; &lt;url&gt;http://www.lixueduan.com&lt;/url&gt; &lt;inceptionYear&gt;2019-Now&lt;/inceptionYear&gt; &lt;properties&gt; &lt;!-- Environment Settings --&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;!-- Spring Settings --&gt; &lt;spring-cloud.version&gt;Finchley.RC1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;!-- Compiler 插件, 设定 JDK 版本 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- 打包 jar 文件时，配置 manifest 文件，加入 lib 包的 jar 依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- Add directory entries --&gt; &lt;addDefaultImplementationEntries&gt;true&lt;/addDefaultImplementationEntries&gt; &lt;addDefaultSpecificationEntries&gt;true&lt;/addDefaultSpecificationEntries&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- resource --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- install --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- clean --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-clean-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- ant --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!-- dependency --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- Java Document Generate --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- YUI Compressor (CSS/JS压缩) --&gt; &lt;plugin&gt; &lt;groupId&gt;net.alchim31.maven&lt;/groupId&gt; &lt;artifactId&gt;yuicompressor-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.5.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;compress&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;jswarn&gt;false&lt;/jswarn&gt; &lt;nosuffix&gt;true&lt;/nosuffix&gt; &lt;linebreakpos&gt;30000&lt;/linebreakpos&gt; &lt;force&gt;true&lt;/force&gt; &lt;includes&gt; &lt;include&gt;**/*.js&lt;/include&gt; &lt;include&gt;**/*.css&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.min.js&lt;/exclude&gt; &lt;exclude&gt;**/*.min.css&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 资源文件配置 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/*.java&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;sonatype-repos-s&lt;/id&gt; &lt;name&gt;Sonatype Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-snapshots&lt;/id&gt; &lt;name&gt;Spring Snapshots&lt;/name&gt; &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;spring-milestones&lt;/id&gt; &lt;name&gt;Spring Milestones&lt;/name&gt; &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;aliyun-repos&lt;/id&gt; &lt;name&gt;Aliyun Repository&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 一个简单的项目，只有一个pom.xml文件，用来管理项目中所需的依赖。 接下来创建服务注册与发现项目即注册中心。]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门系列(四)---Spring Boot 项目打包运行]]></title>
    <url>%2Fposts%2F144a69f9.html</url>
    <content type="text"><![CDATA[本文主要记录了如何在idea下打包SpringBoot项目并部署到云服务器，包括jar包和war包两种方式。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 创建项目首先简单创建一个hello word 代码如下： 1234567891011121314151617181920212223242526/** * 简单的controller * * @author illusoryCloud */@RestControllerpublic class HelloController &#123; @RequestMapping(value = "/hello") public String showHello() &#123; return "hello illusoryCloud"; &#125;&#125;/** * SpringBoot启动类 * * @author illusoryCloud */@SpringBootApplicationpublic class HelloApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HelloApplication.class, args); &#125;&#125; 2. 打包2.1 jar包和war包区别 SpringBoot默认支持很多模板引擎，但是JSP只能够在War中使用 无论是Jar还是War都能够使用嵌套容器，java -jar来独立运行 但只有war才能部署到外部容器中 2.2 jar包SpringBoot官方推荐打成jar包，服务器上有JDK 1.8以上环境就可以直接运行 1.修改pom.xml文件选择打包方式为jar 123456&lt;groupId&gt;com.illusory&lt;/groupId&gt;&lt;artifactId&gt;hello&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!--版本号--&gt;&lt;name&gt;hello&lt;/name&gt; &lt;!--打出来的包的名字 hello-0.0.1-SNAPSHOT.jar--&gt;&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;&lt;packaging&gt;jar&lt;/packaging&gt; &lt;!--打包方式jar/war--&gt; 2. 打包然后用maven打包。 1234567891011[INFO] --- maven-jar-plugin:3.1.1:jar (default-jar) @ hello ---[INFO] Building jar: D:\lillusory\MyProjects\hello\target\hello-0.0.1-SNAPSHOT.jar[INFO] [INFO] --- spring-boot-maven-plugin:2.1.3.RELEASE:repackage (repackage) @ hello ---[INFO] Replacing main artifact with repackaged archive[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 23.922 s[INFO] Finished at: 2019-02-22T20:35:40+08:00[INFO] ------------------------------------------------------------------------ 日志中可以看到打出来的包在D:\lillusory\MyProjects\hello\target\hello-0.0.1-SNAPSHOT.jar 3. 测试SpringBoot内置了一个Tomcat，可以直接java -jar jarName运行。 浏览器访问http://localhost:8080/hello出现hello illusoryCloud说明运行起来了。 这里的端口号是application.yml全局配置文件中配置的端口号。 2.3 war包同时也可以打成war包然后用服务器上的Tomcat启动。 1.修改pom.xml123456789101112 &lt;groupId&gt;com.illusory&lt;/groupId&gt; &lt;artifactId&gt;hello&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!--版本号--&gt; &lt;name&gt;hello&lt;/name&gt; &lt;!--打出来的包的名字 hello-0.0.1-SNAPSHOT.jar--&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;!--打包方式jar/war--&gt;&lt;!--外置tomcat启动--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; maven中的&lt;scope&gt;provided&lt;/scope&gt;表示这个jar包在编译测试等地方是需要的，但是打包不会一起打包进去，这也避免了此类构件当部署到目标容器后产生包依赖冲突。由于SpringBoot内置了Tomcat所以这里需要重新配置一下，防止冲突。 2.改造启动类SpringBoot 内置的Tomcat能认识自己的启动项,而外部tomcat是不认识的 所以需要修改启动类。即继承SpringBootServletInitializer类实现configure方法 1234567891011121314151617181920/** * SpringBoot启动类 * 打成war包时需要改造 继承SpringBootServletInitializer实现configure方法 * 打jar包则不需要 * * @author illusoryCloud */@SpringBootApplicationpublic class HelloApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; //这里的HelloApplication是SpringBoot的启动类 return builder.sources(HelloApplication.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(HelloApplication.class, args); &#125;&#125; 3. 打包和上面打包的方式一样的 12345678910111213[INFO] Packaging webapp[INFO] Assembling webapp [hello] in [D:\lillusory\MyProjects\hello\target\hello-0.0.1-SNAPSHOT][INFO] Processing war project[INFO] Webapp assembled in [472 msecs][INFO] Building war: D:\lillusory\MyProjects\hello\target\hello-0.0.1-SNAPSHOT.war[INFO] --- spring-boot-maven-plugin:2.1.3.RELEASE:repackage (repackage) @ hello ---[INFO] Replacing main artifact with repackaged archive[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 01:00 min[INFO] Finished at: 2019-02-22T21:10:10+08:00[INFO] ------------------------------------------------------------------------ 可以看到打出来的war包在D:\lillusory\MyProjects\hello\target\hello-0.0.1-SNAPSHOT.war 4. 测试先在电脑上测试一下(Windows环境下) 将war包复制到Tomcat的webapps文件夹下 然后找到bin目录下的startup.bat启动Tomcat，项目就会自动启动了。 浏览器访问http://localhost:8080/hello-0.0.1-SNAPSHOT/hello 出现hello illusoryCloud说明ok的。 这里hello-0.0.1-SNAPSHOT就是war包的名称，Tomcat启动时会自动解压war包然后启动项目。 这里的端口号和application.yml全局配置文件中配置的端口号没有关系，是Tomcat中配置的。 在Tomcat\conf\server.xml这个文件中，默认也是8080。 问题 我这里启动的时候出现了一个问题 Caused by: java.lang.NoClassDefFoundError: javax/el/ELManager 最后找到原因是tomcat提供的el-api.jar 和项目里面的el-api.jar冲突; 这时候你需要去找到自己电脑上用的el-api的版本,copy到tomcat的lib目录下,覆盖原来的jar包. 我的在IntelliJ IDEA 2018.3\lib\rt\jasper2.1\el-api.jar这个目录下 我看网上说是和Tomcat版本有关系，我这里是7.0.52 Tomcat日志 若是还有其他问题的话可以查看Tomcat日志。在tomcat\logs\catalina.2019-02-22.log这个文件中。 3. 部署3.1 jar包首先将文件上传到服务器上，服务器上有安装JDK8及以上的版本就可以直接运行。 Linux下JDK的安装及配置点这里 1. 前台运行1$ java -jar hello-0.0.1-SNAPSHOT.jar 但是这样运行的话是在前台运行，当前窗口关闭后就停止了,或者是运行时没法切出去执行其他任务. 2. 后台运行123456$ nohup java -jar hello-0.0.1-SNAPSHOT.jar &gt;temp.txt &amp;//nohup 意思是不挂断运行命令,当账户退出或终端关闭时,程序仍然运行//这种方法会把日志文件输入到你指定的文件中(temp.txt)//在哪个目录下运行的该日志文件就会在哪个目录下，没有指定具体文件则会自动创建(nohup.out)//&amp; 表示后台运行 3. 问题执行以上命令后出现下面的提示 12nohup: ignoring input and redirecting stderr to stdout忽略输出 将错误输出重定向到标准输出 原因 Linux中0、1和2分别表示标准输入、标准输出和标准错误信息输出，可以用来指定需要重定向的标准输入或输出。在一般使用时，默认的是标准输出，即1。 例如：2&gt;temp.txt 就是将错误信息写入temp.txt 标准输出还是显示在屏幕上。 另外，也可以实现0，1，2之间的重定向。2&gt;&amp;1：将错误信息重定向到标准输出。 Linux下还有一个特殊的文件/dev/null，它就像一个无底洞，所有重定向到它的信息都会消失得无影无踪。 如果想要正常输出和错误信息都不显示，则要把标准输出和标准错误都重定向到/dev/null， 例如： 1&gt;/dev/null 2&gt;/dev/null 解决办法 所以最后的命令就是 1nohup java -jar hello-0.0.1-SNAPSHOT.jar &gt;temp.txt 2&gt;&amp;1&amp; 123[root@localhost software]# nohup java -jar hello-0.0.1-SNAPSHOT.jar &gt;temp.txt 2&gt;&amp;1&amp;[1] 22804// 成功启动 pid为22804 4. 测试首先查看服务器的IP 12345678910111213141516171819[root@localhost software]# ip addr1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever2: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:8a:48:7d brd ff:ff:ff:ff:ff:ff inet 192.168.1.111/24 brd 192.168.1.255 scope global noprefixroute ens33 valid_lft forever preferred_lft forever inet6 fe80::20c:29ff:fe8a:487d/64 scope link valid_lft forever preferred_lft forever3: virbr0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000 link/ether 52:54:00:8e:d5:31 brd ff:ff:ff:ff:ff:ff inet 192.168.122.1/24 brd 192.168.122.255 scope global virbr0 valid_lft forever preferred_lft forever4: virbr0-nic: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc pfifo_fast master virbr0 state DOWN group default qlen 1000 link/ether 52:54:00:8e:d5:31 brd ff:ff:ff:ff:ff:ff 然后浏览器访问http://192.168.1.111:8080/hello出现hello illusoryCloud说明成功了。 记得关闭防火墙或者开放8080端口 5. 相关Linux命令 jobs命令和 fg命令 123456$ jobs//那么就会列出所有后台执行的作业，并且每个作业前面都有个编号。[root@localhost software]# jobs[1]+ Running nohup java -jar hello-0.0.1-SNAPSHOT.jar &gt; temp.txt 2&gt;&amp;1 &amp;//如果想将某个作业调回前台控制，只需要 fg + 编号即可。$ fg 1 查看某端口占用的线程的pid 1netstat -nlp |grep :8080 kill 1kill pid 3.2 war包war包运行和在windows上运行其实一样的，也是先将war包copy到Tomcat的webapps目录下，然后启动Tomcat，如果上面测试出现jar包冲突的话这里也需要替换。 Linux下Tomcat安装及配置点这里 启动Tomcat进入Tomcat\bin目录执行./startup.sh即可 1234567[root@localhost bin]# ./startup.sh Using CATALINA_BASE: /usr/local/tomcatUsing CATALINA_HOME: /usr/local/tomcatUsing CATALINA_TMPDIR: /usr/local/tomcat/tempUsing JRE_HOME: /usr/local/jdk8Using CLASSPATH: /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jarTomcat started. 浏览器访问http://192.168.1.111:8080/hello-0.0.1-SNAPSHOT/hello出现hello illusoryCloud说明是没问题的。 4. 参考https://blog.csdn.net/qq_22638399/article/details/81506448 https://blog.csdn.net/c1481118216/article/details/53010963 https://blog.csdn.net/qq_14853889/article/details/80026885]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门系列(三)---Spring Boot 整合 Mybatis]]></title>
    <url>%2Fposts%2F1889ad71.html</url>
    <content type="text"><![CDATA[本文主要记录了如何在SpringBoot项目中整合Mybatis框架与Druid数据库连接池,同时超详细的记录了具体步骤与代码实现。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. DruidDruid 是阿里巴巴开源平台上的一个项目，整个项目由数据库连接池、插件框架和 SQL 解析器组成。该项目主要是为了扩展 JDBC 的一些限制，可以让程序员实现一些特殊的需求，比如向密钥服务请求凭证、统计 SQL 信息、SQL 性能收集、SQL 注入检查、SQL 翻译等，程序员可以通过定制来实现自己需要的功能。 Druid 是目前最好的数据库连接池，在功能、性能、扩展性方面，都超过其他数据库连接池，包括 DBCP、C3P0、BoneCP、Proxool、JBoss DataSource。Druid 已经在阿里巴巴部署了超过 600 个应用，经过多年生产环境大规模部署的严苛考验。Druid 是阿里巴巴开发的号称为监控而生的数据库连接池！ 1.1 引入依赖在 pom.xml 文件中引入 druid-spring-boot-starter 依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt; 引入数据库连接mysql-connector-java依赖 12345&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 1.2 配置 application.yml在 application.yml 中配置数据库连接 12345678910111213spring: datasource: druid: url: jdbc:mysql://ip:port/dbname?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 initial-size: 1 min-idle: 1 max-active: 20 test-on-borrow: true # MySQL 5.x: com.mysql.jdbc.Driver # MySQL 8.x: com.mysql.cj.jdbc.Driver driver-class-name: com.mysql.cj.jdbc.Driver 2. Mybatis2.1 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt; &lt;/dependency&gt; 2.2 配置 application.yml123mybatis: type-aliases-package: com.illusory.hello.spring.boot.domain mapper-locations: classpath:mapper/*.xml 3. 测试3.1 创建数据库123456789CREATE DATABASE hello;USE hello;CREATE TABLE users(uid INT(5) AUTO_INCREMENT COMMENT &apos;用户ID&apos;,uname VARCHAR(20) COMMENT &apos;用户名&apos;,uage INT(3) COMMENT &apos;用户年龄&apos;,PRIMARY KEY(uid)) COMMENT=&apos;用户表&apos;;INSERT INTO users VALUES(NULL,&apos;zhangsan&apos;,11),(NULL,&apos;lisi&apos;,22),(NULL,&apos;wangwu&apos;,33); 3.2 User12345678910111213package com.illusory.hello.spring.boot.domain;/** * @author illusoryCloud * @version 1.0.0 * @date 2019/3/15 13:58 */public class User &#123; private int uid; private String uname; private int uage; //省略Getter/Setter&#125; 3.3 UserMappercom/illusory/hello/spirng/boot/mapper/UserMapper 12345678910package com.illusory.hello.spring.boot.mapper;/** * @author illusoryCloud * @version 1.0.0 * @date 2019/3/15 13:58 */public interface UserMapper &#123; List&lt;User&gt; queryAll();&#125; resources/mapper/UserMapper.xml 12345678&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.illusory.hello.spring.boot.mapper.UserMapper"&gt;&lt;select id="queryAll" resultType="user"&gt; SELECT u.uid,u.uname,u.uage FROM users as u&lt;/select&gt;&lt;/mapper&gt; 3.4 Serivce12345678910package com.illusory.hello.spring.boot.service;/** * @author illusoryCloud * @version 1.0.0 * @date 2019/3/15 14:08 */public interface UserService &#123; List&lt;User&gt; queryAll();&#125; 1234567891011121314151617package com.illusory.hello.spring.boot.service.impl;/** * @author illusoryCloud * @version 1.0.0 * @date 2019/3/15 14:09 */@Servicepublic class UserServiceImpl implements UserService &#123; @Resource private UserMapper userMapper; @Override public List&lt;User&gt; queryAll() &#123; return userMapper.queryAll(); &#125;&#125; 3.5 UserController12345678910111213141516171819package com.illusory.hello.spring.boot.controller;/** * @author illusoryCloud * @version 1.0.0 * @date 2019/3/15 14:34 */@Controllerpublic class UserController &#123; @Autowired private UserService userService; @RequestMapping(value = "/users", method = RequestMethod.GET) public String users(Model model) &#123; List&lt;User&gt; users = userService.queryAll(); model.addAttribute("users", users); return "index"; &#125;&#125; 3.6 HTML12345678910111213&lt;!DOCTYPE html SYSTEM "http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-spring4-4.dtd"&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;用户列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;div th:each="user : $&#123;users&#125;"&gt; &lt;div th:text="$&#123;user.uname&#125;"&gt;&lt;/div&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3.7 测试浏览器访问localhost:8080/users显示 123zhangsanlisiwangwu 到此SpringBoot整合Mybatis完成。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门系列(二)---Spring Boot 整合 Thymeleaf]]></title>
    <url>%2Fposts%2F730d2e5e.html</url>
    <content type="text"><![CDATA[本文主要记录了如何在SpringBoot项目中使用Thymeleaf，同时简要分析了Thymeleaf模板引擎的优缺点与基本语法。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Thymeleaf简介Thymeleaf 是一个跟 Velocity、FreeMarker 类似的模板引擎，它可以完全替代 JSP 。相较与其他的模板引擎，它有如下三个极吸引人的特点 Thymeleaf 在有网络和无网络的环境下皆可运行，即它可以让美工在浏览器查看页面的静态效果，也可以让程序员在服务器查看带数据的动态页面效果。这是由于它支持 html 原型，然后在 html 标签里增加额外的属性来达到模板 + 数据的展示方式。浏览器解释 html 时会忽略未定义的标签属性，所以 thymeleaf 的模板可以静态地运行；当有数据返回到页面时，Thymeleaf 标签会动态地替换掉静态内容，使页面动态显示。 Thymeleaf 开箱即用的特性。它提供标准和 Spring 标准两种方言，可以直接套用模板实现 JSTL、 OGNL 表达式效果，避免每天套模板、改 JSTL、改标签的困扰。同时开发人员也可以扩展和创建自定义的方言。 Thymeleaf 提供 Spring 标准方言和一个与 SpringMVC 完美集成的可选模块，可以快速的实现表单绑定、属性编辑器、国际化等功能。 2. 为什么使用 Thymeleaf如果希望以 Jar 形式发布模块则尽量不要使用 JSP 相关知识，这是因为 JSP 在内嵌的 Servlet 容器上运行有一些问题 (内嵌 Tomcat、 Jetty 不支持 Jar 形式运行 JSP，Undertow 不支持 JSP)。 Spring Boot 中推荐使用 Thymeleaf 作为模板引擎，因为 Thymeleaf 提供了完美的 Spring MVC 支持 Spring Boot 提供了大量模板引擎，包括： FreeMarker Groovy Mustache Thymeleaf Velocity Beetl 3. 使用1. 引入依赖主要增加 spring-boot-starter-thymeleaf 和 nekohtml 这两个依赖 123456789 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt; &lt;/dependency&gt; spring-boot-starter-thymeleaf：Thymeleaf 自动配置 nekohtml：允许使用非严格的 HTML 语法 完整的 pom.xml 如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--注意这里继承了父项目spring-boot-starter-parent--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.illusory&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-boot&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;hello-spring-boot&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--两个依赖spring-boot-starter-web和test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--Thymeleaf Begin--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt; &lt;/dependency&gt; &lt;!--Thymeleaf End--&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2. 在 application.yml中配置 Thymeleaf1234567spring: thymeleaf: cache: false # 开发时关闭缓存,不然没法看到实时页面 mode: HTML # 用非严格的 HTML encoding: UTF-8 servlet: content-type: text/html 3. HTML引入 Thymeleaf修改 html 标签用于引入 thymeleaf 引擎，这样才可以在其他标签里使用 th:* 语法，这是下面语法的前提。 12&lt;!DOCTYPE html SYSTEM "http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-spring4-4.dtd"&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt; 4. 演示controller在前面的controller中增加一个hi()方法。 123456789101112131415161718192021222324252627package com.illusory.hello.spring.boot;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;/** * @author illusoryCloud * @version 1.0.0 * @date 2019/3/15 12:36 */@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping(value = "/hello", method = RequestMethod.GET) public String hello() &#123; return "hello spring boot!"; &#125; @RequestMapping(value = "/hi", method = RequestMethod.GET) public String hi(Model model) &#123; model.addAttribute("name", "SpringBoot"); return "index"; &#125;&#125; index.html1234567891011&lt;!DOCTYPE html SYSTEM "http://www.thymeleaf.org/dtd/xhtml1-strict-thymeleaf-spring4-4.dtd"&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;首页&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p th:text="'Hello！ ' + $&#123;name&#125; + '!'" &gt;spring&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 非常简单的一个页面，直接打开时会显示spring，浏览器在解析HTML时会自动忽略掉无法识别的标签。 然后程序启动后在访问则会显示Hello！SpringBoot！ 4. 常用语法获取变量值1&lt;p th:text="'Hello！ ' + $&#123;name&#125; + '!'" &gt;name&lt;/p&gt; 可以看出获取变量值用 $ 符号,对于javaBean的话使用 变量名.属性名 方式获取,这点和 EL 表达式一样. 另外 $ 表达式只能写在th标签内部,不然不会生效,上面例子就是使用 th:text 标签的值替换 p 标签里面的值,至于 p 里面的原有的值只是为了给前端开发时做展示用的.这样的话很好的做到了前后端分离。 引入 URLThymeleaf 对于 URL 的处理是通过语法 @{…} 来处理的 123&lt;a th:href="@&#123;http://www.baidu.com&#125;"&gt;绝对路径&lt;/a&gt;&lt;a th:href="@&#123;/&#125;"&gt;相对路径&lt;/a&gt;&lt;a th:href="@&#123;css/bootstrap.min.css&#125;"&gt;Content路径,默认访问static下的css文件夹&lt;/a&gt; 类似的标签有:th:href 和 th:src 字符串替换很多时候可能我们只需要对一大段文字中的某一处地方进行替换，可以通过字符串拼接操作完成： 1&lt;span th:text="'Welcome to our application, ' + $&#123;user.name&#125; + '!'"&gt; 一种更简洁的方式是： 1&lt;span th:text="|Welcome to our application, $&#123;user.name&#125;!|"&gt; 当然这种形式限制比较多，|…|中只能包含变量表达式${…}，不能包含其他常量、条件表达式等。 运算符在表达式中可以使用各类算术运算符，例如+, -, *, /, % 1th:with="isEven=($&#123;prodStat.count&#125; % 2 == 0)" 逻辑运算符&gt;, &lt;, &lt;=,&gt;=，==,!=都可以使用，唯一需要注意的是使用&lt;,&gt;时需要用它的HTML转义符： 12th:if="$&#123;prodStat.count&#125; &amp;gt; 1"th:text="'Execution mode is ' + ( ($&#123;execMode&#125; == 'dev')? 'Development' : 'Production')" 条件if/unlessThymeleaf 中使用 th:if 和 th:unless 属性进行条件判断，下面的例子中，标签只有在 th:if 中条件成立时才显示： 1&lt;a th:href="@&#123;/login&#125;" th:unless=$&#123;session.user != null&#125;&gt;Login&lt;/a&gt; th:unless 于 th:if 恰好相反，只有表达式中的条件不成立，才会显示其内容。 switchThymeleaf 同样支持多路选择 Switch 结构： 1234&lt;div th:switch="$&#123;user.role&#125;"&gt; &lt;p th:case="'admin'"&gt;User is an administrator&lt;/p&gt; &lt;p th:case="#&#123;roles.manager&#125;"&gt;User is a manager&lt;/p&gt;&lt;/div&gt; 默认属性 default 可以用 * 表示： 12345&lt;div th:switch="$&#123;user.role&#125;"&gt; &lt;p th:case="'admin'"&gt;User is an administrator&lt;/p&gt; &lt;p th:case="#&#123;roles.manager&#125;"&gt;User is a manager&lt;/p&gt; &lt;p th:case="*"&gt;User is some other thing&lt;/p&gt;&lt;/div&gt; 循环渲染列表数据是一种非常常见的场景，例如现在有 n 条记录需要渲染成一个表格，该数据集合必须是可以遍历的，使用 th:each 标签： 1234567891011121314151617181920&lt;body&gt; &lt;h1&gt;Product list&lt;/h1&gt; &lt;table&gt; &lt;tr&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;th&gt;PRICE&lt;/th&gt; &lt;th&gt;IN STOCK&lt;/th&gt; &lt;/tr&gt; &lt;tr th:each="prod : $&#123;prods&#125;"&gt; &lt;td th:text="$&#123;prod.name&#125;"&gt;Onions&lt;/td&gt; &lt;td th:text="$&#123;prod.price&#125;"&gt;2.41&lt;/td&gt; &lt;td th:text="$&#123;prod.inStock&#125;? #&#123;true&#125; : #&#123;false&#125;"&gt;yes&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;p&gt; &lt;a href="../home.html" th:href="@&#123;/&#125;"&gt;Return to home&lt;/a&gt; &lt;/p&gt;&lt;/body&gt; 可以看到，需要在被循环渲染的元素（这里是）中加入 th:each 标签，其中 th:each=&quot;prod : ${prods}&quot; 意味着对集合变量 prods 进行遍历，循环变量是 prod 在循环体中可以通过表达式访问。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot入门系列(一)---第一个SpringBoot项目]]></title>
    <url>%2Fposts%2F6c30e894.html</url>
    <content type="text"><![CDATA[本文主要讲述了Spring框架的变化，从Spring1.0到Spring5.0，从xml配置到注解，到现在的SpringBoot，最后记录了如何创建第一个SpringBoot项目。 前面写摘要 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Spring 简史Spring 1.x 时代在 Spring1.x 时代，都是通过 xml 文件配置 bean，随着项目的不断扩大，需要将 xml 配置分放到不同的配置文件中，需要频繁的在 java 类和 xml 配置文件中切换。 Spring 2.x 时代随着 JDK 1.5 带来的注解支持，Spring2.x 可以使用注解对 Bean 进行申明和注入，大大的减少了 xml 配置文件，同时也大大简化了项目的开发。 那么，问题来了，究竟是应该使用 xml 还是注解呢？ 最佳实践： 应用的基本配置用 xml，比如：数据源、资源文件等 业务开发用注解，比如：Service 中注入 bean 等 Spring 3.x 时代从 Spring3.x 开始提供了 Java 配置方式，使用 Java 配置方式可以更好的理解你配置的 Bean，现在我们就处于这个时代，并且 Spring4.x 和 Spring boot 都推荐使用 java 配置的方式。 Spring 5.x 时代Spring5.x 是 Java 界首个支持响应式的 Web 框架，是 Spring 的一个重要版本，距离 Spring4.x 差不多四年。在此期间，大多数增强都是在 SpringBoot 项目中完成的，其最大的亮点就是提供了完整的端到端响应式编程的支持（新增 Spring WebFlux 模块）。 Spring WebFlux 同时支持使用旧的 Spring MVC 注解声明 Reactive Controller。和传统的 MVC Controller 不同，Reactive Controller 操作的是 非阻塞 的 ServerHttpRequest 和 ServerHttpResponse，而不再是 Spring MVC 里的 HttpServletRequest 和 HttpServletResponse。 至此也代表着 Java 正式迎来了响应式异步编程的时代。 2. Spring Boot2.1 简介Spring Boot 可以称之为 新一代 JavaEE 开发标准；随着动态语言的流行 (Ruby、Groovy、Scala、Node.js)，Java 的开发显得格外的笨重：繁多的配置、低下的开发效率、复杂的部署流程以及第三方技术集成难度大。 在上述环境下，Spring Boot 应运而生。它使用 “习惯优于配置” （项目中存在大量的配置，此外还内置了一个习惯性的配置，让你无需手动进行配置）的理念让你的项目快速的运行起来。使用 Spring Boot 很容易创建一个独立运行（运行 Jar，内嵌 Servlet 容器）准生产级别的基于 Spring 框架的项目，使用 Spring Boot 你可以不用或者只需很少的 Spring 配置。 2.2 优点 快速构建项目 对主流开发框架的无配置集成 项目可独立运行，无需外部依赖 Servlet 容器 提供运行时的应用监控 极大地提高了开发、部署效率 与云计算的天然集成 2.3 缺点 版本迭代速度很快，一些模块改动很大 由于不用自己做配置，报错时很难定位 网上现成的解决方案比较少 3. 第一个SpringBoot项目这里我们使用 Intellij IDEA 来新建一个 Spring Boot 项目。 3.1 创建项目 打开 IDEA -&gt; New Project -&gt; Spring Initializr 2.填写项目信息 3.选择 Spring Boot 版本及 Web 开发所需的依赖 4.保存项目到指定目录 3.2 工程目录结构 一个标准的maven项目。 HelloSpringApplication作为SpringBoot启动类。 resources/static目录存放静态资源文件 resources/templates目录存放html页面。 application.properties为SpringBoot配置文件 Application.class12345678910111213package com.illusory.hello.spring.boot;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class HelloSpringBootApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(HelloSpringBootApplication.class, args); &#125;&#125; 启动类非常简单，其中@SpringBootApplication注解表明这是SpringBoot启动类。 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--注意这里继承了父项目spring-boot-starter-parent--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.illusory&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-boot&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;hello-spring-boot&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--两个依赖spring-boot-starter-web和test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 可以看到项目中有两个依赖spring-boot-starter-web和spring-boot-starter-test。 其中test是都会有的，然后web则是前面勾选的模块。 可以看到已经依赖了Spring各大组件，同时还依赖了一个Tomcat,所以SpringBoot项目是可以独立运行的，因为内置了Tomcat。 4. 功能演示1234567891011121314151617181920package com.illusory.hello.spring.boot;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.ResponseBody;/** * @author illusoryCloud * @version 1.0.0 * @date 2019/3/15 12:36 */@Controllerpublic class HelloController &#123; @ResponseBody @RequestMapping(value = "/hello", method = RequestMethod.GET) public String hello() &#123; return "hello spring boot!"; &#125;&#125; 启动 HelloSpringBootApplication 的 main() 方法，浏览器访问 http://localhost:8080/hello可以看到： 1hello spring boot! 5. 神奇之处 没有配置 web.xml 没有配置 application.xml，Spring Boot 帮你配置了 没有配置 application-mvc.xml，Spring Boot 帮你配置了 没有配置 Tomcat，Spring Boot 内嵌了 Tomcat 容器 6. 自动配置原理Spring Boot的启动类上有一个@SpringBootApplication注解，这个注解是Spring Boot项目必不可少的注解。 123456789101112131415161718192021222324252627282930313233343536373839//SpringBootApplication.class@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125;), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125;)&#125;)public @interface SpringBootApplication &#123; @AliasFor( annotation = EnableAutoConfiguration.class ) Class&lt;?&gt;[] exclude() default &#123;&#125;; @AliasFor( annotation = EnableAutoConfiguration.class ) String[] excludeName() default &#123;&#125;; @AliasFor( annotation = ComponentScan.class, attribute = "basePackages" ) String[] scanBasePackages() default &#123;&#125;; @AliasFor( annotation = ComponentScan.class, attribute = "basePackageClasses" ) Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;;&#125; 可以看到这是个复合注解，其中有一个是@EnableAutoConfiguration,开启自动配置，说明SpringBoot配置肯定和这个有关。 1234567891011121314//EnableAutoConfiguration.class@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(&#123;AutoConfigurationImportSelector.class&#125;)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; 这个注解也是一个派生注解，其中的关键功能由@Import({AutoConfigurationImportSelector.class})提供，其导入的AutoConfigurationImportSelector的selectImports()方法通过SpringFactoriesLoader.loadFactoryNames()扫描所有具有META-INF/spring.factories的jar包。spring-boot-autoconfigure-x.x.x.x.jar里就有一个这样的spring.factories文件。 最终@EnableAutoConfiguration注解通过@SpringBootApplication被间接的标记在了Spring Boot的启动类上。在SpringApplication.run(...)的内部就会执行selectImports()方法，找到所有JavaConfig自动配置类的全限定名对应的class，然后将所有自动配置类加载到Spring容器中。 Spring Boot关于自动配置的源码在spring-boot-autoconfigure-x.x.x.x.jar中： 可以看到SpringBoot提供了很多的默认配置，在我们没有手动配置时就会使用提供的默认配置。SpringBoot提倡的约定大于配置。 参考《Spring boot实战》 https://blog.csdn.net/u014745069/article/details/83820511]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL主从复制与双主互备]]></title>
    <url>%2Fposts%2F846f909.html</url>
    <content type="text"><![CDATA[本文主要讲述了MySQL的主从复制与双主互备的作用与好处，并且记录了具体的搭建过程与过程中的常见问题。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介1.1 什么是主从复制?主从复制，是用来建立一个和主数据库完全一样的数据库环境，称为从数据库；主数据库一般是准实时的业务数据库。 1.2 主从复制的作用 1.做数据的热备，作为后备数据库，主数据库服务器故障后，可切换到从数据库继续工作，避免数据丢失。 2.架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。 3.读写分离，使数据库能支撑更大的并发。在报表中尤其重要。由于部分报表sql语句非常的慢，导致锁表，影响前台服务。如果前台使用master，报表使用slave，那么报表sql将不会造成前台锁，保证了前台速度。 1.3 主从复制的原理 数据库有个bin-log二进制文件，记录了所有sql语句。 我们的目标就是把主数据库的bin-log文件的sql语句复制到从库。 让其在从机的relay-log重做日志文件中再执行一次这些sql语句即可。 1.4 大致流程对于每一个主从复制的连接，都有三个线程。 1.binlog输出线程 :每当有从库连接上主库时，主库就会创建一个线程然后发送binlog文件到从库。 2.从库I/O线程 :当START SLAVE语句在从库开始执行之后，从库创建一个I/O线程，该线程连接到主库并请求主库发送binlog里面的更新记录到从库上。从库I/O线程读取主库的binlog输出线程发送的更新并拷贝这些更新到本地文件，其中包括relay log文件。 3.从库的SQL线程:从库创建一个SQL线程，这个线程读取从库I/O线程写到relay log的更新事件并执行。 拥有多个从库的主库为每一个连接到主库的从库创建一个binlog输出线程，每一个从库都有它自己的I/O线程和SQL线程。 1.5 具体流程 1.主库db的更新事件(update、insert、delete)被写到binlog。 2.从库发起连接，连接到主库。 3.此时主库创建一个binlog dump thread线程，把binlog的内容发送到从库。 4.从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log。 5.还会创建一个SQL线程，从relay log里面读取内容，从Exec_Master_Log_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db。 2. 环境准备2.1 所需环境先准备两台服务器，且安装好mysql。必须保证两台机器上的mysql中数据是一致的，不然主从复制时可能会出现问题。 如果两台机器数据不一致，比如先有主机后加的从机，此时可以先复制主机数据到从机，在配置主从复制。 2.2 手动同步数据库先在主机上执行以下SQL，锁定表中数据。 12mysql&gt; flush table with read lock;Query OK, 0 rows affected (0.01 sec) 不要退出这个终端，否则这个锁就失效了。 在不退出终端的情况下，再开启一个终端直接打包压缩数据文件或使用mysqldump工具导出数据。这里通过打包mysql文件来完成数据的备份，操作过程如下： 一、导出数据库1、导出数据和表结构： 12# 格式：mysqldump -u用户名 -p密码 数据库名 &gt; 数据库名.sql# /usr/local/mysql/bin/ mysqldump -uroot -proot test &gt; test.sql 2、只导出表结构： 12# 格式：mysqldump -u用户名 -p密码 -d 数据库名 &gt; 数据库名.sql# /usr/local/mysql/bin/ mysqldump -uroot -proot -d test &gt; test.sql 具体如下： 123456#创建保存备份文件的文件夹[root@localhost ~]# mkdir -p /usr/local/mysql/data/backup #创建备份文件并压缩[root@localhost ~]# /usr/local/mysql/bin/mysqldump -uroot -p 'root' --events -A -B |gzip &gt;/usr/local/mysql/data/backup/mysql_bak.$(date +%F).sql.gz# 用scp将备份文件复制到从机上[root@localhost ~]# scp /usr/local/mysql/data/backup/mysql_bak.2019-03-12.sql.gz root@192.168.5.151:/usr/local/mysql/data/backup 备份结束后，解锁主库，恢复读写 12mysql&gt; unlock tables;Query OK, 0 rows affected (0.00 sec) 从库进行同步： 1234# 解压[root@localhost backup]# gunzip mysql_bak.2019-03-12.sql.gz #导入SQL文件[root@localhost backup]# mysql -uroot -p &lt;mysql_bak.2019-03-12.sql 或者用另一种导入方法： 12345678#1.首先建空数据库mysql&gt;create database abc;#2.选择数据库mysql&gt;use abc;#3.设置数据库编码mysql&gt;set names utf8;#4.导入数据（注意sql文件的路径）mysql&gt;source /usr/local/mysql/data/backup/mysql_bak.2019-03-12.sql; 3. 搭建主从复制3.1 修改配置文件主机Master：192.168.5.153 从机Slave：192.168.5.151 在默认情况下，MySQL的配置文件是/etc/my.cnf,首先修改Mater主机的配置文件， 1[root@localhost bin]# vim /etc/my.cnf 在Master的/etc/my.cnf文件中的[mysqld]段添加如下内容： 123456789101112#节点标识，主、从节点不能相同，必须全局唯一 一般填ip最后几位server-id=153#开启MySQL的binlog日志功能。“mysql-bin”表示日志文件的命名格式#生成文件名为mysql-bin.000001、mysql-bin.000002等的日志文件log-bin=mysql-bin#定义relay-log日志文件的命名格式relay-log=mysql-relay-bin#复制过滤选项，可以过滤不需要复制的数据库或表，例如“mysql.%”表示不复制MySQL库下的所有对象replicate-wild-ignore-table=mysql.%replicate-wild-ignore-table=information_schema.%# 指定需要复制的数据库或表 test数据库下的所有表都复制replicate-wild-do-table=test.% 接着修改Slave从机的配置文件 123456789101112#节点标识，主、从节点不能相同，必须全局唯一 一般填ip最后几位server-id=151#开启MySQL的binlog日志功能。“mysql-bin”表示日志文件的命名格式#生成文件名为mysql-bin.000001、mysql-bin.000002等的日志文件log-bin=mysql-bin#定义relay-log日志文件的命名格式relay-log=mysql-relay-bin#复制过滤选项，可以过滤不需要复制的数据库或表，例如“mysql.%”表示不复制MySQL库下的所有对象replicate-wild-ignore-table=mysql.%replicate-wild-ignore-table=information_schema.%# 指定需要复制的数据库或表,与上面replicate-wild-do-table=test.% 特别注意: 生产库上一般不建议设置过滤规则, 如果非要设置, 强烈建议从库使用通配符方式过滤某个库。 从库可以使用通配符&quot;库名.%&quot;方式过滤主从同步时某个库的设置 12replicate-wild-do-table=webdb.% #只复制webdb库下的所有表`replicate-wild-ignore-table=mysql.% #忽略mysql库下的所有表 温馨提示：在实际业务场景中，mysq主从同步时最好别过滤库，即最好进行基于整个数据库的同步配置。如果业务库比较多的情况下，可使用mysql多实例方式进行同步，一个业务库对应一个mysql实例，每个mysql实例做基于它的整个数据库的同步配置。使用过滤库或过滤表的方式进行主从同步配置，后续会带来一些比较麻烦的坑。 12replicate-wild-dO-table= "库名.%"replicate-wild-ignore-table= "库名.%" 而不建议从库使用DB方式过滤某个库: 12replicate_do_db ="库名"replicate_ingore_db ="库名" 3.2 创建复制用户首先在Mater的MySQL库中创建复制用户给Slave复制时使用，操作过程如下： 1234567891011[root@localhost bin]# /etc/init.d/mysqld restart#@ 前面的那个是 用户名 后面的是主机地址 %表示所有 最后的root是密码mysql&gt; grant replication slave on *.* to &apos;repl_user&apos;@&apos;192.168.5.151&apos; identified by &apos;root&apos;;Query OK, 0 rows affected (0.01 sec)mysql&gt; show master status; +------------------+----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000001 | 686 | | | +------------------+----------+--------------+------------------+ 然后在Slave的MySQL库中将Mster设为自己的主服务器，操作如下： 1mysql&gt; change master to master_host=&apos;192.168.5.153&apos;,master_user=&apos;repl_user&apos;,master_password=&apos;root&apos;,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=686; 注意: master_log_file和master_log_pos两个选项，这两个选项的值是在master上通过SQL语句show master status查询到的结果。 接着就可以在Slave上启动slave服务了，可执行如下SQL命令： 1mysql&gt; start slave; 查看Slave上slave的运行状态： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061mysql&gt; show slave status\G;*************************** 1. row *************************** Slave_IO_State: Master_Host: 192.168.5.154 Master_User: repl_user Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 442 Relay_Log_File: mysql-relay-bin.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: test.% Replicate_Wild_Ignore_Table: mysql.%,information_schema.% Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 442 Relay_Log_Space: 154 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: NULLMaster_SSL_Verify_Server_Cert: No Last_IO_Errno: 1593 Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the --replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it). Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 1 Master_UUID: Master_Info_File: /usr/local/mysql/data/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: 190311 16:27:22 Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.00 sec) 这里需要重点关注的是Slave_IO_Running和Slave_SQL_Running，这两个就是在Slave节点上运行的主从复制线程，正常情况下这两个值都应该为Yes。 另外，还需要注意的是Slave_IO_State、Master_Host、Master_Log_File、Read_Master_Log_Pos、Relay_Log_File、Relay_Log_Pos和Relay_Master_Log_File几个选项，可以查看出MySQL复制的运行原理及执行规律。最后还有一个Replicate_Wild_Ignore_Table选项，这个是之前在my.cnf中添加过的，通过此选项的输出值可以知道过滤了哪些数据库。 到这里主从复制已经ok了。 3.3 测试在master上创建一个表，注意前面配置的时只复制test数据库中的数据，所以需要先建一个test数据库。 1234567891011121314mysql&gt; create database test;Query OK, 1 row affected (0.01 sec)mysql&gt; use test;Database changedmysql&gt; CREATE TABLE users( -&gt; uid INT PRIMARY KEY, -&gt; uname VARCHAR(20), -&gt; sex INT, -&gt; age INT -&gt; );Query OK, 0 rows affected (0.09 sec)mysql&gt; 创建好后slave查看一下 12345678910111213141516171819202122mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.00 sec)mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || test |+--------------------+5 rows in set (0.01 sec) 证明主从复制已经成功了。 4. 小结4.1 主从同步过程 1.在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制。 2.此时，Slave服务器的IO线程会通过在Master上已经授权的复制用户权限请求连接Master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容 3.Master服务器接收到来自Slave服务器的IO线程的请求后，其上负责复制的IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在Master服务器端记录的IO线程。返回的信息中除了binlog中的下一个指定更新位置。 4.当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（Mysql-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容 5.Slave服务器端的SQL线程会实时检测本地Relay Log中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点. 4.2 主从复制条件 开启Binlog功能 主库要建立账号 从库要配置master.info (CHANGE MASTER to…相当于配置密码文件和Master的相关信息) start slave 开启复制功能 4.3 主从复制时需要理解 3个线程，主库IO，从库IO和SQL及作用 master.info（从库）作用 relay-log 作用 异步复制 binlog作用 (如果需要级联需要开启Binlog) 4.4 主从复制时注意事项 主从复制是异步逻辑的SQL语句级的复制 复制时，主库有一个I/O线程，从库有两个线程，I/O和SQL线程 实现主从复制的必要条件是主库要开启记录binlog功能 作为复制的所有Mysql节点的server-id都不能相同 binlog文件只记录对数据库有更改的SQL语句（来自主库内容的变更），不记录任何查询（select，show）语句 彻底解除主从复制关系- stop slave;- reset slave; 或直接删除master.info和relay-log.info这两个文件；- 修改my.cnf删除主从相关配置参数。 4.5 常见问题1.数据丢失与复制延迟 主库宕机后，数据可能丢失 从库只有一个SQL Thread，主库写压力大，复制很可能延时 2. 解决方法 半同步复制—解决数据丢失的问题 并行复制—-解决从库复制延迟的问题 3. 半同步复制原理1.事务在主库写完binlog后需要从库返回一个已接受，才放回给客户端；2.5.5集成到mysql，以插件的形式存在，需要单独安装3.确保事务提交后binlog至少传输到一个从库4.不保证从库应用完成这个事务的binlog5.性能有一定的降低 6.网络异常或从库宕机，卡主库，直到超时或从库恢复 4. 并行复制社区版5.6中新增并行是指从库多线程apply binlog库级别并行应用binlog，同一个库数据更改还是串行的(5.7版并行复制基于事务组)设置设置sql线程数为10set global slave_parallel_workers=10; 5. 双主备份5.1 简介根据上面的主从环境部署，master和slave已经实现同步，即在master上写入新数据，自动同步到slave。而从库只能读不能写，一旦从库有写入数据，就会造成主从数据不一致！下面就说下Mysql主主复制环境，在slave上更新数据时，master也能自动同步过来。 温馨提示：在做主主同步前，提醒下需要特别注意的一个问题：主主复制和主从复制有一些区别，因为多主中都可以对服务器有写权限，所以设计到自增长重复问题，例如：出现的问题（多主自增长ID重复）1）首先在A和B两个库上创建test表结构;2）停掉A，在B上对数据表test(存在自增长属性的ID字段)执行插入操作，返回插入ID为1;3）然后停掉B，在A上对数据表test(存在自增长属性的ID字段)执行插入操作，返回的插入ID也是1;4）然后 同时启动A,B，就会出现主键ID重复 解决方法：只要保证两台服务器上的数据库里插入的自增长数据不同就可以了如：A插入奇数ID，B插入偶数ID，当然如果服务器多的话，还可以自定义算法，只要不同就可以了在下面例子中，在两台主主服务器上加入参数，以实现奇偶插入！记住:在做主主同步时需要设置自增长的两个相关配置，如下：auto_increment_offset 表示自增长字段从那个数开始，取值范围是1 .. 65535。这个就是序号。如果有n台mysql机器，则从第一台开始分为设1，2…nauto_increment_increment 表示自增长字段每次递增的量，其默认值是1，取值范围是1 .. 65535。如果有n台mysql机器，这个值就设置为n。 在主主同步配置时，需要将两台服务器的：auto_increment_increment 增长量都配置为2auto_increment_offset 分别配置为1和2。这是序号，第一台从1开始，第二台就是2，以此类推!这样效果就是：master的数据id是1,3,5,7…, slave的数据id是2,4,6,8….这样才可以避免两台服务器同时做更新时自增长字段的值之间发生冲突。（针对的是有自增长属性的字段） 5.2 修改配置文件Master的配置文件my.cnf 123456789#主主备份新增log-slave-updatessync_binlog = 1binlog_checksum = nonebinlog_format = mixed#防止ID自增重复 offset=1auto-increment-increment = 2 auto-increment-offset = 1 slave-skip-errors = all Slave的配置文件my.cnf 123456789#主主备份新增log-slave-updatessync_binlog = 1binlog_checksum = nonebinlog_format = mixed#防止ID自增重复 offset=2auto-increment-increment = 2 auto-increment-offset = 2 slave-skip-errors = all 5.3 创建同步用户同时在主从服务器建立一个连接帐户，该帐户必须授予REPLIATION SLAVE权限。这里因为服务器A和服务器B互为主从，所以都要分别建立一个同步用户。 Master 其实前面主机上已经创建了一个账户了，这里可以不用再创建的，不过还是写上。 12mysql&gt; grant replication slave on *.* to &apos;DoubleRel&apos;@&apos;192.168.5.151&apos; identified by &apos;root&apos;;mysql&gt; flush privileges; Slave 123mysql&gt; grant replication slave on *.* to &apos;DoubleRel&apos;@&apos;192.168.5.153&apos; identified by &apos;root&apos;;mysql&gt; flush privileges; 5.4 指定Master互相将对方作为Master Master 注意：master_log_file,master_log_pos这两个刚好是在对面的机器上查询出来的，即MAster上查出来的Position=150，那么在Slave上执行的命令就是master_log_pos=150 12345678mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000003 | 150 | | | |+------------------+----------+--------------+------------------+-------------------+mysql&gt;change master to master_host=&apos;192.168.5.151&apos;,master_user=&apos;DoubleRel&apos;,master_password=&apos;root&apos;,master_log_file=&apos;mysql-bin.000002&apos;,master_log_pos=150; Slave 12345678mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000003 | 150 | | | |+------------------+----------+--------------+------------------+-------------------+mysql&gt;change master to master_host=&apos;192.168.5.153&apos;,master_user=&apos;DoubleRel&apos;,master_password=&apos;root&apos;,master_log_file=&apos;mysql-bin.000003&apos;,master_log_pos=150; 5.5 开启SlaveMaster 1234567mysql&gt; start slave;Query OK, 0 rows affected (0.02 sec)mysql&gt; show slave status \G;#查看下面两项值均为Yes，即表示设置从服务器成功。Slave_IO_Running: YesSlave_SQL_Running: Yes saster 1234567mysql&gt; start slave;Query OK, 0 rows affected (0.02 sec)mysql&gt; show slave status \G;#查看下面两项值均为Yes，即表示设置从服务器成功。Slave_IO_Running: YesSlave_SQL_Running: Yes 5.6 测试现在Master中查询，只有users一张表 1234567mysql&gt; show tables;+----------------+| Tables_in_test |+----------------+| users |+----------------+1 row in set (0.00 sec) 然后在Slave中创建一张表 12345mysql&gt; CREATE TABLE orders( -&gt; oid INT PRIMARY KEY, -&gt; oname VARCHAR(20) -&gt; );Query OK, 0 rows affected (0.06 sec) Master中再次查询 12345678mysql&gt; show tables;+----------------+| Tables_in_test |+----------------+| orders || users |+----------------+2 rows in set (0.00 sec) ok，已经有两张表了，接着在Master中添加一张表 12345mysql&gt; CREATE TABLE account( -&gt; aid INT PRIMARY KEY, -&gt; aname VARCHAR(20) -&gt; );Query OK, 0 rows affected (0.04 sec) 然后在Slave中查询 123456789mysql&gt; show tables;+----------------+| Tables_in_test |+----------------+| account || orders || users |+----------------+3 rows in set (0.00 sec) 三张表都在，测试成功，说明双主备份搭建成功了。 6. 问题show slave status \G;查看状态时出现Slave_IO_Running: Connecting 可能的原因： 6.1 网络不通Master和Slave互相ping一下看能不能ping通 6.2 账户密码错误：检测生成的用户和配置的密码是否一致，就是下面的这两个地方。@前面的时账号 后面的是允许访问的主机地址，最后的root则是密码。 123mysql&gt; grant replication slave on *.* to &apos;DoubleRel&apos;@&apos;192.168.5.151&apos; identified by &apos;root&apos;;mysql&gt;change master to master_host=&apos;192.168.5.153&apos;,master_user=&apos;DoubleRel&apos;,master_password=&apos;root&apos;,master_log_file=&apos;mysql-bin.000003&apos;,master_log_pos=150; 6.3 防火墙可以先关闭防火墙在测试。 12systemctl stop firewalld # 临时关闭防火墙systemctl disable firewalld # 禁止开机启动 6.4 配置文件问题检查配置文件my.cnf是否有错误,注意语法。 6.5 连接服务器时语法还有就是设置Master时变量是否弄错，如下： 12345678mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000003 | 150 | | | |+------------------+----------+--------------+------------------+-------------------+mysql&gt;change master to master_host=&apos;192.168.5.153&apos;,master_user=&apos;DoubleRel&apos;,master_password=&apos;root&apos;,master_log_file=&apos;mysql-bin.000003&apos;,master_log_pos=150; show master status查询出来的结果是给对方用的，这里的master_log_file和master_log_pos是在对方的机器上查询出来的结果 6.6 主服务器mysql权限查看配置的账号能不能在本机上登录。 12345678910111213mysql&gt; select user,host from user;+---------------+---------------+| user | host |+---------------+---------------+| repl_user | % || DoubleRel | 192.168.5.151 || mysql.session | localhost || mysql.sys | localhost || root | localhost |+---------------+---------------+5 rows in set (0.00 sec)# 看下能不能登录[root@localhost ~]# mysql -uDoubleRel -proot -h192.168.5.151 7. 参考https://blog.csdn.net/darkangel1228/article/details/80004222 https://blog.51cto.com/superpcm/2094958 https://blog.csdn.net/darkangel1228/article/details/80003967 https://blog.csdn.net/ljw_jiawei/article/details/84188962]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper入门教程(三)---Watcher与分布式锁]]></title>
    <url>%2Fposts%2F4975d97e.html</url>
    <content type="text"><![CDATA[本文讲述了ZooKeeper的watch监听与ZooKeeper分布式锁的实现原理。 ZooKeeper入门系列文章目录 ZooKeeper入门教程(一)—安装与基本使用 ZooKeeper入门教程(二)—原生API与ACL权限认证 ZooKeeper入门教程(三)—Watcher与分布式锁 ….. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. ZooKeeper的watch监听1.1 简介 在 ZooKeeper 中，引入了 Watcher 机制来实现这种分布式的通知功能。ZooKeeper 允许客户端向服务端注册一个 Watcher 监听，当服务器的一些特定事件触发了这个 Watcher，那么就会向指定客户端发送一个事件通知来实现分布式的通知功能。 同样，其watcher是监听数据发送了某些变化，那就一定会有对应的事件类型, 和状态类型。 1.2 事件类型与节点相关。 EventType.NodeCreated EventType.NodeDataChanged EventType.NodeChildrenChanged EventType.NodeDeleted 1.3 状态类型与客户端实例相关。 KeeperState.Oisconnected KeeperState.SyncConnected KeeperState.AuthFailed KeeperState.Expired 1.4 持续监听ZooKeeper中有很多个节点，客户端也也可以new多个watcher，会开一个新的线程分别监听不同的节点，当监听的节点发送变化后，客户端就可以收到消息。其中watch可以看成是一个动作，是一次性的，watch一次就只能收到一次监听，节点别修改两次也只能收到第一次的通知。 两种持续监听方案： 1.收到变化后将Boolean值手动赋为true，表示下一次还要监听 2.再new一个watcher去监听 1.5 测试代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283@Testpublic void testWatch() throws KeeperException, InterruptedException, IOException &#123; Watcher watcher = new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; Event.EventType type = event.getType(); Event.KeeperState state = event.getState(); String path = event.getPath(); switch (state) &#123; case SyncConnected: System.out.println("state: SyncConnected"); System.out.println("path: " + path); waitZooKeeperConnOne.countDown(); break; case Disconnected: System.out.println("state: Disconnected"); System.out.println("path: " + path); break; case AuthFailed: System.out.println("state: AuthFailed"); System.out.println("path: " + path); break; case Expired: System.out.println("state: Expired"); System.out.println("path: " + path); break; default: System.out.println("state: default"); &#125; System.out.println("------------------------"); switch (type) &#123; case None: System.out.println("type: None"); System.out.println("path: " + path); break; case NodeCreated: System.out.println("type: NodeCreated"); System.out.println("path: " + path); break; case NodeDataChanged: System.out.println("type: NodeDataChanged"); System.out.println("path: " + path); break; case DataWatchRemoved: System.out.println("type: DataWatchRemoved"); System.out.println("path: " + path); break; case ChildWatchRemoved: System.out.println("type:child watch被移除"); System.out.println("path: " + path); break; case NodeChildrenChanged: System.out.println("type: NodeChildrenChanged"); System.out.println("path: " + path); break; case NodeDeleted: System.out.println("type: NodeDeleted"); System.out.println("path: " + path); break; default: System.out.println("type: default"); &#125; System.out.println("------------------------"); &#125; &#125;; String childPath = "/cloud/test5"; String childPath2 = "/cloud/test6"; String parentPath = "/cloud"; //创建时watch一次 1次 ZooKeeper z = new ZooKeeper(CONN_ADDR, SESSION_TIMEOUT, watcher); waitZooKeeperConnOne.await(); //这里也watch一次 2次 z.exists(childPath, true); z.create(childPath, "cloud".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); //watch一下父节点 即/cloud 3次 z.getChildren(parentPath, true); z.create(childPath2, "cloud".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); //再watch一次子节点 4次 z.exists(childPath, true); z.setData(childPath, "a".getBytes(), -1); Thread.sleep(1000);&#125; 1.5 watcher小结ZooKeeper 的 Watcher 具有以下几个特性。 1. 一次性无论是服务端还是客户端，一旦一个 Watcher 被触发，ZooKeeper 都会将其从相应的存储中移除。因此，在 Watcher 的使用上，需要反复注册。这样的设计有效地减轻了服务端的压力。 2. 客户端串行执行客户端 Watcher 回调的过程是一个串行同步的过程，这为我们保证了顺序，同时，需要注意的一点是，一定不能因为一个 Watcher 的处理逻辑影响了整个客户端的 Watcher 回调，所以，我觉得客户端 Watcher 的实现类要另开一个线程进行处理业务逻辑，以便给其他的 Watcher 调用让出时间。 3. 轻量WatcherEvent 是 ZooKeeper 整个 Watcher 通知机制的最小通知单元，这个数据结构中只包含三部分内容：通知状态、事件类型和节点路径。也就是说，Watcher 通知非常简单，只会告诉客户端发生了事件，而不会说明事件的具体内容。 例如针对 NodeDataChanged 事件，ZooKeeper 的Watcher 只会通知客户端指定数据节点的数据内容发生了变更，而对于原始数据以及变更后的新数据都无法从这个事件中直接获取到，而是需要客户端主动重新去获取数据——这也是 ZooKeeper 的 Watcher 机制的一个非常重要的特性。 2. ZooKeeper分布式锁2.1 为什么需要分布式锁并发相关的各种锁只能限制当前服务器上只能有一个用户或者线程访问加锁的资源，在单机部署环境下确实是没问题的，但是在有多台服务器的分布式环境下，并发相关的锁就不管用了，Nginx负载均衡将用户请求分到多台服务器上，每台服务器上都会有一个用户能访问到加锁的资源，这样就出现了并发问题，所以为了解决在分布式环境下的并发问题就出现了分布式锁。 2.2 相关概念1. 有序节点如果创建的是有序节点，那么zookeeper在生成子节点时会根据当前的子节点数量自动添加整数序号，也就是说如果是第一个创建的子节点，那么生成的子节点为/locker/node-0000000000，下一个节点则为/locker/node-0000000001，依次类推。 2. 临时节点ZooKeeper的临时节点时本次会话有效，等客户端执行完业务代码后关闭会话，临时节点就自动删除掉了。 3. 事件监听在读取数据时，我们可以同时对节点设置事件监听，当节点数据或结构变化时，zookeeper会通知客户端。当前zookeeper有如下四种事件: 1.节点创建 2.节点删除 3.节点数据修改 4.子节点变更 就是上一篇文章中讲的watcher。 2.3 分布式锁1. 独占锁对于独占锁，我们可以将资源 R1 看做是 lock 节点，操作 O1 访问资源 R1 看做创建 lock 节点，释放资源 R1 看做删除 lock 节点。这样我们就将独占锁的定义对应于具体的 Zookeeper 节点结构，通过创建 lock 节点获取锁，删除节点释放锁。 123root -exclusive_locak ---lock 详细的过程如下： 多个客户端竞争创建 lock 临时节点 其中某个客户端成功创建 lock 节点，其他客户端对 lock 节点设置 watcher 持有锁的客户端删除 lock 节点或该客户端崩溃，会话关闭，由 Zookeeper 删除 lock 节点 其他客户端获得 lock 节点被删除的通知 重复上述4个步骤，直至无客户端在等待获取锁了 2. 读写锁读写锁包含一个读锁和写锁，操作 O1 对资源 R1 加读锁，且获得了锁，其他操作可同时对资源 R1 设置读锁，进行共享读操作。如果操作 O1 对资源 R1 加写锁，且获得了锁，其他操作再对资源 R1 设置不同类型的锁都会被阻塞。总结来说，读锁具有共享性，而写锁具有排他性。 在 Zookeeper 中，由于读写锁和独占锁的节点结构不同，读写锁的客户端不用再去竞争创建 lock 节点。所以在一开始，所有的客户端都会创建自己的锁节点。如果不出意外，所有的锁节点都能被创建成功，此时锁节点结构如图3所示。之后，客户端从 Zookeeper 端获取 /share_lock 下所有的子节点，并判断自己能否获取锁。如果客户端创建的是读锁节点，获取锁的条件（满足其中一个即可）如下： 自己创建的节点序号排在所有其他子节点前面 自己创建的节点前面无写锁节点 如果客户端创建的是写锁节点，由于写锁具有排他性。所以获取锁的条件要简单一些，只需确定自己创建的锁节点是否排在其他子节点前面即可。 12345root -share_lock ---host1-R-0000000001 ---host2-R-0000000002 ---host3-R-0000000003 详细的流程如下： 所有客户端创建自己的锁节点 从 Zookeeper 端获取 /share_lock 下所有的子节点 判断自己创建的锁节点是否可以获取锁，如果可以，持有锁。否则对自己关心的锁节点设置 watcher 持有锁的客户端删除自己的锁节点，某个客户端收到该节点被删除的通知，并获取锁 重复步骤4，直至无客户端在等待获取锁了 host2-R-0000000002 对应的客户端 C2 只需监视 host1-W-0000000001 节点是否被删除即可。而 host3-W-0000000003 对应的客户端 C3 只需监视 host2-R-0000000002 节点是否被删除即可，只有 host2-R-0000000002 节点被删除，客户端 C3 才能获取锁。而 host1-W-0000000001 节点被删除时，产生的通知对于客户端 C3 来说是无用的，即使客户端 C3 响应了通知也没法获取锁。 这里总结一下，不同客户端关心的锁节点是不同的。如果客户端创建的是读锁节点，那么客户端只需找出比读锁节点序号小的最后一个的写锁节点，并设置 watcher 即可。而如果是写锁节点，则更简单，客户端仅需对该节点的上一个节点设置 watcher 即可。 2.4 例子ZooKeeper可以通过依赖于临时节点实现分布式锁。假设有两台服务器 一台8888 一台8889，都部署了同一个web程序。 此刻同时来了两个请求 一个被分到了8888服务器，一个被分到了8889服务器上。两个请求都要去修改数据库中的User表里的ID 为666的用户的信息(例如都是把age属性+1 假设当前age为22） 没加锁前： 用户A查询到age为22 ++后变成23 用户B也查询到是22 ++后也变成23 其中这里两个++后应该变成24的，由于没加锁出现了数据异常 加锁后 ： 用户A先在ZooKeeper中创建临时有序节点假设为/locker/node-0000000009，创建之后会getChildren查看/locker节点下的所有子节点，如果自己的编号是最小的，说明自己是最先创建的，则获取到了锁，如果不是就等待前面的节点被自动删除(即前面的用户释放了锁)。此时用户B也来访问，也要临时有序节点，假设为/locker/node-00000000010，接着getChildren查看/locker节点下的所有子节点，发现自己不是最小的，那么就会等待在这里。 最终A和B只有一个人能成功创建节点并修改数据，A获取到锁后开始执行业务代码，那么A将age ++后变成23了 然后数据库持久化 8888中的age就是23了 8889中还是22 接着服务器8888和8889之间执行进行数据同步 同步成功后A关闭会话，临时节点失效，锁释放了。 此时B用户创建的节点是最小的，就获取到了锁，开始执行业务代码，去修改数据 此时获取到age=23 ++后变成了24 持久化后 再次进行8888 8889服务期间进行数据同步。 这样就不会出现数据异常。 问题：为什么要用临时节点，创建持久化节点然后执行完后删除不行吗？ 答：临时节点性能高 3. 参考https://blog.csdn.net/qiangcuo6087/article/details/79067136]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper入门教程(二)---原生API与ACL权限认证]]></title>
    <url>%2Fposts%2F3ced5d74.html</url>
    <content type="text"><![CDATA[本文主要记录了ZooKeeper原生API的基本使用和ZooKeeper的ACL权限认证说明。 ZooKeeper入门系列文章目录 ZooKeeper入门教程(一)—安装与基本使用 ZooKeeper入门教程(二)—原生API与ACL权限认证 ZooKeeper入门教程(三)—Watcher与分布式锁 ….. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 原生API1.1 引入依赖123456&lt;!--zookeeper--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.4-beta&lt;/version&gt;&lt;/dependency&gt; 1.2 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173package zookeeper;import org.apache.zookeeper.AsyncCallback;import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.WatchedEvent;import org.apache.zookeeper.Watcher;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import org.apache.zookeeper.data.Stat;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.util.List;import java.util.concurrent.CountDownLatch;/** * @author illusory */public class ZooKeeperBase &#123; /** * ZooKeeper地址 */ static final String CONN_ADDR = "192.168.5.154:2181,192.168.5.155:2181,192.168.5.156:2181"; /** * session超时时间ms */ static final int SESSION_TIMEOUT = 5000; /** * wait for zk connect */ static final CountDownLatch waitZooKeeperConnOne = new CountDownLatch(1); private ZooKeeper zooKeeper; @Before public void before() throws IOException &#123; /** * zk客户端 * 参数1 connectString 连接服务器列表，用逗号分隔 * 参数2 sessionTimeout 心跳检测时间周期 毫秒 * 参数3 watcher 事件处理通知器 * 参数4 canBeReadOnly 标识当前会话是否支持只读 * 参数5 6 sessionId sessionPassword通过这两个确定唯一一台客户端 目的是提供重复会话 */ zooKeeper = new ZooKeeper(CONN_ADDR, SESSION_TIMEOUT, new Watcher() &#123; @Override public void process(WatchedEvent watchedEvent) &#123; //获取事件状态与类型 Event.KeeperState state = watchedEvent.getState(); Event.EventType type = watchedEvent.getType(); //如果是建立连接成功 if (Event.KeeperState.SyncConnected == state) &#123; //刚连接成功什么都没有所以是None if (Event.EventType.None == type) &#123; //连接成功则发送信号 让程序继续执行 waitZooKeeperConnOne.countDown(); System.out.println("ZK 连接成功"); &#125; &#125; &#125; &#125;); &#125; @Test public void testCreate() throws IOException, InterruptedException, KeeperException &#123; waitZooKeeperConnOne.await(); System.out.println("zk start"); //创建简介 // 参数1 key // 参数2 value 参数3 一般就是ZooDefs.Ids.OPEN_ACL_UNSAFE // 参数4 为节点模式 有临时节点(本次会话有效，分布式锁就是基于临时节点)或者持久化节点 // 返回值就是path 节点已存在则报错NodeExistsException/** * 同步方式 * * 参数1 path 可以看成是key 原生Api不能递归创建 不能在没父节点的情况下创建子节点的，会抛出异常 * 框架封装也是通过if一层层判断的 如果父节点没有 就先给你创建出来 这样实现的递归创建 * 参数2 data 可以看成是value 要求是字节数组 也就是说不支持序列化 * 如果要序列化可以使用一些序列化框架 Hessian Kryo等 * 参数3 节点权限 使用ZooDefs.Ids.OPEN_ACL_UNSAFE开放权限即可 * 在权限没有太高要求的场景下 没必要关注 * 参数4 节点类型 创建节点的类型 提供了多种类型 * CreateMode.PERSISTENT 持久节点 * CreateMode.PERSISTENT_SEQUENTIAL 持久顺序节点 * CreateMode.EPHEMERAL 临时节点 * CreateMode.EPHEMERAL_SEQUENTIAL 临时顺序节点 * CreateMode.CONTAINER * CreateMode.PERSISTENT_WITH_TTL * CreateMode.PERSISTENT_SEQUENTIAL_WITH_TTL */// String s = zooKeeper.create("/illusory", "test".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); //illusory// System.out.println(s); //原生Api不能递归创建 不能在没父节点的情况下创建子节点的 //框架封装也是同过if判断的 如果父节点没有 就先给你创建出来 这样实现的递归创建// zooKeeper.create("/illusory/testz/zzz", "testzz".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);// System.out.println();/** * 异步方式 * 在同步基础上多加两个参数 * * 参数5 注册一个回调函数 要实现AsyncCallback.Create2Callback()重写processResult(int rx, String path, Object ctx, String name, Stat stat)方法 * processResult参数1 int rx为服务端响应码 0表示调用成功 -4表示端口连接 -110表示指定节点存在 -112表示会话已过期 * 参数2 String path 节点调用时传入Api的数据节点路径 * 参数3 Object ctx 调用接口时传入的ctx值 * 参数4 String name 实际在服务器创建节点的名称 * 参数5 Stat stat 被创建的那个节点信息 * */ zooKeeper.create("/illusory/testz/zzz/zzz/aa", "testzz".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT , (rc, path, ctx, name, stat) -&gt; &#123; System.out.println(stat.getAversion()); System.out.println(rc); System.out.println(path); System.out.println(ctx); &#125;, "s"); System.out.println("继续执行"); Thread.sleep(1000); byte[] data = zooKeeper.getData("/illusory", false, null); System.out.println(new String(data)); &#125; @Test public void testGet() throws KeeperException, InterruptedException &#123; waitZooKeeperConnOne.await();// zooKeeper.create("/illusory","root".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);// zooKeeper.create("/illusory/aaa","aaa".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);// zooKeeper.create("/illusory/bbb","aaa".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);// zooKeeper.create("/illusory/ccc","aaa".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); //不支持递归 只能取下面的一层 List&lt;String&gt; children = zooKeeper.getChildren("/illusory", false); for (String s : children) &#123; //拼接绝对路径 String realPath = "/illusory/" + s; byte[] data = zooKeeper.getData(realPath, false, null); System.out.println(new String(data)); &#125; &#125; @Test public void testSet() throws KeeperException, InterruptedException &#123; waitZooKeeperConnOne.await(); zooKeeper.setData("/illusory/aaa", "new AAA".getBytes(), -1); zooKeeper.setData("/illusory/bbb", "new BBB".getBytes(), -1); zooKeeper.setData("/illusory/ccc", "new CCC".getBytes(), -1); testGet(); &#125; @Test public void testDelete() throws KeeperException, InterruptedException &#123; waitZooKeeperConnOne.await(); zooKeeper.delete("/illusory/aaa", -1); testGet(); &#125; @Test public void testExists() throws KeeperException, InterruptedException &#123; waitZooKeeperConnOne.await(); //判断节点是否存在 没有就是null 有的话会返回一长串12884901923,12884901933,1552027900801,1552028204414,1,0,0,0,7,0,12884901923 Stat exists = zooKeeper.exists("/illusory/bbb", null); System.out.println(exists); &#125;&#125; 2. ACL权限认证2.1 为什么需要ACL简单来说 :在通常情况下,zookeeper允许未经授权的访问,因此在安全漏洞扫 描中暴漏未授权访问漏洞。 这在一些监控很严的系统中是不被允许的,所以需要ACL来控制权限. 2.2 Zookeeper权限分类 权限包括以下几种: CREATE: 能创建子节点 READ：能获取节点数据和列出其子节点 WRITE: 能设置节点数据 DELETE: 能删除子节点 ADMIN: 能设置权限 2.3 zookeeper认证方式 world：默认方式，相当于全世界都能访问 auth：代表已经认证通过的用户(cli中可以通过addauth digest user:pwd 来添加当前上下文中的授权用户) digest：即用户名:密码这种方式认证，这也是业务系统中最常用的 ip：使用IP地址认证 一般常用的是digest或者ip这两种。 2.4 代码示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Test public void testAuth() throws KeeperException, InterruptedException, IOException &#123; /** * 测试路径 */ final String Path = "/testAuth"; final String pathDel = "/testAuth/delNode"; /** * 认证类型 */ final String authType = "digest"; /** * 正确的key */ final String rightAuth = "123456"; /** * 错误的key */ final String badAuth = "654321"; ZooKeeper z1 = new ZooKeeper(CONN_ADDR, SESSION_TIMEOUT, null); //添加认证信息 类型和key 以后执行操作时必须带上一个相同的key才行 z1.addAuthInfo(authType, rightAuth.getBytes()); //把所有的权限放入集合中，这样不管操作什么权限的节点都需要认证才行 List&lt;ACL&gt; acls = new ArrayList&lt;&gt;(ZooDefs.Ids.CREATOR_ALL_ACL); try &#123; zooKeeper.create(Path, "xxx".getBytes(), acls, CreateMode.PERSISTENT); &#125; catch (Exception e) &#123; System.out.println("创建节点，抛出异常： " + e.getMessage()); &#125; ZooKeeper z2 = new ZooKeeper(CONN_ADDR, SESSION_TIMEOUT, null); /** * 未授权 */ try &#123; //未授权客户端操作时抛出异常 //NoAuthException: KeeperErrorCode = NoAuth for /testAuth z2.getData(Path, false, new Stat()); &#125; catch (Exception e) &#123; System.out.println("未授权：操作失败，抛出异常： " + e.getMessage()); &#125; /** * 错误授权信息 */ ZooKeeper z3 = new ZooKeeper(CONN_ADDR, SESSION_TIMEOUT, null); try &#123; //添加错误授权信息后再次执行 z3.addAuthInfo(authType, badAuth.getBytes()); //NoAuthException: KeeperErrorCode = NoAuth for /testAuth z3.getData(Path, false, new Stat()); &#125; catch (Exception e) &#123; System.out.println("错误授权信息：操作失败，抛出异常： " + e.getMessage()); &#125; /** * 正确授权信息 */ ZooKeeper z4 = new ZooKeeper(CONN_ADDR, SESSION_TIMEOUT, null); //添加正确授权信息后再次执行 z4.addAuthInfo(authType, rightAuth.getBytes()); byte[] data = z4.getData(Path, false, new Stat()); System.out.println("正确授权信息：再次操作成功获取到数据：" + new String(data)); &#125; 3. 参考https://mulingya.iteye.com/blog/2425990]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper入门教程(一)---安装与基本使用]]></title>
    <url>%2Fposts%2F137f5008.html</url>
    <content type="text"><![CDATA[本文主要对ZooKeeper做了简要介绍包括设计目标、服务组成、应用场景等，同时记录了Linux下安装ZooKeeper的详细过程，最后还包括了ZooKeeper的基本使用方法。 ZooKeeper入门系列文章目录 ZooKeeper入门教程(一)—安装与基本使用 ZooKeeper入门教程(二)—原生API与ACL权限认证 ZooKeeper入门教程(三)—Watcher与分布式锁 ….. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。 ZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。 ZooKeeper包含一个简单的原语集， 提供Java和C的接口。 1. 设计目标 1.简单的数据结构，Zookeeper就是以简单的树形结构来进行相互协调的 2.可以构建集群，只要集群中超过半数的机器能正常工作，整个集群就能正常对外提供服务。 3.顺序访问，对于每个客户端的每个请求，zk都会分配一个全局唯一的递增编号，这个编号反应了所有事务操作的先后顺序 4.高性能，全量数据保存在内存中，并直接服务于所有的非事务请求 2. 服务组成ZKServer根据身份特性分为三种 Leader，负责客户端的write类型请求 Follower,负责客户端的read类型请求 Observer，特殊的Follower，可以接受客户端的read氢气球，但不参加选举 3. 应用场景Hadoop、Storm、消息中间件、RPC服务框架、数据库增量订阅与消费组件(MySQL Binlog)、分布式数据库同步系统、淘宝的Otter。 zookeeper的特性就是在分布式场景下高可用，但是原生的API实现分布式功能非 常困难，团队去实现也太浪费时间，即使实现了也未必稳定。那么可以采用第三方的 客户端的完美实现，比如Curator框架，他是Apache的顶级项目。 1. 配置管理配置的管理在分布式应用环境中很常见，比如我们在平常的应用系统中，经常会碰到这样的求：如机器的配置列表、运行时的开关配罝、数据库配罝信息等。这些全局配置信息通常具备以下3个特性：1数据量比较小。2数据内容在运行时动态发生变化。3集群中各个集群共享信息，配置一致。 2. 集群管理Zookeeper不仅能够帮你维护当前的集群中机器的服务状态，而且能够帮你选出一个“总管”，让这个总管来管理集群，这就是Zookeeper的另一个功能Leader，并实现集群容错功能。1希望知道当前集群中宄竞有多少机器工作。2对集群中每天集群的运行时状态进行数据收集。3对集群中每台集群进行上下线操作。 3.发布与订阅Zookeeper是一个典型的发布/订阅模式的分布式数控管理与协调框架，开发人员可以使用它来进行分布式数据的发布与订阅。 4. 数据库切换比如我们初始化zookeeper的时候读取其节点上的数据库配置文件,当ES—旦发生变更时，zookeeper就能帮助我们把变更的通知发送到各个客户端，每个了互动在接收到这个变更通知后，就可以从新进行最新数据的获取。 5. 分布式日志的收集我们可以做一个日志系统收集集群中所有的日志信息，进行统 一管理。 2. 安装注：Zookeeper集群最低需要3个节点，同时要求服务器间时间保持一致。 2.1 下载官网：https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/ 这里下载的是zookeeper-3.4.13.tar.gz 下载后上传到服务器上，习惯放在/usr/software目录下 2.2 解压将Zookeeper解压到/usr/local目录下 1[root@localhost software]# tar -zxvf zookeeper-3.4.13.tar.gz -C /usr/local/ 改个名字 1[root@localhost local]# mv zookeeper-3.4.13/ zookeeper 2.3 配置环境变量1[root@localhost etc]# vim /etc/profile 添加如下内容：目录按照自己的目录写 12export ZOOKEEPER_HOME=/usr/local/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin 刷新使其生效 1[root@localhost etc]# source /etc/profile 2.4 修改配置文件ZooKeeper配置文件在/usr/local/zookeeper/conf/zoo_sample.cfg 首先修改一下名字，改成zoo.cfg 1[root@localhost conf]# mv zoo_sample.cfg zoo.cfg 然后修改配置文件 1[root@localhost conf]# vim zoo.cfg 主要修改如下内容： 12345678# 保存数据的地方dataDir=/usr/local/zookeeper/data#文件末尾添加下面这些配置#server.0 IP server.0 192.168.1.111:2888:3888server.1 192.168.1.112:2888:3888server.2 192.168.1.113:2888:3888 2.5 配置myid然后创建一下上面配置的/usr/local/zookeeper/data目录 1[root@localhost zookeeper]# mkdir data 接着在/usr/local/zookeeper/data目录下创建一个叫myid的文件 1[root@localhost data]# vim myid 分别写入一个数字，和上面配置的server.0 192.168.1.111:2888:3888这个对应上。 即 192.168.1.111上的myid中写入一个数字0 192.168.1.112上的myid中写入一个数字1 192.168.1.113上的myid中写入一个数字2 2.6 配置详解123456789101112131415tickTinte： 基本事件服务器之间或客户端与服务器之间维持心跣的时间间隔dataDiri：存储内存中数据库快照的位置，顾名思义就是Zookeeper保存数据的目录，默认情況下，Zookeeper将写数据的日志文件也保存在这个目录里，clientPorti：这个端口就是客户端连接Zookeeper服务器的端口，Zookeeper会监听这个雄口，接受客户端的访间请求。initLimit： 这个配置表示ZooKeeper最大能接受多少个心跳时间间隔，当超过后最大次数后还没收到客户端信息，表明客户端连接失败syncLiniiti ：这个配置表明Leader和Follower之间发送消息，请求和应答时间长度，最长不能超多多少个tickTinteserver.A = B：C：D A：表示这个是第几号服务器，myid中的数字就是这个 B：这个服务器的IP C：与集群中的leader交换信息的端口 D：集群中的leader挂了，需要一个端口用来进行选举，选出一个新的leader 3. 使用1. 启动到这里Zookeeper就算配置完成了,可以启动了。 进入/usr/local/zookeeper/bin目录，可以看到里面有很多脚本文件。 12[root@localhost bin]# lsREADME.txt zkCleanup.sh zkCli.cmd zkCli.sh zkEnv.cmd zkEnv.sh zkServer.cmd zkServer.sh zkTxnLogToolkit.cmd zkTxnLogToolkit.sh 其中zkServer.sh就是服务端操作相关脚本，zkCli.sh这个就是客户端。 前面配置了环境变量，所以在哪里都可以使用这些脚本，不用非得进到这个文件夹。 启动服务端： 1[root@localhost bin]# zkServer.sh start 查看Zookeeper状态 1234[root@localhost data]# zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/bin/../conf/zoo.cfgMode: leader 可以已经启动了，而且这是一个leader节点。那么其他两个节点就是follower了。 问题 1Error contacting service. It is probably not running. 解决 1.可能是防火墙问题，关闭防火墙 12临时关闭: systemctl stop firewalld开机禁用(需要重启生效):systemctl disable firewalld 2.myid配置错了，这个必须和配置文件对应上，必须放在配置的那个文件夹下 2. 进入客户端可以通过shell操作zookeeper,首先进入客户端 1[root@localhost data]# zkCli.sh windows下的可视化工具ZooInspector 下载地址https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip 解压后build目录下有个jar包，cmd命令行中通过命令java -jar zookeeper-dev-ZooInspector.jar运行 idea下也有zookeeper插件。 常用操作： 3. 查询节点ls path ZK是一个树形结构 刚创建是跟目录下有个zookeeper节点，zookeeper节点下有个quoat节点 1234[zk: localhost:2181(CONNECTED) 0] ls /[zookeeper][zk: localhost:2181(CONNECTED) 2] ls /zookeeper[quota] 4. 创建节点create path value 创建节点 12[zk: localhost:2181(CONNECTED) 5] create /illusory redisCreated /illusory 5. get/setget path获取值 12345678910111213141516171819[zk: localhost:2181(CONNECTED) 6] get /illusory# 值redis# 这个ID就是前面说的那个ID Zk会为所有客户端的每一次操作生成一个全局唯一的IDcZxid = 0x100000003# 创建时间ctime = Thu Mar 07 23:18:12 CST 2019mZxid = 0x100000003# 修改时间mtime = Thu Mar 07 23:18:12 CST 2019pZxid = 0x100000003cversion = 0#数据版本号 每次修改后都会加1dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 5# 孩子 子节点numChildren = 0 set path 设置值 12345678910111213[zk: localhost:2181(CONNECTED) 7] set /illusory mysqlcZxid = 0x100000003ctime = Thu Mar 07 23:18:12 CST 2019mZxid = 0x100000004mtime = Thu Mar 07 23:24:10 CST 2019pZxid = 0x100000003cversion = 0# 可以看到 改变后也加1了dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 5numChildren = 0 6. 删除delete path 只能删除子节点 12345678[zk: localhost:2181(CONNECTED) 9] create /illusory/cloud nginxCreated /illusory/cloud[zk: localhost:2181(CONNECTED) 11] ls /illusory[cloud][zk: localhost:2181(CONNECTED) 12] delete /illusoryNode not empty: /illusory# 删除子节点成功[zk: localhost:2181(CONNECTED) 13] delete /illusory/cloud rmr path 递归删除父节点也可以删除 1234[zk: localhost:2181(CONNECTED) 15] ls /illusory[cloud]# 递归删除[zk: localhost:2181(CONNECTED) 16] rmr /illusory 所有命令列表 12345678910111213141516171819202122ZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port 4. 参考https://www.cnblogs.com/lsdb/p/7297731.html]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门教程(五)---搭建Redis集群]]></title>
    <url>%2Fposts%2F397ed67.html</url>
    <content type="text"><![CDATA[本文主要记录了Redis集群搭建与使用的详细过程。 Redis系列教程目录 Redis入门教程(一)—安装与配置 Redis入门教程(二)—五大基础数据类型与常用命令 Redis入门教程(三)—安全性、事务、发布订阅 Redis入门教程(四)—主从复制与持久化 Redis入门教程(五)—搭建Redis集群 Redis入门教程(六)—通过JavaApi(Jedis)操作Redis Redis入门教程(七)—通过 Docker 安装 Redis ……. 更多文章欢迎访问我的个人博客–&gt;幻境云图 最少要3台机器才能形成集群，同时每个主需要配一个从，即最好6台机器。不过这里也没这么多机器小霸王电脑也开不了6个虚拟机 所以就在一台机器上开6个Redis做个伪集群，真实情况下也差不多是这样配置的 1. 创建文件夹先创建一个文件夹redis-cluster，然后在这个文件夹里分别创建6个文件夹当成6台机器，redis7001、redis7002、redis7003、redis7004、redis7005、redis7006、假装是6台服务器….. 123[root@localhost etc]# mkdir -p /usr/local/redis-cluster[root@localhost etc]# cd /usr/local/redis-cluster/[root@localhost redis-cluster]# mkdir 7001 &amp;&amp; mkdir 7002 &amp;&amp; mkdir 7003 &amp;&amp; mkdir 7004 &amp;&amp; mkdir 7005 &amp;&amp; mkdir 7006 2. 修改配置文件然后把redis.conf配置文件分别复制到这6个文件夹 12# 先复制一份 等修改好后再复制到其他地方[root@localhost redis-5.0.3]# cp redis.conf /usr/local/redis-cluster/7001 然后修改配置文件redis.conf,主要修改下面这几个地方： 12345678910111213141516# 开启后台启动1.daemonize yes # 端口号改为对应的700*2.port 7001 # 绑定IP 改为当前机器的IP3.bind 192.168.5.191 # 数据存储目录 每台机器必须指向不同的位置 改为对应的700*4.dir /usr/local/redis-cluster/7001 # 开启集群模式5.cluster-enabled yes # 这里最好和port对应700*6.cluster-config-file nodes-7001.conf # 超时时间可以自己调整7.cluster-node-timeout 5000 # 开启AOF持久化8.appendonly yes 修改完成后再分别负责到另外5台机器。复制后记得把需要修改的地方修改一下，port、dir、cluster-config-file 3. 环境准备到这里6个文件夹的redis.conf配置文件都修改好了，由于Redis集群需要Ruby命令，所以需要安装Ruby。 1234[root@localhost 7006]# yum install ruby[root@localhost 7006]# yum install rubygems#redis和Ruby的接口[root@localhost 7006]# gem install redis 问题可能最后一步出现问题，提示如下： 1redis requires Ruby version &gt;= 2.2.2 CentOS 默认支持ruby是2.0版本导，redis需要大于2.2.2的版本。 解决通过rvm安装最新的ruby即可，具体如下; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 安装curl curl是Linux下的文件传输工具[root@localhost 7006]# yum install curl# 安装rvm RVM是一个命令行工具，可以提供一个便捷的多版本Ruby环境的管理和切换。[root@localhost 7006]# gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB[root@localhost 7006]# \curl -sSL https://get.rvm.io | bash -s stable# 查看一下rvm安装上没有[root@localhost 7006]# find / -name rvm -print#如果出现下面这样的就说明安装上了 /usr/local/rvm /usr/local/rvm/src/rvm /usr/local/rvm/src/rvm/bin/rvm /usr/local/rvm/src/rvm/lib/rvm /usr/local/rvm/src/rvm/scripts/rvm /usr/local/rvm/bin/rvm /usr/local/rvm/lib/rvm /usr/local/rvm/scripts/rvm# 使rvm配置文件生效 [root@localhost 7006]# source /usr/local/rvm/scripts/rvm# 查看rvm库中已知的ruby版本[root@localhost 7006]# rvm list known# 大概会向这样 当前最新的时2.6# MRI Rubies[ruby-]1.8.6[-p420][ruby-]1.8.7[-head] # security released on head[ruby-]1.9.1[-p431][ruby-]1.9.2[-p330][ruby-]1.9.3[-p551][ruby-]2.0.0[-p648][ruby-]2.1[.10][ruby-]2.2[.10][ruby-]2.3[.8][ruby-]2.4[.5][ruby-]2.5[.3][ruby-]2.6[.0]ruby-head#安装ruby2.6.0 这里需要等一会 下载之后还要等编译完...[root@localhost 7006]# rvm install 2.6.0#使用ruby2.6.0[root@localhost 7006]# rvm use 2.6.0#设置ruby默认版本[root@localhost 7006]# rvm use 2.6.0 --default#查看ruby版本 [root@localhost 7006]# ruby --version# 继续安装Redis[root@localhost 7006]# gem install redis 4. 启动Redis分别启动6个Redis 12345678910111213141516171819# 分别启动6个Redis[root@localhost 7006]# /usr/local/redis/bin/redis-server /usr/local/redis-cluster/7001/redis.conf[root@localhost 7006]# /usr/local/redis/bin/redis-server /usr/local/redis-cluster/7002/redis.conf[root@localhost 7006]# /usr/local/redis/bin/redis-server /usr/local/redis-cluster/7003/redis.conf[root@localhost 7006]# /usr/local/redis/bin/redis-server /usr/local/redis-cluster/7004/redis.conf[root@localhost 7006]# /usr/local/redis/bin/redis-server /usr/local/redis-cluster/7005/redis.conf[root@localhost 7006]# /usr/local/redis/bin/redis-server /usr/local/redis-cluster/7006/redis.conf#查看一下启动成功没[root@localhost redis-cluster]# ps aux|grep redisroot 16205 0.1 0.2 159512 2604 ? Ssl 14:08 0:16 /usr/local/redis/bin/redis-server 0.0.0.0:6379root 35225 0.2 0.2 153880 2836 ? Ssl 16:22 0:00 /usr/local/redis/bin/redis-server 192.168.5.154:7001 [cluster]root 35388 0.2 0.2 153880 2836 ? Ssl 16:24 0:00 /usr/local/redis/bin/redis-server 192.168.5.154:7002 [cluster]root 35398 0.1 0.2 153880 2832 ? Ssl 16:24 0:00 /usr/local/redis/bin/redis-server 192.168.5.154:7003 [cluster]root 35407 0.1 0.2 153880 2836 ? Ssl 16:25 0:00 /usr/local/redis/bin/redis-server 192.168.5.154:7004 [cluster]root 35415 0.1 0.2 153880 2836 ? Ssl 16:25 0:00 /usr/local/redis/bin/redis-server 192.168.5.154:7005 [cluster]root 35424 0.1 0.2 153880 2832 ? Ssl 16:25 0:00 /usr/local/redis/bin/redis-server 192.168.5.154:7006 [cluster]root 35468 0.0 0.0 112708 976 pts/1 R+ 16:25 0:00 grep --color=auto redis# ok的 5. 创建集群5.0之前的方式进入redis安装目录/usr/local/redis-5.0.3/src找到redis-trib.rb脚本,这就是redis集群相关操作的脚本，是ruby写的.执行命令创建集群 123456789# 解释： # ./redis-trib.rb 即redis集群操作脚本 # create 即创建集群# --replicas 即配置 后面一长串都是集群配置# 1 这个1是redis主从比例 主机三台 从机三台 主/--&gt; 3/3 即 1# 后面的6台机器中 会根据配置的比例把前面的几台(这里是3台)做为主，后面的做为从# 然后主节点中的第一个对应的一定是从节点中的第一个 依次排下去这里就是7001 对应7004[root@localhost src]# ./redis-trib.rb create --replicas 1 192.168.5.154:7001 192.168.5.154:7002 192.168.5.154:7003 192.168.5.154:7004 192.168.5.154:7005 192.168.5.154:7006 5.0之后的方式Redis 5.0 版本，放弃了Ruby的集群方式，改为使用C语言编写的 redis-cli的方式，使集群的构建方式复杂度大大降低。命令如下： 1234567891011121314151617181920212223242526272829303132# 参数的含义和上面也是一样的#create 即创建集群# --replicas 即配置 后面一长串都是集群配置# 1 这个1是redis主从比例 主机三台 从机三台 主/--&gt; 3/3 即 1# 后面的6台机器中 会根据配置的比例把前面的几台(这里是3台)做为主，后面的做为从# 然后主节点中的第一个对应的一定是从节点中的第一个 依次排下去这里就是7001 对应7004[root@localhost src]# redis-cli --cluster create 192.168.5.154:7001 192.168.5.154:7002 192.168.5.154:7003 192.168.5.154:7004 192.168.5.154:7005 192.168.5.154:7006 --cluster-replicas 1# 接下来会询问是否设置 输入yes即可Can I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Performing Cluster Check (using node 192.168.5.154:7001)M: 092694ff8d9a2fef0df632af1650653b6756efd5 192.168.5.154:7001 slots:[0-5460] (5461 slots) master 1 additional replica(s)S: 1c465b386313dbe47fbdea93775a9ef249b8e5ae 192.168.5.154:7004 slots: (0 slots) slave replicates 092694ff8d9a2fef0df632af1650653b6756efd5M: 1c3f76d0f78d378f6413a66b7df0092b3f5be7ea 192.168.5.154:7002 slots:[5461-10922] (5462 slots) master 1 additional replica(s)S: 80694351fa024c34316ffc443a3e25a5e99132cf 192.168.5.154:7005 slots: (0 slots) slave replicates 1c3f76d0f78d378f6413a66b7df0092b3f5be7eaS: 35eeed488e23f852520df69cdac3dfcb0001c7cf 192.168.5.154:7006 slots: (0 slots) slave replicates 74fde96cb2cd794f0c15d26366641ce9afc34946M: 74fde96cb2cd794f0c15d26366641ce9afc34946 192.168.5.154:7003 slots:[10923-16383] (5461 slots) master# 到这里集群就搭建好了 其中 slots:[0-5460] (5461 slots) 表示槽 # 可以发现只有master有 slave没有 因为slave是不支持写的 只能读 6. 测试到此为止，集群已经搭建成功，进行验证。连接随便一个客户端 12# -c 表示集群模式 -h 主机名 -p 端口号[root@localhost bin]# /usr/local/redis/bin/reids-cli -c -h 192.168.5.154 -p 7001 检测cluster nodes查看集群信息 12345678[root@localhost bin]# /usr/local/redis/bin/redis-cli -c -h 192.168.5.154 -p 7001192.168.5.154:7001&gt; cluster nodes1c465b386313dbe47fbdea93775a9ef249b8e5ae 192.168.5.154:7004@17004 slave 092694ff8d9a2fef0df632af1650653b6756efd5 0 1551948999244 4 connected092694ff8d9a2fef0df632af1650653b6756efd5 192.168.5.154:7001@17001 myself,master - 0 1551948997000 1 connected 0-54601c3f76d0f78d378f6413a66b7df0092b3f5be7ea 192.168.5.154:7002@17002 master - 0 1551948997000 2 connected 5461-1092280694351fa024c34316ffc443a3e25a5e99132cf 192.168.5.154:7005@17005 slave 1c3f76d0f78d378f6413a66b7df0092b3f5be7ea 0 1551948998236 5 connected35eeed488e23f852520df69cdac3dfcb0001c7cf 192.168.5.154:7006@17006 slave 74fde96cb2cd794f0c15d26366641ce9afc34946 0 1551948997226 6 connected74fde96cb2cd794f0c15d26366641ce9afc34946 192.168.5.154:7003@17003 master - 0 1551948999000 3 connected 10923-16383 添加数据测试一下 1234# 集群模式下 数据会随机或者平均分到几个主机中 这里在7001存的数据进入了第5798个槽中 即7002主机192.168.5.154:7001&gt; set name illusory-&gt; Redirected to slot [5798] located at 192.168.5.154:7002OK 然后7002查询，在添加前查询时没有数据的 等7001存数据后 再次查询就能查到了 123456[root@localhost ~]# /usr/local/redis/bin/redis-cli -c -h 192.168.5.154 -p 7002192.168.5.154:7002&gt; keys *(empty list or set)192.168.5.154:7002&gt; keys *1) "name"192.168.5.154:7002&gt; 注：集群模式只需要配置一次，以后启动后就自动为集群模式了。 7. 集群常用命令redis5提供了一些操作集群的工具，在redis安装目录下/usr/local/redis-5.0.3/utils/create-cluster/create-cluster 是个shell脚本文件。使用前需要修改脚本中的一些信息 12345678910111213[root@localhost create-cluster]# vim create-cluster#!/bin/bash# Settings#这个端口改为比自己的第一个节点小1# 会默认自增1形成7001~7006 六个节点PORT=7000# 超时时间TIMEOUT=2000# 节点数 也需要改为相对应的NODES=6# 主从比例也是REPLICAS=1 启动集群：/root/local/redis-5.0.3/utils/create-cluster/create-cluster start 关闭集群：/root/local/redis-5.0.3/utils/create-cluster/create-cluster stop 附上一个启动集群的脚本 12345678910#!/bin/sh/usr/local/redis/bin/redis-server /usr/local/redis-cluster/7001/redis.conf/usr/local/redis/bin/redis-server /usr/local/redis-cluster/7002/redis.conf/usr/local/redis/bin/redis-server /usr/local/redis-cluster/7003/redis.conf/usr/local/redis/bin/redis-server /usr/local/redis-cluster/7004/redis.conf/usr/local/redis/bin/redis-server /usr/local/redis-cluster/7005/redis.conf/usr/local/redis/bin/redis-server /usr/local/redis-cluster/7006/redis.conf/usr/local/redis/bin/redis-cli --cluster create 192.168.5.154:7001 192.168.5.154:7002 192.168.5.154:7003 192.168.5.154:7004 192.168.5.154:7005 192.168.5.154:7006 --cluster-replicas 1 更多集群相关命令/usr/local/redis/bin/redis-cli --cluster help 12345678910111213141516171819202122232425262728293031323334353637Cluster Manager Commands: create host1:port1 ... hostN:portN --cluster-replicas &lt;arg&gt; check host:port --cluster-search-multiple-owners info host:port fix host:port --cluster-search-multiple-owners reshard host:port --cluster-from &lt;arg&gt; --cluster-to &lt;arg&gt; --cluster-slots &lt;arg&gt; --cluster-yes --cluster-timeout &lt;arg&gt; --cluster-pipeline &lt;arg&gt; --cluster-replace rebalance host:port --cluster-weight &lt;node1=w1...nodeN=wN&gt; --cluster-use-empty-masters --cluster-timeout &lt;arg&gt; --cluster-simulate --cluster-pipeline &lt;arg&gt; --cluster-threshold &lt;arg&gt; --cluster-replace add-node new_host:new_port existing_host:existing_port --cluster-slave --cluster-master-id &lt;arg&gt; del-node host:port node_id call host:port command arg arg .. arg set-timeout host:port milliseconds import host:port --cluster-from &lt;arg&gt; --cluster-copy --cluster-replace help For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster. 8. 参考https://www.jianshu.com/p/72443fef9554 http://www.runoob.com/redis/redis-hashes.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门教程(六)---通过JavaApi(Jedis)操作Redis]]></title>
    <url>%2Fposts%2Fe456b1e5.html</url>
    <content type="text"><![CDATA[本文主要记录了如果通过Jedis操作Redis，包括了单机版Redis和集群版Redis。 Redis系列教程目录 Redis入门教程(一)—安装与配置 Redis入门教程(二)—五大基础数据类型与常用命令 Redis入门教程(三)—安全性、事务、发布订阅 Redis入门教程(四)—主从复制与持久化 Redis入门教程(五)—搭建Redis集群 Redis入门教程(六)—通过JavaApi(Jedis)操作Redis Redis入门教程(七)—通过 Docker 安装 Redis ……. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 导包需要引入Jedis包，其实和直接在shell中操作是一样的。 123456&lt;!-- jedis.Jedis --&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt; 2. 基本使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * @author illusoryCloud */public class JedisTest &#123; @Test public void jedisTestOne() &#123; Jedis jedis = new Jedis("192.168.1.111", 6379); //-------------string---------------- String set = jedis.set("name", "illusorycloud"); //ok System.out.println(set); String name = jedis.get("name"); //illusorycloud System.out.println(name); //-------------hash---------------- Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put("name", "illusory"); map.put("age", "30"); map.put("address", "cq"); jedis.hmset("user", map); JedisPool pool = jedisPoolTest(); //从连接池中获取一个Jedis实例 Jedis j = pool.getResource(); j.set("test", "111"); &#125; /** * 方法描述 构建redis连接池 * 池子中存放着多个jedis实例 */ @Test public JedisPool jedisPoolTest() &#123; JedisPool pool = null; if (pool == null) &#123; JedisPoolConfig config = new JedisPoolConfig(); //控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取； //如果赋值为-1，则表示不限制；如果pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted(耗尽)。 config.setMaxTotal(50); //控制一个pool最多有多少个状态为idle(空闲的)的jedis实例。 config.setMaxIdle(5); //表示当borrow(引入)一个jedis实例时，最大的等待时间，如果超过等待时间，则直接抛出JedisConnectionException；单位毫秒 //小于零:阻塞不确定的时间, 默认-1 config.setMaxWaitMillis(1000 * 100); //在borrow(引入)一个jedis实例时，是否提前进行validate操作；如果为true，则得到的jedis实例均是可用的； config.setTestOnBorrow(true); //return 一个jedis实例给pool时，是否检查连接可用性（ping()） config.setTestOnReturn(true); //connectionTimeout 连接超时（默认2000ms） //soTimeout 响应超时（默认2000ms） pool = new JedisPool(config, "127.0.0.1", 6379, 2000, "619868"); &#125; return pool; &#125;&#125; 3. 组合使用1234567891011121314151617181920212223242526272829303132333435363738394041424344//指定业务 查询业务 SYS_USER_SEL_AGE_25 //指定业务 查询业务 SYS_USER_SEL_SEX_MAN //指定业务 查询业务 SYS_USER_SEL_SEX_WOMEN private final String SYS_USER_TABLE = "SYS_USER_TABLE"; private final String SYS_USER_SEL_AGE_25 = "SYS_USER_SEL_AGE_25"; private final String SYS_USER_SEL_SEX_MAN = "SYS_USER_SEL_SEX_MAN"; private final String SYS_USER_SEL_SEX_WOMEN = "SYS_USER_SEL_SEX_WOMEN"; /** * User对象 数据量很大且查询频繁 需要把user表中的数据都放入缓存 */ @Test public void jedisTestTwo() &#123; Jedis jedis = new Jedis("192.168.5.154", 6379); //1.做放入操作 Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String uid1 = "illusory" + UUID.randomUUID().toString(); User u1 = new User(uid1, "illusoryCloud", 22, "man"); map.put(uid1, JSON.toJSONString(u1)); String uid2 = "illusory" + UUID.randomUUID().toString(); User u2 = new User(uid2, "Java", 23, "women"); map.put(uid2, JSON.toJSONString(u2)); String uid3 = "illusory" + UUID.randomUUID().toString(); User u3 = new User(uid3, "Android", 24, "man"); map.put(uid3, JSON.toJSONString(u3)); String uid4 = "illusory" + UUID.randomUUID().toString(); User u4 = new User(uid4, "iOS", 25, "women"); map.put(uid4, JSON.toJSONString(u4)); String uid5 = "illusory" + UUID.randomUUID().toString(); User u5 = new User(uid5, "Python", 26, "man"); map.put(uid5, JSON.toJSONString(u5)); jedis.hmset("SYS_USER_TABLE", map); //假如这里放入了1000W条数据 //如何按条件查询 //select * from user where set='women' //select * from user where set='women' and age=25 //很明显是做不到的 //一般持久化时都是多种数据类型配合使用 hash+set //详情见jedsiTestThree(); &#125; 直接存进入后无法按条件查询，所以存时需要好好考虑。 123456789101112131415161718192021222324252627282930313233343536@Test public void jedsiTestThree() &#123; Jedis jedis = new Jedis("192.168.5.154", 6379); //写入数据时往多个集合中写 //1.做放入操作 Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String uid1 = "illusory" + UUID.randomUUID().toString(); User u1 = new User(uid1, "illusoryCloud", 22, "man"); //这里满足多种条件时 每个集合都存一次 map.put(uid1, JSON.toJSONString(u1)); jedis.sadd(SYS_USER_SEL_SEX_MAN, uid1); String uid2 = "illusory" + UUID.randomUUID().toString(); User u2 = new User(uid2, "Java", 23, "women"); map.put(uid2, JSON.toJSONString(u2)); jedis.sadd(SYS_USER_SEL_SEX_WOMEN, uid2); String uid3 = "illusory" + UUID.randomUUID().toString(); User u3 = new User(uid3, "Android", 24, "man"); map.put(uid3, JSON.toJSONString(u3)); jedis.sadd(SYS_USER_SEL_SEX_MAN, uid3); String uid4 = "illusory" + UUID.randomUUID().toString(); User u4 = new User(uid4, "iOS", 25, "women"); map.put(uid4, JSON.toJSONString(u4)); jedis.sadd(SYS_USER_SEL_SEX_WOMEN, uid4); jedis.sadd(SYS_USER_SEL_AGE_25, uid4); String uid5 = "illusory" + UUID.randomUUID().toString(); User u5 = new User(uid5, "Python", 26, "man"); map.put(uid5, JSON.toJSONString(u5)); jedis.hmset(SYS_USER_TABLE, map); jedis.sadd(SYS_USER_SEL_SEX_MAN, uid5); //select * from user where set='women' //select * from user where set='women' and age=25 &#125; 查询 123456789101112131415161718192021222324252627@Test public void select() &#123; Jedis jedis = new Jedis("192.168.5.154", 6379); //select * from user where set='women' System.out.println("------------select * from user where set='women'--------"); //查出所有women的id Set&lt;String&gt; userWomenId = jedis.smembers(SYS_USER_SEL_SEX_WOMEN); //再通过id查询user for (Iterator iterator = userWomenId.iterator(); iterator.hasNext(); ) &#123; String next = (String) iterator.next(); String userString = jedis.hget(SYS_USER_TABLE, next); //string--&gt;json--&gt;user JSON userJson = (JSON) JSONObject.parse(userString); User user = JSON.toJavaObject(userJson, User.class); System.out.println("userName: "+user.getName()); System.out.println(userJson); &#125; System.out.println("------------select * from user where set='women' and age=25--------"); //select * from user where set='women' and age=25 Set&lt;String&gt; sinter = jedis.sinter(SYS_USER_SEL_AGE_25, SYS_USER_SEL_SEX_WOMEN); for (Iterator iterator = sinter.iterator(); iterator.hasNext(); ) &#123; String next = (String) iterator.next(); String userJson = jedis.hget(SYS_USER_TABLE, next); System.out.println(userJson); &#125; &#125; 结果 1234567------------select * from user where set='women'--------userName: iOS&#123;"sex":"women","name":"iOS","id":"illusory8bf000a3-3ed9-4f80-8d25-95729d3b8447","age":25&#125;userName: Java&#123;"sex":"women","name":"Java","id":"illusoryc42cbc91-9ed2-4468-b1a3-8ce05ff86766","age":23&#125;------------select * from user where set='women' and age=25--------&#123;"age":25,"id":"illusory8bf000a3-3ed9-4f80-8d25-95729d3b8447","name":"iOS","sex":"women"&#125; 4. Redis集群Redis集群操作主要使用JedisCluster这个类。 12345678910111213141516171819202122232425262728293031323334@Testpublic void jedisClusterTest() &#123; String host = "192.168.5.154"; Set&lt;HostAndPort&gt; jedisClusterNode = new HashSet&lt;&gt;(); jedisClusterNode.add(new HostAndPort(host, 7001)); jedisClusterNode.add(new HostAndPort(host, 7002)); jedisClusterNode.add(new HostAndPort(host, 7003)); jedisClusterNode.add(new HostAndPort(host, 7004)); jedisClusterNode.add(new HostAndPort(host, 7005)); jedisClusterNode.add(new HostAndPort(host, 7006)); //jedsi连接池配置 JedisPoolConfig cfg = new JedisPoolConfig(); //最大实例数 cfg.setMaxTotal(100); //最大空闲数 cfg.setMaxIdle(20); //最大等待时间 -1 无限 cfg.setMaxWaitMillis(-1); cfg.setTestOnBorrow(true); JedisCluster jc = new JedisCluster(jedisClusterNode, 6000, 100, cfg); //向单机操作一样 会自动从连接池中拿出一个实例来操作。 jc.set("name", "illusory"); jc.set("age", "22"); jc.set("sex", "man"); jc.set("addr", "cq"); System.out.println(jc.set("name", "illusory")); System.out.println(jc.set("age", "22")); System.out.println(jc.set("sex", "man")); System.out.println(jc.set("addr", "cq")); System.out.println(jc.get("name"));&#125; 5. 参考http://www.runoob.com/redis/redis-hashes.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门教程(四)---主从复制与持久化]]></title>
    <url>%2Fposts%2F84dd6d72.html</url>
    <content type="text"><![CDATA[本文主要记录了如何配置Redis主从复制和Redis的持久化机制介绍与具体配置使用，包括RDB和AOF，通过对比阐述了其各自的优缺点。 Redis系列教程目录 Redis入门教程(一)—安装与配置 Redis入门教程(二)—五大基础数据类型与常用命令 Redis入门教程(三)—安全性、事务、发布订阅 Redis入门教程(四)—主从复制与持久化 Redis入门教程(五)—搭建Redis集群 Redis入门教程(六)—通过JavaApi(Jedis)操作Redis Redis入门教程(七)—通过 Docker 安装 Redis ……. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 主从复制主节点负责写数据，从节点负责读数据，主节点定期把数据同步到从节点保证数据的一致性。 1.1 要点 1.Master可以拥有多个slave 2.多个Slavic可以连接同一个master外，还可以连接到其他的slave 3.从复制不会阻塞master在同步数据时master可以继续处理client请求 4.提供系统的伸缩性 1.2 过程 1.slave与master建立连接，发送sync同步命令 2.master开启一个后台进程，将数据库快照保存到文件中，同时master主进程会开始收集新的写命令并缓存 3.后台完成保存后，就将文件发送给slave 4.slave将此文件保存到硬盘上 1.3 使用主服务器不需要任何调整，只需要对从服务器进行配置。 修改从服务器Redis配置文件：/usr/local/redis/etc/redis.conf 1234#添加如下配置#slaveof master服务器IP master服务器端口号#slaveof &lt;masterip&gt; &lt;masterport&gt;slaveof 192.168.1.111 6379 如果master服务器上的Redis配置了密码，那么还需要配置以下密码 12#masterauth &lt;master-password&gt;masterauth redis 最后使用info查看role角色即可知道是主服务或从服务。 主服务器可读可写，从服务器只能读不能写。 1.4 问题如果从服务器中查看info出现 1master_link_status:down 即主从连接失败，这时在Redis.conf配置文件中做如下修改： 123#bindip 表示具有访问权限#bind 127.0.0.1 即localhost才能访问 修改为0.0.0.0 即都可以访问bind 0.0.0.0 修改后从重启一下，应该就oK了。 当然可能还要防火墙的问题，需要关掉防火墙 12systemctl stop firewalld # 临时关闭防火墙systemctl disable firewalld # 禁止开机启动 或者主从服务器根本ping不通，这…. 2. Redis持久化2.1 简介Redis是一个支持持久化的内存数据库，可以将内存中的数据写入到磁盘里。 Redis有两种持久化机制： RDB持久化（原理是将Reids在内存中的数据以快照的方式写入到二进制文件dump.rdb中,所以叫RDB），默认开启RDB机制。实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 AOF(append-only file)机制日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录以append-only的模式写入一个AOF日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集。 2.2 对比RDB方式是定时保存一次，若突然掉电，很可能会丢失数据。 AOF方式可以配置每次操作都写入日志文件中,数据安全性高。 1. RDB优点 ： 1). 单文件备份: 一旦采用该方式，那么你的整个Redis数据库将只包含一个文件，这对于文件备份而言是非常完美的。 2). 恢复简单: 对于灾难恢复而言，RDB是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。 3). 性能最大化 : 对于Redis的服务进程而言，在开始持久化时，它唯一需要做的只是fork出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行IO操作了。 4). 相比于AOF机制，如果数据集很大，RDB的启动效率会更高。 缺点 : 1). 数据丢失 ： 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么RDB将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。 2). 停顿 ： 由于RDB是通过fork子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。 2. AOF优点 ： 1). 该机制可以带来更高的数据安全性，即数据持久性。Redis中提供了3中同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，即每次发生的数据变 化都会被立即记录到磁盘中。 2). 安全 ：由于该机制对日志文件的写入操作采用的是append模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。然而如果我们本次操 作只是写入了一半数据就出现了系统崩溃问题，不用担心，在Redis下一次启动之前，我们可以通过redis-check-aof工具来帮助我们解决数据 一致性的问题。 3). 安全： 如果日志过大，Redis可以自动启用rewrite机制。即Redis以append模式不断的将修改数据写入到老的磁盘文件中，同时Redis还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行rewrite切换时可以更好的保证数据安全性。 4). AOF包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。 缺点 ： 1). 大数据时恢复速度慢，对于相同数量的数据集而言，AOF文件通常要大于RDB文件。 2). 根据同步策略的不同，AOF在运行效率上往往会慢于RDB。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和RDB一样高效。 3. 小结 AOF ： 牺牲一些性能，换取更高的缓存一致性。 RDB ：保证性能最大化，有一定数据丢失风险。 2.3 使用RDB方式是默认开启的不用配置，如果配置开启了AOF那么RDB会关闭。 如何开启AOF？ 修改Redis.conf配置文件 12345#appendonly no 是否开启aof 改成yes即可appendonly yes# The name of the append only file (default: "appendonly.aof")#设置保存的日志文件名 一般用默认的就好了appendfilename "appendonly.aof" 3. 参考http://www.runoob.com/redis/redis-hashes.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门教程(三)---安全性、事务、发布订阅]]></title>
    <url>%2Fposts%2F5df38113.html</url>
    <content type="text"><![CDATA[本文主要记录了Redis安全性(设置密码)、Redis事务和Redis提供的的发布与订阅功能。 Redis系列教程目录 Redis入门教程(一)—安装与配置 Redis入门教程(二)—五大基础数据类型与常用命令 Redis入门教程(三)—安全性、事务、发布订阅 Redis入门教程(四)—主从复制与持久化 Redis入门教程(五)—搭建Redis集群 Redis入门教程(六)—通过JavaApi(Jedis)操作Redis Redis入门教程(七)—通过 Docker 安装 Redis ……. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 安全性可以为Redis设置密码。修改配置文件 123456789[root@localhost etc]# vim redis.conf # Warning: since Redis is pretty fast an outside user can try up to# 150k passwords per second against a good box. This means that you should# use a very strong password otherwise it will be very easy to break.## requirepass foobared#设置密码 这里的redis就是密码requirepass redis 重启Redis，并进入客户端，执行查询keys * 提示无权限 1234[root@localhost etc]# /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf[root@localhost etc]# /usr/local/redis/bin/redis-cli 127.0.0.1:6379&gt; keys *(error) NOAUTH Authentication required. 输入密码后即可正常使用。 auth password 123456127.0.0.1:6379&gt; auth redisOK127.0.0.1:6379&gt; keys *1) "zset1"2) "set1"3) "list1" 也可以在进入客户端时输入密码 1/usr/local/redis/bin/redis-cli -a password 不过一般都不设置密码，工作中都是只能内网访问。 2. Redis事务Redis事务非常简单，使用方法如下： 首先使用multi打开事务，然后就写数据了，现在设置的数据都会放在队列里进行保存，最后使用exec执行，把数据依次存储到Redis中，discard取消事务。 watch : 监视一个或多个key，如果事务执行前key被修改了，那么事务将被打断。 123456789101112131415161718192021127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set a 1QUEUED127.0.0.1:6379&gt; set b 2QUEUED127.0.0.1:6379&gt; set c 3QUEUED127.0.0.1:6379&gt; incr aQUEUED127.0.0.1:6379&gt; set d aQUEUED127.0.0.1:6379&gt; incr dQUEUED127.0.0.1:6379&gt; exec1) OK2) OK3) OK4) (integer) 25) OK6) (error) ERR value is not an integer or out of range 不过事务中出错后并不会回滚，前面的还是已经执行了… 3. 发布与订阅Redis提供了简单的发布订阅功能，具体如下： 1234# 订阅监听subscribe [频道] # 进行发布消息广播publish [频道][发布内容] 1234567891011121314# 订阅频道cctv127.0.0.1:6379&gt; subscribe cctvReading messages... (press Ctrl-C to quit)1) "subscribe"2) "cctv"3) (integer) 1# 发布广播127.0.0.1:6379&gt; publish cctv hello(integer) 0# 订阅窗口就可以接受到消息了1) "message"2) "cctv"3) "hello" 4. 参考http://www.runoob.com/redis/redis-hashes.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门教程(二)---五大基础数据类型与常用命令]]></title>
    <url>%2Fposts%2F8380a4fa.html</url>
    <content type="text"><![CDATA[本文主要记录了Redis五大基础数据类型与key命令，包括了String、Hash、List、Set、ZSet。 Redis系列教程目录 Redis入门教程(一)—安装与配置 Redis入门教程(二)—五大基础数据类型与常用命令 Redis入门教程(三)—安全性、事务、发布订阅 Redis入门教程(四)—主从复制与持久化 Redis入门教程(五)—搭建Redis集群 Redis入门教程(六)—通过JavaApi(Jedis)操作Redis Redis入门教程(七)—通过 Docker 安装 Redis ……. 更多文章欢迎访问我的个人博客–&gt;幻境云图 Redis一共分5种数据类型：String、Hash、List、Set、ZSet 1. String1.1 set 命令 描述 set key value 设置指定 key 的值 setnx key value 只有在 key 不存在时设置 key 的值。(not exist) setex key seconds valuel 将值 value 关联到 key ，并将 key 的过期时间设为 seconds (秒)。expired psetex key milliseconds value] 和setex命令相似，但它以毫秒为单位设置 key 的生存时间 mset key value [key value …] 同时设置一个或多个 key-value 对。 msetnx key value [key value …] 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。 1.2 get 命令 描述 get key 获取指定 key 的值。 mget key1 [key2..] 获取所有(一个或多个)给定 key 的值。 getrange key start end 返回 key 中字符串值的子字符 strlen key 返回 key 所储存的字符串值的长度。 1.3 update 命令 描述 getset key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。 setrange key offset value 用 value 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。 incr key 将 key 中储存的数字值一。 incrby key increment 将 key 所储存的值加上给定的增量值（increment） 。 incrbyfloat key increment 将 key 所储存的值加上给定的浮点增量值（increment） 。 decr key 将 key 中储存的数字值减一。 decrby key decrement key 所储存的值减去给定的减量值（decrement） 。 append key value 追加字符串到key末尾 1.4 实例123设置值：set key value--&gt;set myname illusory //同一个key多次set会覆盖获取值：get key ------&gt;get myname删除值：del key--------&gt;del myname 其他set方法： setnx(not exist): 如果key不存在就设置值，返回1;存在就不设置，返回0； 1234567#格式：setnx key value127.0.0.1:6379&gt; set myname illusoryOK127.0.0.1:6379&gt; setnx myname cloud #myname 已经存在了 返回0(integer) 0127.0.0.1:6379&gt; get myname # 值也没有发生变化"illusory" setex(expired): 设置数据过期时间，数据只存在一段时间 123#格式：setnx key seconds value;setnx vercode 60 123456； #设置key--&gt;vercode有效时间60s，60s内获取值为123456,60s后返回nil（Redis中nil表示空） 123456127.0.0.1:6379&gt; setex vercode 5 123456OK127.0.0.1:6379&gt; get vercode #时间没到 还能查询到"123456"127.0.0.1:6379&gt; get vercode #5s到了 数据过期 查询返回nil(nil) setrange：替换字符串 123#格式：setrange key offset valueset email 123456789@gmail.comsetrange email 10 qqqqq # 从第10位开始替换(不包括第10位) 后面跟上用来替换的字符串 12345678127.0.0.1:6379&gt; set email 123456789@gmail.comOK127.0.0.1:6379&gt; get email"123456789@qqail.com"127.0.0.1:6379&gt; setrange email 10 qqqqq(integer) 19127.0.0.1:6379&gt; get email"123456789@qqqqq.com" mset：一次设置多个值 mset key1 value1 key2 value2 ...keyn valuen mget：一次获取多个值 mget key1 key2 key3...keyn 123456127.0.0.1:6379&gt; mset k1 111 k2 222 k3 333 OK127.0.0.1:6379&gt; mget k1 k2 k31) "111"2) "222"3) "333" getset: 返回旧值并设置新值 12#格式 getset key valuegetset name cloud #将name设置为cloud并放回name的旧值 12345678127.0.0.1:6379&gt; set name illusoryOK127.0.0.1:6379&gt; get name"illusory"127.0.0.1:6379&gt; getset name cloud"illusory"127.0.0.1:6379&gt; get name"cloud" incr/decr:对一个值进行递增或者递减操作。 123# 格式 incr key/decr keyincr age #age递增1decr age #age递减1 12345678910127.0.0.1:6379&gt; get age"22"127.0.0.1:6379&gt; incr age #递增(integer) 23127.0.0.1:6379&gt; get age"23"127.0.0.1:6379&gt; decr age #递减(integer) 22127.0.0.1:6379&gt; get age"22" incrby/decrby:对一个值按照一定步长进行递增或者递减操作。 123# 格式 incrby key increment/decrby key incrementincrby age 3 #age递增3decrby age 3 #age递减3 12345678910127.0.0.1:6379&gt; get age"22"127.0.0.1:6379&gt; incrby age 3(integer) 25127.0.0.1:6379&gt; get age"25"127.0.0.1:6379&gt; decrby age 3(integer) 22127.0.0.1:6379&gt; get age"22" append:字符串追加 12#格式 append key valueappend name cloud #在name后追加cloud 123456127.0.0.1:6379&gt; get name"illusory"127.0.0.1:6379&gt; append name cloud(integer) 13127.0.0.1:6379&gt; get name"illusorycloud" strlen：获取字符串长度 12#格式 strlen key strlen name #获取name对应的value的长度 1234127.0.0.1:6379&gt; get name"illusorycloud"127.0.0.1:6379&gt; strlen name(integer) 13 2. Hash工作中使用最多的就是Hash类型 将一个对象存储在Hash类型里要比String类型里占用的空间少一些，并方便存取整个对象。 hset:类似于set，数据都存为Hash类型，类似于存在map中 123456# 格式 hset key filed valuehset me name illusory #me是hash名 name是hash中的key illusory为hash中的value #类似于Java中的Map Map&lt;Object,Object&gt; me = new HashMap&lt;&gt;(); me.put("name", "illusory"); 2.1 hset 命令 描述 hset key filed value 将哈希表 key 中的字段 field 的值设为 value 。 hsetnx key filed value 类似setnx,只有在字段 field 不存在时，设置哈希表字段的值。 hmset key filed1 value1[filed2 value2..] 同时将多个 field-value (域-值)对设置到哈希表 key 中。 2.2 hget 命令 描述 hget key filed 获取存储在哈希表中指定字段的值。 hmget key filed1 [filed2…] 获取所有给定字段的值 hgetall key 获取在哈希表中指定 key 的所有字段和值 hkeys key 获取所有哈希表中的字段 hvals key 获取哈希表中所有值 hscankey cursor [MATCH pattern][COUNT count] 迭代哈希表中的键值对。 hexists key filed 查看哈希表 key 中，指定的字段是否存在。 hlen key 获取哈希表中字段的数量 hstrlen key filed 返回哈希表 key 中， 给定field的字符串长度 2.3 update 命令 描述 hincrby key field increment 为哈希表 key 中的指定字段的整数值加上增量 increment 。 hincrbyfloat key field increment 为哈希表 key 中的指定字段的浮点数值加上增量 increment 。 hdel key 删除哈希表key 中的一个或多个指定域，不存在的域将被忽略。 2.4 实例hset:类似于set，数据都存为Hash类型，类似于存在map中 hget:类似于get 12# 格式 hget hash filedhget me name #获取hash名为me的hash中的name对应的value 12345678127.0.0.1:6379&gt; hset me name illusory(integer) 1127.0.0.1:6379&gt; hset me age 22(integer) 1127.0.0.1:6379&gt; hget me name"illusory"127.0.0.1:6379&gt; hget me age"22" 同样也有批量操作的hmset、hmget 12#格式 hmset key filed1 value1 filde2 value2 ....filedn valuen#格式 hmget key filed1 filde2....filedn 12345127.0.0.1:6379&gt; hmset me name illusory age 22OK127.0.0.1:6379&gt; hmget me name age1) "illusory"2) "22" hsetnx(not exist): 如果key不存在就设置值，返回1;存在就不设置，返回0； 1#格式 hsetnx value filed value hincrby/hdecrby:对一个值按照一定步长进行递增或者递减操作。 123# 格式 hincrby key filed increment/hdecrby key filed incrementincrby me age 3 #age递增3decrby me age 3 #age递减3 hstrlen key filed:回哈希表 key 中， 与给定域 field 相关联的值的字符串长度（string length）。 如果给定的键或者域不存在， 那么命令返回 0 。 hexists:判断是否存在 1#格式 hexists value filed hlen:查看hash的filed数 1#格式 hlen key hdel:删除指定hash中的filed 1#格式 hdel key filed hkeys:返回指定hash中所有的filed 1#格式 hkeys key hvals:返回指定hash中所有的value 1#格式 hvals key hgetall:返回指定hash中所有的filed和value 1#格式 hgetall key 12345127.0.0.1:6379&gt; hgetall me1) "name"2) "illusory"3) "age"4) "23" 3. List可以看做Java中的List，不过更像Queue。 3.1 lpush/rpush 命令 描述 lpush key value1 [value2..] 将一个或多个值插入到列表头部 lpushx key value 将一个值插入到已存在的列表头部 rpush key value1 [value2..] 将一个或多个值插入到列表尾部 rpushx key value 将一个值插入到已存在的列表尾部 lset key index value 将列表 key 下标为 index 的元素的值设置为 value 。 linsert key BEFORE\ AFTER pivot value 将值 value 插入到列表 key 当中，位于值 pivot 之前或之后。 3.2 lpop/rpop 命令 描述 lpop key 移除并获取列表的第一个元素 blpop key [key …] timeout lpop的阻塞版本，没有元素可供弹出的时候会阻塞直到有元素或超时。 rpop key 移除并获取列表的倒数第一个元素 brpop key [key …] timeout rpop的阻塞版本，没有元素可供弹出的时候会阻塞直到有元素或超时。 rpoplpush source destination 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 brpoplpush source destination timeout rpoplpush的阻塞版，source为空时阻塞直到不为空或者超时。 lrem key count value 移除列表元素 lrange key start stop 返回列表 key 中指定区间内的元素，区间以偏移量 start 和 stop 指定。 ltrim key start stop 对一个列表进行修剪(trim)，只保留指定区间内的元素。 llen key 返回列表 key的长度。 lindex key index 返回列表 key 中，下标为 index的元素。 4. SetSet集合是String类型的无序集合，通过hashtable实现的，对集合我们可以取交集，并集，差集。 Java中List的升级版。 4.1 sadd/spop 命令 描述 sadd key member [member …] 将一个或多个 member 元素加入到集合 key 当中，已经存在于集合的 member 元素将被忽略 spop key 移除并返回集合中的一个随机元素。 srem key member [member …] 移除集合 key 中的一个或多个 member 元素，不存在的 member 元素会被忽略。 smove source destination member 将 member 元素从 source 集合移动到 destination 集合。 4.2 get 命令 描述 sinter key [key …] 返回给定所有集合的交集 sinterstore destination key [key …] 返回给定所有集合的交集并存储在 destination 中 sunion key [key …] 返回所有给定集合的并集 sunionstore destination key [key …] 返回所有给定集合的并集存储在 destination 集合中 sdiffkey [key …] 返回给定所有集合的差集 sdiffstore destination key [key …] 返回给定所有集合的差集并存储在 destination 中 smembers key 返回集合 key 中的所有成员。 sismember key member 判断 member 元素是否集合 key 的成员。 scard key 返回集合 key 的基数(集合中元素的数量) srandmember key [count] 返回集合中一个或多个随机数 5. ZSetZSet则是有序的。 5.1 zadd 命令 描述 zadd key score1 member1 [score2 member2…] 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。 zincrby key increment member 为有序集 key 的成员 member 的 score 值加上增量 increment 。 5.2 get 命令 描述 zscore key member 返回有序集 key 中，成员 member 的 score 值。 zcard key 返回有序集 key 的基数。(集合中元素的数量) zcount key min max 返回有序集 key 中， score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量。 zrange key start stop [withscores] 返回有序集 key 中，指定区间内的成员。其中成员的位置按 score 值递增(从小到大)来排序。 zrevrange key start stop [withscores] 类似zrange,不过成员位置按 score 值递增(从大到小)来排序。 zrangebyscore key min max [withscores][LIMIT offset count] 返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。 zrevrangebyscore key min max [withscores][LIMIT offset count] 类似zrangebyscore，不过有序集成员按 score 值递增(从小到大)次序排列。 zrank key member 返回有序集 key 中成员 member 的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。 zrevrank key member 类似zrank，其中有序集成员按 score 值递增(从大到小)顺序排列。 zrangebylex key min max [LIMIT offset count] 通过字典区间返回有序集合的成员 zlexcount key min max 返回该集合中， 成员介于 min 和 max 范围内的元素数量。 zuniostore destination numkeys key [key …] 计算给定的一个或多个有序集的并集，并存储在新的 key 中 zinterstore destination numkeys key [key …] 计算给定的一个或多个有序集的交集，并存储在新的 key 中 5.3 delete 命令 描述 zrem key member [member …] 移除有序集 key 中的一个或多个成员，不存在的成员将被忽略。 zremrangebyrank key start stop 移除有序集 key 中，指定排名(rank)区间内的所有成员。 zremrangebyscore key min max 移除有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员 zremrangebylex key min max 移除该集合中， 成员介于 min 和 max 范围内的所有元素。 6. Key命令Redis中所有key都可以使用的命令。 命令 描述 del key 该命令用于在 key 存在时删除 key。 dump key 序列化给定 key ，并返回被序列化的值。 exists key 检查给定 key 是否存在。 expire key seconds 为给定 key 设置过期时间，以秒计。 expireat key timestamp 类似expirre，都用于为 key 设置过期时间。 不同在于 expireat命令接受的时间参数是 UNIX 时间戳(unix timestamp)。 pexpire key milliseconds 设置 key 的过期时间以毫秒计。 pexpireat key timestamp 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计 keys pattern 类似模糊查询，查找所有符合给定模式( pattern)的 key。key l 查出以l开头的 move key db 将当前数据库的 key 移动到给定的数据库 db(0~15) 当中。 7. 其他命令 命令 描述 keys * 返回满足的所有键 (可以模糊匹配） exists key[keys…] 是否存在指定的key expire key secondes 设置某个key的过期时间， ttl key 与expire搭配，查看剩余时间 persist key 取消过期时间 select db(0~15) 择数据库数据库,默认进入的是0数据库 move key db(0~15) 将当前数据中的key转移到其他数据库中 randomkey 随机返回数据库里的一个key rename key 重命名key echo 打印命令 dbsize 查看数据库的key数量 info 获取数据库信息 conflg get 实时传储收到的请求(返回相关的配置信息} config get * 返回所有配置 flushdb 空当前数据库 flushall 清空所有数据库 8. 参考http://redisdoc.com/internal/index.html http://www.runoob.com/redis/redis-hashes.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门教程(一)---安装与配置]]></title>
    <url>%2Fposts%2F876962d5.html</url>
    <content type="text"><![CDATA[本文主要记录了如何在 Linux(CentOS 7) 下安装 Redis 与 Redis 基本使用与配置。 Redis系列教程目录 Redis入门教程(一)—安装与配置 Redis入门教程(二)—五大基础数据类型与常用命令 Redis入门教程(三)—安全性、事务、发布订阅 Redis入门教程(四)—主从复制与持久化 Redis入门教程(五)—搭建Redis集群 Redis入门教程(六)—通过JavaApi(Jedis)操作Redis Redis入门教程(七)—通过 Docker 安装 Redis ……. 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Redis安装1.1 下载官网https://redis.io/download 下载文件，这里下的是redis-5.0.3.tar.gz 然后上传到服务器。这里是放在了/usr/software目录下 1.2 环境准备安装编译源码所需要的工具和库: 1# yum install gcc gcc-c++ ncurses-devel perl 1.3 解压安装1. 解压12[root@localhost software]# tar -zxvf redis-5.0.3.tar.gz -C /usr/local//解压到/usr/local目录下 2. 编译进入刚才解压的后的文件夹redis-5.0.3进行编译 1[root@localhost redis-5.0.3]# make 如果提示Hint: It&#39;s a good idea to run &#39;make test&#39; ;)就说明编译ok了，接下来进行安装。 3. 安装进入src目录下 12[root@localhost redis-5.0.3]# cd src/[root@localhost src]# make install 出现下面的提示代表安装ok 123456789 CC Makefile.depHint: It's a good idea to run 'make test' ;) INSTALL install INSTALL install INSTALL install INSTALL install INSTALL install 4. 文件复制创建两个文件夹来存放Redis命令和配置文件。 12[root@localhost local]# mkdir -p /usr/local/redis/etc[root@localhost local]# mkdir -p /usr/local/redis/bin 把redis-5.0.3下的redis.conf复制到/usr/local/redis/etc`目录下 1[root@localhost redis-5.0.3]# cp redis.conf /usr/local/redis/etc/ 把redis-5.0.3/src里的mkreleasehdr.sh、redis-benchmark、redis-check-aof、redis-check-rdb、redis-cli、redis-server 文件移动到/usr/local/redis/bin下 1[root@localhost src]# mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-server /usr/local/redis/bin 2. 启动2.1 前台启动启动时并指定配置文件：. 1[root@localhost etc]# /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf 出现如下提示代表启动成功 1234567891011121314151617181920212223242526272829[root@localhost etc]# /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf10869:C 05 Mar 2019 13:33:39.041 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo10869:C 05 Mar 2019 13:33:39.042 # Redis version=5.0.3, bits=64, commit=00000000, modified=0, pid=10869, just started10869:C 05 Mar 2019 13:33:39.042 # Configuration loaded10869:M 05 Mar 2019 13:33:39.044 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 5.0.3 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ ''-._ ( ' , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 | `-._ `._ / _.-' | PID: 10869 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 10869:M 05 Mar 2019 13:33:39.046 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.10869:M 05 Mar 2019 13:33:39.046 # Server initialized10869:M 05 Mar 2019 13:33:39.047 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.10869:M 05 Mar 2019 13:33:39.047 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.10869:M 05 Mar 2019 13:33:39.047 * DB loaded from disk: 0.000 seconds10869:M 05 Mar 2019 13:33:39.047 * Ready to accept connections 退出：CTRL+C 2.2 后台启动(注意要使用后台启动需要修改redis.conf里的daemonize改为yes) 1234567891011121314151617[root@localhost etc]# vim redis.conf #主要修改下面这个daemonize# By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.# daemonize no 把这个改为yes no代表前台启动 yes代表后台启动daemonize yes# The working directory.## The DB will be written inside this directory, with the filename specified# above using the 'dbfilename' configuration directive.## The Append Only File will also be created inside this directory.## Note that you must specify a directory here, not a file name.# dir ./ 这个是工作区 默认为./ 即上级目录 这里也改一下dir /usr/local/redis/etc 再次启动 1[root@localhost etc]# /usr/local/redis/bin/redis-server /usr/local/redis/etc/redis.conf 验证启动是否成功： 1234[root@localhost etc]#/ps aux|grep redisroot 11012 0.2 0.2 153880 2344 ? Ssl 13:36 0:00 /usr/local/redis/bin/redis-server 127.0.0.1:6379root 11126 0.0 0.0 112708 976 pts/2 R+ 13:39 0:00 grep --color=auto redis redis启动成功端口号也是默认的6379。 2.3 使用1. 进入客户端进入redis客户端 12345#语法redis-cli -h host -p port -a password#连接本机则不用写host和port 这里没设置密码也不用写[root@localhost etc]# /usr/local/redis/bin/redis-cli 127.0.0.1:6379&gt; 成功进入Redis客户端 随意操作一下： 1234567891011121314127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; set name illusoryOK127.0.0.1:6379&gt; keys *1) "name"127.0.0.1:6379&gt; get name"illusory"127.0.0.1:6379&gt; set age 22OK127.0.0.1:6379&gt; get age"22"127.0.0.1:6379&gt; quit #退出命令[root@localhost etc]# 退出客户端：quit 2. 关闭Redis退出redis服务的三种方法： 1.pkill redis-server、 2.kill 进程号、 3./usr/local/redis/bhi/redis-cli shutdown 3. dump.rdb文件由于前面配置文件中配置的是dir /usr/local/redis/etc,所以Redis的所有数据都会存储在这个目录 1234[root@localhost etc]# lltotal 68-rw-r--r--. 1 root root 92 Mar 5 13:36 dump.rdb-rw-r--r--. 1 root root 62174 Mar 5 13:36 redis.conf 确实有这个文件。这个文件删除后Redis中的数据就真的没了。 3. 参考http://www.runoob.com/redis/redis-hashes.html]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门教程(四)---反向代理与负载均衡]]></title>
    <url>%2Fposts%2F930200c5.html</url>
    <content type="text"><![CDATA[本章主要对Nginx服务器的常用配置文件，包括虚拟主机配置，location配置级语法等。 Nginx入门教程系列文章目录 Nginx入门教程(一)—安装与配置 Nginx入门教程(二)—配置文件详解 Nginx入门教程(三)—日志文件切割 Nginx入门教程(四)—反向代理与负载均衡 …… 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 反向代理(proxy)1.1 简介如果您的内容服务器具有必须保持安全的敏感信息，如信用卡号数据库，可在防火墙外部设置一个代理服务器作为内容服务器的替身。 当外部客户机尝试访问内容服务器时，会将其送到代理服务器。实际内容位于内容服务器上，在防火墙内部受到安全保护。代理服务器位于防火墙外部，在客户机看来就像是内容服务器。 这样，代理服务器就在安全数据库和可能的恶意攻击之间提供了又一道屏障。与有权访问整个数据库的情况相对比，就算是侥幸攻击成功，作恶者充其量也仅限于访问单个事务中所涉及的信息。未经授权的用户无法访问到真正的内容服务器，因为防火墙通路只允许代理服务器有权进行访问。 就是客户端先访问Nginx服务器，Nginx收到请求后再去请求内容服务器,这样中间多了一个Nginx服务器中转，会更加安全。 1.2 配置1. 修改配置文件首先需要修改Nginx服务器配置文件nginx.conf`。 配置文件大概是这样的，在server中添加一个location用于中转。 123456789101112131415161718http&#123; keepalive_timeout 65; server&#123; listen 80; //端口号 server_name localhost; //域名 location \ &#123; root html; //网站根目录 index index.html; //网站首页 &#125; access_log logs/host.access.log main; //访问日志 error page 500 error.html; //错误页面 #这里就是代理 通过正则表达式来匹配 #后缀以.jsp结尾的请求都会跳转到 http://192.168.5.154:8080; location ~ \.jsp$ &#123; proxy_pass http://192.168.5.154:8080; &#125; &#125;&#125; 2. 开启内容服务器然后在192.168.5.154的8080端口开启了一个tomcat,当做是真正的内容服务器，在tomcat默认的index.jsp`中添加了一句显示IP地址的。 12&lt;!--测试Nginx反向代理新增--&gt;remote ip:&lt;%=request.getRemoteAddr()%&gt; 1.3 测试然后开始访问： 首先直接访问内容服务器(Tomcat)：192.168.5.154:8080 1remote ip:192.168.5.199 然后访问Nginx通过代理来访问内容服务器：192.168.5.154/index.jsp 1remote ip:192.168.5.154 显示远程 IP是192.168.5.154，这个刚好就是Nginx服务器的IP； 反向代理成功。 1.4 问题前面设置后反向代理已经成功了,但是这样设置后，每次访问内容服务器都显示的是Nginx服务器的IP,内容服务器无法获取用户的真实IP，所以还需要进行一点修改。 1. 修改123456789101112131415161718192021http&#123; keepalive_timeout 65; server&#123; listen 80; //端口号 server_name localhost; //域名 location \ &#123; root html; //网站根目录 index index.html; //网站首页 &#125; access_log logs/host.access.log main; //访问日志 error page 500 error.html; //错误页面 #这里就是代理 通过正则表达式来匹配 #后缀以.jsp结尾的请求都会跳转到 http://192.168.5.154:8080; location ~ \.jsp$ &#123; #在请求头中添加上真实的IP #具体格式为 proxy_set_header 属性名 数据 proxy_set_header X-real-ip $remote_addr proxy_pass http://192.168.5.154:8080; &#125; &#125;&#125; proxy_set_header X-real-ip $remote_addr :Nginx服务器是知道客户端真实IP的，所以为了让内容服务器知道真实IP，只需要将真实IP添加到请求头中就可以了。 其中X-real-ip 是自定义的，内容服务器取数据时也使用这个X-real-ip $remote_addr 则是获取远程客户端IP。 2. 测试：修改jsp，添加了一句代码。 1234 &lt;!--测试Nginx反向代理新增--&gt;&lt;!--获取请求头中的真实IP--&gt; Real remote ip:&lt;%=request.getHeader("X-real-ip")%&gt; &lt;br /&gt; remote ip/Nginx ip:&lt;%=request.getRemoteAddr()%&gt; 然后开始访问： 首先直接访问内容服务器(Tomcat)：192.168.5.154:8080 12Real remote ip:null remote ip/Nginx ip:192.168.5.199 然后访问Nginx通过代理来访问内容服务器：192.168.5.154/index.jsp 12Real remote ip:192.168.5.199 remote ip/Nginx ip:192.168.5.154 成功获取到真实IP，问题解决。 2. 负载均衡(upstream)2.1 简介可以在一个组织内使用多个代理服务器来平衡各 Web 服务器间的网络负载。 对于客户机发往真正服务器的请求，代理服务器起着中间调停者的作用。客户机每次都使用同一个 URL，但请求所采取的路由每次都可能经过不同的代理服务器。 同样是客户端先访问Nginx服务器，然后Nginx服务器再根据负载均衡算法将请求分发到不同的内容服务器上。 2.2 配置同意需要修改Nginx服务器配置文件nginx.conf`。 配置文件大概是这样的，在server中添加一个location用于中转。 12345678910111213141516171819202122232425262728293031323334http&#123; keepalive_timeout 65; #upstream 负载均衡 与server同级 #tomcat_server 负载均衡名字 自定义的 #要用在下面location反向代理处 #poxy_pass http://tomcat_server; upstream tomcat_server&#123; #weight权重 max_fails 最大失败次数 超过后就认为该节点down掉了 fail_timeout 超时时间 #192.168.5.154:8080 IP地址或者域名都可以 server 192.168.5.154:8080 weight=1 max_fails=2 fail_timeout=30s; server 192.168.5.155:8080 weight=1 max_fails=2 fail_timeout=30s; &#125; server&#123; listen 80; //端口号 server_name localhost; //域名 location \ &#123; root html; //网站根目录 index index.html; //网站首页 &#125; access_log logs/host.access.log main; //访问日志 error page 500 error.html; //错误页面 #proxy_pass 反向代理 通过正则表达式来匹配 #后缀以.jsp结尾的请求都会跳转到 http://192.168.5.154:8080; #proxy_set_header 将真实IP添加到请求头中 传递到内容服务器 location ~ \.jsp$ &#123; proxy_set_header X-real-ip $remote_addr #proxy_pass http://192.168.5.154:8080; #反向代理这里不光可以写IP 还可以写上面配置的负载均衡 proxy_pass http://tomcat_server; &#125; &#125;&#125; 2.3 测试开启两个tomcat，一个是192.168.5.154,一个是192.168.5.155`. 然后浏览器访问nginx服务器：192.168.5.154/index.jsp； 会随机跳转到两个tomcat服务器中的一个就说明负载均衡配置成功了。 3. 参考http://www.runoob.com/linux/nginx-install-setup.html https://www.cnblogs.com/javahr/p/8318728.html]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门教程(三)---日志文件切割]]></title>
    <url>%2Fposts%2F3ebafd31.html</url>
    <content type="text"><![CDATA[本章主要对Nginx服务器的日志文件分析，包括日志文件切割与cron定时任务语法详解。 Nginx入门教程系列文章目录 Nginx入门教程(一)—安装与配置 Nginx入门教程(二)—配置文件详解 Nginx入门教程(三)—日志文件切割 Nginx入门教程(四)—反向代理与负载均衡 …… 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 日志文件再看一下Nginx目录结构 12345/usr/local/nginx --conf 配置文件 --html 网页文件 --logs 日志文件 --sbin 主要二进制文件 1.1 查看日志前面看了conf配置文件，这里看下logs日志文件; 1234/usr/local/nginx/logs -- access.log #访问日志 -- error.log #错误日志 -- nginx.pid #存放Nginx当前进程的pid nginx.pid 存放Nginx当前进程的pid 123456[root@localhost logs]# cat nginx.pid98830[root@localhost logs]# ps aux|grep nginxroot 98830 0.0 0.0 20552 616 ? Ss 09:57 0:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 98831 0.0 0.1 23088 1636 ? S 09:57 0:00 nginx: worker processroot 105254 0.0 0.0 112708 976 pts/1 R+ 11:02 0:00 grep --color=auto nginx access.log 访问日志 1234[root@localhost logs]# tail -f -n 20 access.log192.168.5.199 - - [04/Mar/2019:10:02:10 +0800] "GET / HTTP/1.1" 200 612 "-" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36"192.168.5.199 - - [04/Mar/2019:10:02:10 +0800] "GET /favicon.ico HTTP/1.1" 404 555 "http://192.168.5.154/" "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36" 1.2 日志分割Nginx日志都会存在一个文件里，随着时间推移，这个日志文件会变得非常大，分析的时候很难操作，所以需要对日志文件进行分割，可以根据访问量来进行选择：如按照天分割、或者半天、小时等。 建议使用shell脚本方式进行切割日志 。 1. 编写脚本脚本如下： 12345678910111213141516171819202122232425262728293031323334#!/bin/sh#根路径BASE_DIR=/usr/local/nginx#最开始的日志文件名BASE_FILE_NAME_ACCESS=access.logBASE_FILE_NAME_ERROR=error.logBASE_FILE_NAME_PID=nginx.pid#默认日志存放路径DEFAULT_PATH=$BASE_DIR/logs#日志备份根路径BASE_BAK_PATH=$BASE_DIR/datalogsBAK_PATH_ACCESS=$BASE_BAK_PATH/accessBAK_PATH_ERROR=$BASE_BAK_PATH/error#默认日志文件路径+文件名DEFAULT_FILE_ACCESS=$DEFAULT_PATH/$BASE_FILE_NAME_ACCESSDEFAULT_FILE_ERROR=$DEFAULT_PATH/$BASE_FILE_NAME_ERROR#备份时间BAK_TIME=`/bin/date -d yesterday +%Y%m%d%H%M`#备份文件 路径+文件名BAK_FILE_ACCESS=$BAK_PATH_ACCESS/$BAK_TIME-$BASE_FILE_NAME_ACCESSBAK_FILE_ERROR=$BAK_PATH_ERROR/$BAK_TIME-$BASE_FILE_NAME_ERROR # 打印一下备份文件 echo access.log备份成功：$BAK_FILE_ACCESSecho error.log备份成功：$BAK_FILE_ERROR#移动文件mv $DEFAULT_FILE_ACCESS $BAK_FILE_ACCESSmv $DEFAULT_FILE_ERROR $BAK_FILE_ERROR#向nginx主进程发信号重新打开日志kill -USR1 `cat $DEFAULT_PATH/$BASE_FILE_NAME_PID` 其实很简单，主要步骤如下： 1.移动日志文件：这里已经将日志文件移动到datalogs`目录下了，但Nginx还是会继续往这里面写日志 2.发送USR1命令：告诉Nginx把日志写到Nginx.conf`中配置的那个文件中，这里会重新生成日志文件 具体如下： 第一步:就是重命名日志文件，不用担心重命名后nginx找不到日志文件而丢失日志。在你未重新打开原名字的日志文件前(即执行第二步之前)，nginx还是会向你重命名的文件写日志，Linux是靠文件描述符而不是文件名定位文件。 第二步:向nginx主进程发送USR1信号。nginx主进程接到信号后会从配置文件中读取日志文件名称，重新打开日志文件(以配置文件中的日志名称命名)，并以工作进程的用户作为日志文件的所有者。重新打开日志文后，nginx主进程会关闭重名的日志文件并通知工作进程使用新打开的日志文件。(就不会继续写到前面备份的那个文件中了)工作进程立刻打开新的日志文件并关闭重名名的日志文件。然后你就可以处理旧的日志文件了。 2. 赋权1[root@localhost sbin]# chmod 777 log.sh 将log.sh脚本设置为可执行文件 3. 执行设置一个定时任务用于周期性的执行该脚本 cron是一个linux下的定时执行工具，可以在无需人工干预的情况下运行作业。 123456789service crond start //启动服务service crond stop //关闭服务service crond restart //重启服务service crond reload //重新载入配置service crond status //查看服务状态 设置定时任务： 123[root@localhost datalogs]# crontab -e*/1 * * * * sh /usr/local/nginx/sbin/log.sh */1 * * * *： 为定时时间 这里为了测试 是设置的每分钟执行一次； 0 2 * * * :每天凌晨两点执行 sh ：为任务类型 这里是一个sh脚本 /usr/local/nginx/sbin/log.sh ：为脚本路径 4. Nginx信号量Nginx支持以下几种信号选项： TERM，INT : 快速关闭 QUIT ：从容关闭（优雅的关闭进程,即等请求结束后再关闭) HUP ：平滑重启，重新加载配置文件 （平滑重启，修改配置文件之后不用重启服务器。直接kill -PUT 进程号即可） USR1 ：重新读取日志文件，在切割日志时用途较大（停止写入老日志文件，打开新日志文件，之所以这样是因为老日志文件就算修改的文件名，由于inode的原因，nginx还会一直往老的日志文件写入数据） USR2 ：平滑升级可执行程序 ，nginx升级时候用 WINCH ：从容关闭工作进程 2.cron表达式2.1 基本语法 cron表达式代表一个时间的集合，使用6个空格分隔的字段表示： 字段名 是否必须 允许的值 允许的特定字符 秒(Seconds) 是 0-59 * / , - 分(Minute) 是 0-59 * / , - 时(Hours) 是 0-23 * / , - 日(Day of month) 是 1-31 * / , - ? 月(Month) 是 1-12 或 JAN-DEC * / , - 星期(Day of week) 否 0-6 或 SUM-SAT * / , - ? 注：月(Month)和星期(Day of week)字段的值不区分大小写，如：SUN、Sun 和 sun 是一样的。 星期字段没提供相当于* 一般只需要写5位就行了。即 分 时 日 月 周 123456789# ┌───────────── min (0 - 59)# │ ┌────────────── hour (0 - 23)# │ │ ┌─────────────── day of month (1 - 31)# │ │ │ ┌──────────────── month (1 - 12)# │ │ │ │ ┌───────────────── day of week (0 - 6) (0 to 6 are Sunday to# │ │ │ │ │ Saturday, or use names; 7 is also Sunday)# │ │ │ │ │# │ │ │ │ │# * * * * * command to execute 2.2 特定字符 星号(*):表示 cron 表达式能匹配该字段的所有值。如在第2个字段使用星号(hour)，表示每小时 斜线(/):表示增长间隔，如第1个字段(minutes) 值是 3/1，表示每小时的第3分钟开始执行一次，之后每隔1分钟执行一次（1,2,3,4….59都执行一次） 逗号(,):用于枚举值，如第6个字段值是 MON,WED,FRI，表示 星期一、三、五 执行。 连字号(-):表示一个范围，如第3个字段的值为 9-17 表示 9am 到 5pm 之间每个小时（包括9和17） 问号(?):只用于 日(Day of month) 和 星期(Day of week)，表示不指定值，可以用于代替 * 3. 参考https://www.cnblogs.com/crazylqy/p/6891929.html http://www.runoob.com/linux/nginx-install-setup.html]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门教程(二)---配置文件详解]]></title>
    <url>%2Fposts%2F5a0a337e.html</url>
    <content type="text"><![CDATA[本章主要对Nginx服务器的常用配置文件，包括虚拟主机配置，location配置级语法等。 Nginx入门教程系列文章目录 Nginx入门教程(一)—安装与配置 Nginx入门教程(二)—配置文件详解 Nginx入门教程(三)—日志文件切割 Nginx入门教程(四)—反向代理与负载均衡 …… 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 虚拟主机配置在前面启动Nignx后，Nginx目录下会多出几个文件夹 1234567891011/usr/local/nginx --conf 配置文件 --html 网页文件 --logs 日志文件 --sbin 主要二进制文件 --client_body_temp --fastcgi_temp --proxy_temp --scgi_temp --uwsgi_temp 不过这些temp文件夹都不是重点。 1.1 配置文件这里讲解一下conf里的配置文件，有很多配置文件，重点看nginx.conf. 12345678910111213141516/usr/local/nginx/conf -- fastcgi.conf -- fastcgi.conf.default -- fastcgi_params -- fastcgi_params.default -- koi-utf -- koi-win -- mime.types -- mime.types.default -- nginx.conf # 重点关心这个 -- nginx.conf.default -- scgi_params -- scgi_params.default -- uwsgi_params -- uwsgi_params.default --win-utf 1.2 nginx.conf看一下默认的nginx.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108[root@localhost conf]# vim nginx.conf//默认配置如下：#可以指定用户 不过无所谓#user nobody; #nginx工作进程,一般设置为和cpu核数一样worker_processes 1; #错误日志存放目录 #error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#进程pid存放位置#pid logs/nginx.pid;events &#123; # 单个CPU最大连接数 worker_connections 1024;&#125;# http 这里重点http &#123; #文件扩展名与类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #设置日志模式 #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; #开启高效传输模式 sendfile on; # 激活tcp_nopush参数可以允许把httpresponse header和文件的开始放在一个文件里发布 # 积极的作用是减少网络报文段的数量 #tcp_nopush on; #连接超时时间，单位是秒 #keepalive_timeout 0; keepalive_timeout 65; #开启gzip压缩功能 #gzip on; #基于域名的虚拟主机 server &#123; #监听端口 listen 80; #域名 server_name localhost; #字符集 #charset koi8-r; #nginx访问日志 这里的main就是上面配置的那个log_format main #access_log logs/host.access.log main; #location 标签 #这里的/表示匹配根目录下的/目录 location / &#123; #站点根目录，即网站程序存放目录 #就是上面的四个文件夹中的html文件夹 root html; #首页排序 默认找index.html 没有在找index.htm index index.html index.htm; &#125; # 错误页面 #error_page 404 /404.html; # redirect server error pages to the static page /50x.html #错误页面 错误码为500 502 503 504时 重定向到50x.html error_page 500 502 503 504 /50x.html; #location 标签 #这里的表示匹配根目录下的/50x.html location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; 1.3 基本配置上面的配置文件好像挺长的，其实最重要的就那么几个。 12345678910111213http&#123; keepalive_timeout 65; server&#123; listen 80; //端口号 server_name localhost; //域名 location \ &#123; root html; //网站根目录 index index.html; //网站首页 &#125; access_log logs/host.access.log main; //访问日志 error page 500 error.html; //错误页面 &#125;&#125; 2. location2.1 简介nginx.conf大概内容如下： 12345678910111213http&#123; keepalive_timeout 65; server&#123; listen 80; //端口号 server_name localhost; //域名 location \ &#123; root html; //网站根目录 index index.html; //网站首页 &#125; access_log logs/host.access.log main; //访问日志 error page 500 error.html; //错误页面 &#125;&#125; 其中server代表虚拟主机，一个虚拟主机可以配置多个location location表示uri方法定位 基本语法如下： 1.location=pattern{} 静准匹配 2.location pattern{} 一般匹配 3.location~pattern{} 正则匹配 Nginx可以对数据进行压缩，对一些图片、css、js、html等文件进行缓存，从而实现动静分离等待优化功能。 动态的就去访问tomcat服务器，静态的就直接访问Nginx服务器。 基本语法： 123location [=|~|~*|^~|@] /uri/ &#123; ....&#125; 〖=〗 表示精确匹配，如果找到，立即停止搜索并立即处理此请求。〖~ 〗 表示区分大小写匹配〖~*〗 表示不区分大小写匹配〖^~ 〗 表示只匹配字符串,不查询正则表达式。 〖@〗 指定一个命名的location，一般只用于内部重定向请求。 2.2 正则表达式1.语法格式： 123location [=|~|~*|^~|@] /uri/ &#123; .....&#125; 1.依据不同的前缀=，^~,~，~* ”和不带任何前缀(因为[ ] 表示可选，可以不要的)表达不同的含义。 简单的说尽管location 的/uri/ 配置一样，但前缀不一样，表达的是不同的指令含义。注意：查询字符串不在URI范围内。例如：/films.htm?fid=123 的URI 是/films.htm。 2.对这些不同前缀，分下类，就2 大类： 正则location : ~和~*前缀表示正则location ，~区分大小写，~*不区分大小写。 普通location : =，^~和@和 无任何前缀, 都属于普通location 。 详细说明： ~ : 区分大小写匹配 ~* : 不区分大小写匹配 !~ : 区分大小写不匹配 !~* : 不区分大小写不匹配 ^ : 以什么开头的匹配 $ : 以什么结尾的匹配 * : 代表任意字符 3. 参考http://www.runoob.com/linux/nginx-install-setup.html]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx入门教程(一)---安装与配置]]></title>
    <url>%2Fposts%2F545ed69.html</url>
    <content type="text"><![CDATA[本章主要对Nginx服务器进行了介绍，同时对Nginx与Apache之间做出了对比，最后记录了如何在Linux下通过解压方式安装Nginx，也对Nginx基本使用做出了说明。 Nginx入门教程系列文章目录 Nginx入门教程(一)—安装与配置 Nginx入门教程(二)—配置文件详解 Nginx入门教程(三)—日志文件切割 Nginx入门教程(四)—反向代理与负载均衡 …… 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Nginx简介Nginx是一款轻量级的Web服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好。 1.1 Nginx模块架构Nginx 由内核和模块组成。Nginx 的模块从结构上分为核心模块、基础模块和第三方模块。 核心模块：HTTP 模块、 EVENT 模块和 MAIL 模块 基础模块： HTTP Access 模块、HTTP FastCGI 模块、HTTP Proxy 模块和 HTTP Rewrite模块 第三方模块：HTTP Upstream Request Hash 模块、 Notice 模块和 HTTP Access Key模块 1.2 Nignx与AppacheNginx的高并发得益于其采用了epoll模型，与传统的服务器程序架构不同epoll 是linux内核2.6以后才出现的。 Nginx采用epoll模型，异步非阻塞，而Apache采用的是select 模型 。 Select模型：select 选择句柄的时候是遍历所有句柄，也就是说句柄有事件响应时，select 需要遍历所有句柄才能获取到哪些句柄有事件通知，因此效率是非常低。 epoll 模型：epoll对于句柄事件的选择不是遍历的，是事件响应的，就是句柄上事件来就马上选择出来，不需要遍历整个句柄链表，因此效率非常高。 2. 安装注：这里用的是CentOS 7 2.1 安装包下载官网：http://nginx.org/en/download.html 这里下载的时nginx-1.15.9.tar.gz 上传到服务器上，这里放在了usr/software目录下 2.2 环境准备安装编译源码所需要的工具和库: 1# yum install gcc gcc-c++ ncurses-devel perl 安装HTTP rewrite module模块: 1# yum install pcre pcre-devel 安装HTTP zlib模块: 1# yum install zlib gzip zlib-devel 2.3 编译安装解压： 12[root@localhost software]# tar -zxvf nginx-1.15.9.tar.gz -C /usr/local//解压到/usr/local目录下 配置: 进行configure配置，检查是否报错。 12345678910111213[root@localhost nginx-1.15.9]# ./configure --prefix=/usr/local/nginx//出现下面的配置摘要就算配置okConfiguration summary + using system PCRE library + OpenSSL library is not used + using system zlib library nginx path prefix: &quot;/usr/local/nginx&quot; nginx binary file: &quot;/usr/local/nginx/sbin/nginx&quot; ..... nginx http uwsgi temporary files: &quot;uwsgi_temp&quot; nginx http scgi temporary files: &quot;scgi_temp&quot; 编译安装: 1234[root@localhost nginx-1.15.9]# make&amp;&amp;make install//出现下面的提示就算编译安装okmake[1]: Leaving directory `/usr/local/nginx-1.15.9&apos; 编译安装后多了一个Nginx文件夹,在/usr/local/nginx 内部又分为四个目录 12345/usr/local/nginx --conf 配置文件 --html 网页文件 --logs 日志文件 --sbin 主要二进制文件 查看Nginx版本: 123[root@localhost nginx]# /usr/local/nginx/sbin/nginx -vnginx version: nginx/1.15.9//这里是Nginx 1.15.9 到这里Nginx安装就结束了。 3. 基本操作3.1 启动123[root@localhost sbin]# /usr/local/nginx/sbin/nginx//这里如果没有报错就说明启动成功了 查看 1234[root@localhost sbin]# ps aux|grep nginxroot 98830 0.0 0.0 20552 616 ? Ss 09:57 0:00 nginx: master process /usr/local/nginx/sbin/nginxnobody 98831 0.0 0.1 23088 1392 ? S 09:57 0:00 nginx: worker processroot 98839 0.0 0.0 112708 976 pts/1 R+ 09:57 0:00 grep --color=auto nginx 可以看到Nginx有两个进程，一个master进程一个worker进程. 同时浏览器已经可以访问了:直接访问IP地址即可http://192.168.5.154/ 显示如下： 1234567Welcome to nginx!If you see this page, the nginx web server is successfully installed and working. Further configuration is required.For online documentation and support please refer to nginx.org.Commercial support is available at nginx.com.Thank you for using nginx. 说明Nginx确实已经启动了。 3.2 常用命令12345[root@localhost sbin]# /usr/local/nginx/sbin/nginx -s reload # 重新载入配置文件[root@localhost sbin]# /usr/local/nginx/sbin/nginx -s reopen # 重启 Nginx[root@localhost sbin]# /usr/local/nginx/sbin/nginx -s stop # 停止 Nginx 4. 参考http://www.runoob.com/linux/nginx-install-setup.html]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock源码分析]]></title>
    <url>%2Fposts%2Fef6a0c58.html</url>
    <content type="text"><![CDATA[本文主要对ReentrantLock的源码进行了简单的分析，具体包括ReentrantLock的初始化(公平锁和非公平锁)，加锁过程和解锁过程等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. AbstractQueuedSynchronizerReentrantLock的实现依赖于AbstractQueuedSynchronizer所以需要了解一下AQS。 1.1 简介类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架，是java.util.concurrent的核心，CountDownLatch、FutureTask、Semaphore、ReentrantLock等都有一个内部类是这个抽象类的子类。 AQS定义两种资源共享方式： Exclusive: 独占，只有一个线程能执行,如ReentrantLock Share: 共享，多个线程可同时执行，如Semaphore/CountDownLatch 1.2 AQS的4个属性12345678910// 头结点，大概可以看做是当前持有锁的线程private transient volatile Node head;// 阻塞的尾节点，每个新的节点进来，都插入到最后private transient volatile Node tail;//当前锁的状态，0代表没有被占用，大于0代表有线程持有当前锁 //是可重入锁 每次获取都活加1private volatile int state;// 代表当前持有独占锁的线程 锁重入时用这个来判断当前线程是否已经拥有了锁//继承自AbstractOwnableSynchronizerprivate transient Thread exclusiveOwnerThread; 1.3 阻塞队列Node节点的属性 Node 的数据结构其实也挺简单的，就是 thread + waitStatus + pre + next 四个属性而已。 12345678910111213141516171819202122232425262728293031323334353637383940414243static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ // 标识节点当前在共享模式下 static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ // 标识节点当前在独占模式下 static final Node EXCLUSIVE = null; // ======== 下面的几个int常量是给waitStatus用的 =========== /** waitStatus value to indicate thread has cancelled */ // 表示此线程取消了争抢这个锁 static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ //被标识为该等待唤醒状态的后继结点，当其前继结点的线程释放了同步锁或被取消， //将会通知该后继结点的线程执行。 //就是处于唤醒状态，只要前继结点释放锁，就会通知标识为SIGNAL状态的后继结点的线程执行。 static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ //该标识的结点处于等待队列中，结点的线程等待在Condition上,等待其他线程唤醒 //当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将 //从等待队列转移到同步队列中，等待获取同步锁。 static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ // 与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。 static final int PROPAGATE = -3; // ===================================================== // 节点的等待状态 // 取值为上面的1、-1、-2、-3，或者0 // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待， // 也许就是说半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的 //AQS在判断状态时，通过用waitStatus&gt;0表示取消状态，而waitStatus&lt;0表示有效状态。 volatile int waitStatus; // 前驱节点的引用 volatile Node prev; // 后继节点的引用 volatile Node next; // 这个就是线程对象 volatile Thread thread;&#125; 2. ReentrantLock的使用123456789101112131415161718192021222324/** * Server层 * 模拟ReentrantLock使用 * * @author illusoryCloud */public class UserServer &#123; /** * 默认是非公平锁 传入参数true则创建的是公平锁 */ private static ReentrantLock reentrantLock = new ReentrantLock(true); public void updateUser() &#123; //加锁 同一时刻只能有一个线程更新User reentrantLock.lock(); try &#123; //do something &#125; finally &#123; //释放锁放在finally代码块中 保证出现异常等情况也能释放锁 reentrantLock.unlock(); &#125; &#125;&#125; 3. ReentrantLock源码分析1. 初始化ReentrantLock reentrantLock = new ReentrantLock(true); 12345678910/** *默认是非公平锁 */public ReentrantLock() &#123; sync = new NonfairSync();&#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 2. 加锁过程reentrantLock.lock(); 公平锁实现如下(JDK1.8)： 1234567891011121314151617181920212223242526272829303132333435 /** * Sync object for fair locks */ static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L;//争锁 final void lock() &#123; //1 acquire(1); &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125; &#125; 1. acquire(1); 1234567891011121314/** * 尝试获取锁 */public final void acquire(int arg) &#123; //tryAcquire(1) 首先尝试获取一下锁 //若成功则不需要进入等待队列了 //1.1 if (!tryAcquire(arg) &amp;&amp; //1.2 // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //1.3 selfInterrupt();&#125; 1.1 tryAcquire(1) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. * 尝试直接获取锁，返回值是boolean，代表是否获取到锁 * 返回true：1.没有线程在等待锁；2.重入锁，线程本来就持有锁，也就可以理所当然可以直接获取 */protected final boolean tryAcquire(int acquires) &#123; //获取当前线程 final Thread current = Thread.currentThread(); //查看锁的状态 int c = getState(); //state == 0 此时此刻没有线程持有锁 可以直接获取锁 if (c == 0) &#123; //由于是公平锁 则在获取锁之前先看一下队列中还有没有其他等待的线程 //讲究先来后到 所以是公平锁 这也是和非公平锁的差别 //非公平锁在这里会直接尝试获取锁 //1.1.1 if (!hasQueuedPredecessors() &amp;&amp; // 如果没有线程在等待，那就用CAS尝试获取一下锁 // 不成功的话，只能说明几乎同一时刻有个线程抢先获取到了锁 //因为刚才hasQueuedPredecessors判断是前面没有线程在等待的 //1.1.2 compareAndSetState(0, acquires)) &#123; //获取到锁后把当前线程设置为锁的拥有者 //1.1.3 setExclusiveOwnerThread(current); //获取锁成功直接返回true return true; &#125; &#125; //到这里说明当前锁已经被占了 //然后判断如果当前线程就是持有锁的线程 //那么这次就是锁的重入 else if (current == getExclusiveOwnerThread()) &#123; //把state加1 int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); //1.1.4 setState(nextc); return true; &#125; //上面两个条件都不满足就返回false //获取锁失败了 回到上一个方法继续看 return false;&#125; 1.1.1 hasQueuedPredecessors() 1234567891011121314/** * 通过判断"当前线程"是不是在CLH队列的队首 * 来返回AQS中是不是有比“当前线程”等待更久的线程 */public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; 1.1.2 compareAndSetState(0, acquires)) 1234567/** * 通过CAS设置锁的状态 */ protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); &#125; 1.1.3 setExclusiveOwnerThread(current) 123456/** * 设置锁的拥有者 */ protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; 1.1.4 setState(nextc) 123456/** * 设置锁的状态 */ protected final void setState(int newState) &#123; state = newState; &#125; 回到前面的方法 123456789101112131415/** * 尝试获取锁 */public final void acquire(int arg) &#123; //tryAcquire(1) 首先尝试获取一下锁 //若成功则不需要进入等待队列了 //1.1 if (!tryAcquire(arg) &amp;&amp; //1.2 // tryAcquire(arg)没有成功，这个时候需要把当前线程挂起，放到阻塞队列中。 //addWaiter(Node.EXCLUSIVE) 1.2.1 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //1.3 selfInterrupt();&#125; 1.1tryAcquire返回false则继续执行后面的 1.2acquireQueued(addWaiter(Node.EXCLUSIVE), arg) 1.2.1 addWaiter(Node.EXCLUSIVE) 12345678910111213141516171819202122232425262728293031/** * 此方法的作用是把线程包装成node，同时进入到队列中 * 参数mode此时是Node.EXCLUSIVE，代表独占模式 */ private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 以下几行代码想把当前node加到链表的最后面去，也就是进到阻塞队列的最后 Node pred = tail; // tail!=null --&gt; 队列不为空 if (pred != null) &#123; // 设置自己的前驱 为当前的队尾节点 node.prev = pred; // 用CAS把自己设置为队尾, 如果成功后，tail == node了 //1.2.1.1 if (compareAndSetTail(pred, node)) &#123; // 进到这里说明设置成功，当前node==tail, 将自己与之前的队尾相连， // 上面已经有 node.prev = pred // 加上下面这句，也就实现了和之前的尾节点双向连接了 pred.next = node; // 线程入队了，可以返回了 return node; &#125; &#125; // 仔细看看上面的代码，如果会到这里， // 说明 pred==null(队列是空的) 或者 CAS失败(有线程在竞争入队) //1.2.1.2 enq(node); return node; &#125; 1.2.1.1 compareAndSetTail(pred, node) 123456/** * 使用CAS设置队列的Tail */private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update); &#125; 1.2.1.2enq(node) 1234567891011121314151617181920212223242526272829303132/** * 进入这个方法只有两种可能：1.等待队列为空 2.有线程竞争入队 * 采用自旋的方式入队 * CAS设置tail过程中，竞争一次竞争不到，多次竞争，总会排到的 */ private Node enq(final Node node) &#123; //无限循环 for (;;) &#123; Node t = tail; // 如果队列是空的就去初始化 if (t == null) &#123; // Must initialize // CAS初始化head节点 //1.2.1.2.1 if (compareAndSetHead(new Node())) // 给后面用：这个时候head节点的waitStatus==0, 看new Node()构造方法就知道了 // 这个时候有了head，但是tail还是null，设置一下， // 设置完了以后，继续for循环，下次就到下面的else分支了 tail = head; &#125; else &#123; // 下面几行，和上一个方法 addWaiter 是一样的， // 通过CAS将当前线程排到队尾，有线程竞争的话排不上重复排 // 直到成功了才return // 这里return后前面的addWaiter()方法也返回 // 接下来进入acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; 1.2 acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) 123456789101112131415161718192021222324252627282930313233343536373839/** * 参数node，经过addWaiter(Node.EXCLUSIVE)，此时已经进入阻塞队列 * 如果acquireQueued(addWaiter(Node.EXCLUSIVE), arg))返回true的话 * 意味着上面这段代码将进入selfInterrupt()，所以正常情况下，下面应该返回false * * 这个方法非常重要，应该说真正的线程挂起，然后被唤醒后去获取锁，都在这个方法里了 */final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //这里无线循环 直到下面的条件满足 //获取当前节点的前一个节点 设置为p final Node p = node.predecessor(); //p=head说明当前节点是队列的第一个 // 所以当前节点可以去试抢一下锁 // enq(node) 方法里面有提到，head是延时初始化的，而且new Node()的时候没有设置任何线程 // 也就是说，当前的head可能不属于任何一个线程，所以作为队头，可以去试一试， // tryAcquire已经分析过了,就是简单用CAS试操作一下state if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 到这里，说明上面的if分支没有成功 //要么当前node本来就不是队头 // 要么就是tryAcquire(arg)没有抢赢别人 //1.2.2 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; //1.2.3 parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 1.2.2 shouldParkAfterFailedAcquire(p, node) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 进入这里说明抢到锁，这个方法说的是："当前线程没有抢到锁，是否需要挂起当前线程？" * 第一个参数是前驱节点，第二个参数代表当前线程的节点 这里一共有三个规则 * 1.如果前继的节点状态为SIGNAL，表明当前节点需要unpark，则返回true 将导致线程阻塞 * 2.如果前继节点状态为CANCELLED(ws&gt;0)，说明前置节点已经被放弃，则找到一个非取消的前驱节点 * 返回false，acquireQueued方法的无限循环将递归调用该方法，直至规则1返回true * 3.如果前继节点状态为非SIGNAL、非CANCELLED，则设置前继的状态为SIGNAL * 返回false后进入acquireQueued的无限循环，与规则2同 */private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; // 前驱节点的 waitStatus == -1 ，说明前驱节点状态正常，当前线程需要挂起，直接可以返回true if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; // 前驱节点 waitStatus大于0 ，说明前驱节点取消了排队。 // 进入阻塞队列排队的线程会被挂起，而唤醒的操作是由前驱节点完成的。 // 所以下面这块代码说的是将当前节点的prev指向waitStatus&lt;=0的节点， // 就是为当前节点找一个正常的前驱节点 毕竟当前节点需要等着前驱节点来唤醒 if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ // 这里就在循环直到找到一个waitStatus 不大于 0的前驱节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 仔细想想，如果进入到这个分支意味着什么 // 前驱节点的waitStatus不等于-1也不大于0，那也就是只可能是0，-2，-3 // 这里说明一下：每个新的node入队时，waitStatu都是0 // 用CAS将前驱节点的waitStatus设置为Node.SIGNAL(也就是-1) compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 1.2.3 parkAndCheckInterrupt() 12345678/** *这个方法很简单，因为前面返回true，所以需要挂起线程，这个方法就是负责挂起线程的 *这里用了LockSupport.park(this)来挂起线程，然后就停在这里了，等待被唤醒 */ private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; 3. 解锁过程reentrantLock.unlock() 解锁的代码比较相比加锁的要简单不少 1234567/** * 解锁 */public void unlock() &#123; //1 sync.release(1);&#125; 1. sync.release(1) 12345678910111213141516171819202122/** * 释放锁 * */public final boolean release(int arg) &#123; //1.1 //这里尝试释放锁如果成功则进入if里面 if (tryRelease(arg)) &#123; // h赋值为当前的head节点 Node h = head; //如果head节点不是null //并且head节点的waitStatus不等于0 即head节点不是刚初始化的 //因为刚初始化是waitStatus是等于0的 if (h != null &amp;&amp; h.waitStatus != 0) //1.2 //唤醒后继节点 unparkSuccessor(h); return true; &#125; return false;&#125; 1.1 tryRelease(1) 1234567891011121314151617181920212223/** * 尝试释放锁 */protected final boolean tryRelease(int releases) &#123; //可重入锁 所以state可以大于1 每次释放时state减1 int c = getState() - releases; //如果当前线程不是拥有锁的线程直接抛出异常 这肯定嘛 都没获取到锁你释放什么 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); // 是否完全释放锁 boolean free = false; // state==0了 说明可以完全释放锁了 if (c == 0) &#123; free = true; //把锁的拥有者设置为null setExclusiveOwnerThread(null); &#125; //锁的状态设置为0 即没有被获取 setState(c); //到这里 锁已经释放了 //回到上边的release(1)方法 return free;&#125; 1.2 unparkSuccessor(h) 12345678910111213141516171819202122232425262728293031323334353637/** * Wakes up node's successor, if one exists. * 唤醒后继节点 如果有的话 * @param node the node 参数node是head头结点 */private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; // 如果head节点当前waitStatus&lt;0, 将其修改为0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 下面的代码就是唤醒后继节点，但是有可能后继节点取消了等待（waitStatus==1） Node s = node.next; //如果直接后继节点是null或者 waitStatus &gt; 0即取消了等待 //那么就直接从队尾往前找，找到waitStatus&lt;=0的所有节点中排在最前面的 if (s == null || s.waitStatus &gt; 0) &#123; s = null; // 从后往前找，不必担心中间有节点取消(waitStatus==1)的情况 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //如果直接后继节点不是空的就直接唤醒 if (s != null) // 唤醒线程 LockSupport.unpark(s.thread);&#125; 唤醒线程以后，被唤醒的线程将从以下代码中继续往前走： 12345private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); // 刚刚线程被挂起在这里了 return Thread.interrupted();&#125;// 又回到这个方法了：acquireQueued(final Node node, int arg)，这个时候，node的前驱是head了 4. 参考https://javadoop.com/post/AbstractQueuedSynchronizer#toc0 https://blog.csdn.net/chen77716/article/details/6641477 https://www.cnblogs.com/waterystone/p/4920797.html]]></content>
      <categories>
        <category>源码分析</category>
      </categories>
      <tags>
        <tag>源码分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL存储过程入门教程及实例详解]]></title>
    <url>%2Fposts%2F38c0d2ef.html</url>
    <content type="text"><![CDATA[存储过程是可编程的函数，在数据库中创建并保存，可以由SQL语句和控制结构组成。 本文主要介绍了MySQL的存储过程，通过语法教学及实例演示详细的叙述了MySQL存储过程的基本使用。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 存储过程简介存储过程是可编程的函数，在数据库中创建并保存，可以由SQL语句和控制结构组成。当想要在不同的应用程序或平台上执行相同的函数，或者封装特定功能时，存储过程是非常有用的。数据库中的存储过程可以看做是对编程中面向对象方法的模拟，它允许控制数据的访问方式。 SQL语句需要先编译然后执行，而存储过程（Stored Procedure）是一组为了完成特定功能的SQL语句集，经编译后存储在数据库中，用户通过指定存储过程的名字并给定参数（如果该存储过程带有参数）来调用执行它。 简单的说，就是一组SQL语句集，功能强大，可以实现一些比较复杂的逻辑功能，类似于JAVA语言中的方法； 存储过程跟触发器有点类似，都是一组SQL集，但是存储过程是主动调用的，且功能比触发器更加强大，触发器是某件事触发后自动调用； 2. 存储过程的优缺点2.1 优点 1.增强SQL语言的功能和灵活性：存储过程可以用控制语句编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。 2.标准组件式编程：存储过程被创建后，可以在程序中被多次调用，而不必重新编写该存储过程的SQL语句。而且数据库专业人员可以随时对存储过程进行修改，对应用程序源代码毫无影响。 3.较快的执行速度：如果某一操作包含大量的Transaction-SQL代码或分别被多次执行，那么存储过程要比批处理的执行速度快很多。因为存储过程是预编译的。在首次运行一个存储过程时查询，优化器对其进行分析优化，并且给出最终被存储在系统表中的执行计划。而批处理的Transaction-SQL语句在每次运行时都要进行编译和优化，速度相对要慢一些。 4.减少网络流量：针对同一个数据库对象的操作（如查询、修改），如果这一操作所涉及的Transaction-SQL语句被组织进存储过程，那么当在客户计算机上调用该存储过程时，网络中传送的只是该调用语句，从而大大减少网络流量并降低了网络负载。 5.作为一种安全机制来充分利用： 通过对执行某一存储过程的权限进行限制，能够实现对相应的数据的访问权限的限制，避免了非授权用户对数据的访问，保证了数据的安全。 2.2 缺点 1.可移植性差 2.对于很简单的sql语句， 存储过程没有优势 3.如果存储过程中不一定会减少网络传输（包含的sql数量并不多， 并且执行很快，就没必要了） 4.如果只有一个用户使用数据库， 那么存储过程对于安全也没什么影响 5.团队开发时需要先统一标准， 否则后期维护是个麻烦 6.在大并发量访问的情况下， 不宜写过多涉及运算的存储过程 7.业务逻辑复杂时， 特别是涉及到对很大的表进行操作的时候， 不如在前端先简化业务逻辑 3. 存储过程语法3.1 基本语法1CREATE PROCEDURE 过程名([[IN|OUT|INOUT] 参数名 数据类型[,[IN|OUT|INOUT] 参数名 数据类型…]]) [特性 ...] 过程体 例如： 123456789101112131415161718-- 存储过程-- 将语句的结束符号从分号;临时改为两个//(可以是自定义) 让编译器把两个"//"之间的内容当做存储过程的代码，不会执行这些代码DELIMITER // -- 创建存储过程 名称为 add_sumCREATE PROCEDURE add_sum(IN a INT,IN b INT,OUT c INT)-- 过程体开始BEGIN-- SET 赋值 SET c=a+b;-- 过程体结束END// -- 存储过程结束DELIMITER ; -- 将分隔符还原为分号 ；-- 调用存储过程SET @a=1;SET @b=2;CALL add_sum(@a,@b,@c);SELECT @c AS SUM; -- 输出为3 MySQL默认以”;”为分隔符，如果没有声明分隔符，则编译器会把存储过程当成SQL语句进行处理，因此编译过程会报错。 所以要事先用DELIMITER //声明当前的分隔符，可以自定义。让编译器把两个//之间的内容当做存储过程的代码，不会执行这些代码；结束后使用DELIMITER ;把分隔符还原。 MYSQL 存储过程中的关键语法 声明语句结束符，可以自定义: 123DELIMITER $$或DELIMITER // 声明存储过程: 1CREATE PROCEDURE demo_in_parameter(IN p_in int) 存储过程开始和结束符号: 1BEGIN .... END 变量赋值: 1SET @p_in=1 变量定义: 1DECLARE l_int int unsigned default 4000000; 创建mysql存储过程、存储函数: 1create procedure 存储过程名(参数) 存储过程体: 1create function 存储函数名(参数) 调用存储过程： 1call sp_name[(传参)]; 3.2 存储过程体过程体的开始与结束使用BEGIN与END进行标识。 ①如果过程没有参数，也必须在过程名后面写上小括号 例：CREATE PROCEDURE sp_name ([proc_parameter[,...]]) …… ②确保参数的名字不等于列的名字，否则在过程体中，参数名被当做列名来处理 存储过程体包含了在过程调用时必须执行的语句，例如：dml、ddl语句，if-then-else和while-do语句、声明变量的declare语句等 过程体格式：以begin开始，以end结束(可嵌套) 1234567BEGIN BEGIN BEGIN statements; END ENDEND 注意： 每个嵌套块及其中的每条语句，必须以分号结束，表示过程体结束的begin-end块(又叫做复合语句compound statement)，则不需要分号。 为语句块贴标签: 123[begin_label:] BEGIN [statement_list]END [end_label] 例如： 1234567label1: BEGIN label2: BEGIN label3: BEGIN statements; END label3 ; END label2;END label1 标签有两个作用： 1、增强代码的可读性 2、在某些语句(例如:leave和iterate语句)，需要用到标签 3.3 参数存储过程根据需要可能会有输入、输出、输入输出参数，如果有多个参数用”,”分割开。MySQL存储过程的参数用在存储过程的定义，共有三种参数类型,IN,OUT,INOUT: IN：参数的值必须在调用存储过程时指定，在存储过程中修改该参数的值不能被返回，为默认值 OUT: 该值可在存储过程内部被改变，并可返回 INOUT: 调用时指定，并且可被改变和返回 1.IN参数例子12345678910111213DELIMITER // CREATE PROCEDURE in_param(IN p_in int) BEGIN SELECT p_in; SET p_in=2; SELECT p_in; END; //DELIMITER ;-- 调用SET @p_in=1; -- 这里@p_in为1CALL in_param(@p_in); -- 这里 修改@p_in值为2SELECT @p_in; -- 查询@p_in值依旧为1 p_in 在存储过程中被修改，但并不影响 @p_id 的值，因为前者为局部变量、后者为全局变量。 12-- 此语句的意思就是根据where条件uid=1查询user表，得到的行数存入变量u_count中（给变量赋值）select count(*) into u_count from user where uid=1; 2.OUT参数例子123456789101112#存储过程DELIMITER // -- 将语句的结束符号从分号;临时改为两个//(可以是自定义) 让编译器把两个"//"之间的内容当做存储过程的代码，不会执行这些代码CREATE PROCEDURE out_param(OUT p_out INT)BEGINSELECT p_out ; SET p_out =999;END// -- 存储过程结束DELIMITER ; -- 将分隔符还原为分号 ；SET @p_out=111;CALL out_param(@p_out); -- 因为out是向调用者输出参数，不接收输入的参数，所以存储过程里的p_out为nullSELECT @p_out; -- 调用了out_param存储过程，输出参数，改变了p_out变量的值 3.INOUT输入参数12345678910111213-- 存储过程DELIMITER // -- 将语句的结束符号从分号;临时改为两个//(可以是自定义) 让编译器把两个"//"之间的内容当做存储过程的代码，不会执行这些代码CREATE PROCEDURE inout_param(INOUT p_inout INT)BEGIN SELECT p_inout ; SET p_inout =999; SELECT p_inout ;END// -- 存储过程结束DELIMITER ; -- 将分隔符还原为分号 ；SET @p_inout=111;CALL inout_param(@p_inout); -- 能接受输入的值 查询结果为111SELECT @p_inout; -- 存储过程修改了值 所以结果为999 注意： 1、如果过程没有参数，也必须在过程名后面写上小括号例： 1CREATE PROCEDURE sp_name ([proc_parameter[,...]]) …… 2、确保参数的名字不等于列的名字，否则在过程体中，参数名被当做列名来处理 建议： 输入值使用in参数。 返回值使用out参数。 inout参数就尽量的少用。 3.4 变量1变量定义局部变量声明一定要放在存储过程体的开始： 1DECLAREvariable_name [,variable_name...] datatype [DEFAULT value]; 其中，datatype 为 MySQL 的数据类型，如: int, float, date,varchar(length) 例如: 12345DECLARE l_int int unsigned default 4000000; DECLARE l_numeric number(8,2) DEFAULT 9.95; DECLARE l_date date DEFAULT '1999-12-31'; DECLARE l_datetime datetime DEFAULT '1999-12-31 23:59:59'; DECLARE l_varchar varchar(255) DEFAULT 'This will not be padded';` 2 变量赋值1SET 变量名 = 表达式值 [,variable_name = expression ...] 3 用户变量123SET @ValueName=value; SET @uid=123; 注意: 1、用户变量名一般以@开头 2、滥用用户变量会导致程序难以理解及管理 3.5 存储过程控制语句1. 变量作用域内部的变量在其作用域范围内享有更高的优先权，当执行到 end。变量时，内部变量消失，此时已经在其作用域外，变量不再可见了，应为在存储过程外再也不能找到这个申明的变量，但是你可以通过 out 参数或者将其值指派给会话变量来保存其值。 2.条件语句1.if-then-else 语句123456789101112131415161718DROP PROCEDURE IF EXISTS myif; -- 删除存储过程myif 如果存在DELIMITER //CREATE PROCEDURE myif(IN a INT)BEGINDECLARE msg VARCHAR(30);IF a = 0 THEN SET msg='a is 0';ELSEIF a = 1 THEN SET msg='a is 1';ELSE SET msg='a is others,not 0 or 1';END IF;SELECT msg;END//DELIMITER ;CALL myif(2); -- 调用 2.case语句：12345678910111213141516171819DROP PROCEDURE IF EXISTS mycase;DELIMITER //CREATE PROCEDURE mycase(IN a INT)BEGINDECLARE msg VARCHAR(30); -- 定义变量CASE aWHEN 0 THEN SET msg='a is 0';WHEN 1 THEN SET msg='a is 1';ELSE -- 相当于switch中的default SET msg='a is others,not 0 or 1';SELECT msg;END CASE;END //DELIMITER ;CALL mycase(1); -- 调用 3.循环语句1.while ···· end while123456789101112131415DROP PROCEDURE IF EXISTS mywhile;DELIMITER //CREATE PROCEDURE mywhile(IN a INT)BEGINDECLARE msg VARCHAR(30);WHILE a&gt;1 DOINSERT INTO user2 VALUES(NULL,a); -- 循环往表中插入数据SET a=a-1; -- 每次执行结束a减1END WHILE;END//DELIMITER ;DROP PROCEDURE mywhile;CALL mywhile(5); 123while 条件 do --循环体endwhile 2.repeat···· end repea它在执行操作后检查结果，而 while 则是执行前进行检查。 1234567891011121314DROP PROCEDURE IF EXISTS myrepeat;DELIMITER //CREATE PROCEDURE myrepeat(IN a INT)BEGINREPEAT INSERT INTO user2 VALUES(NULL,a); SET a=a-1; UNTIL a&lt;1 END REPEAT; END //DELIMITER ; CALL myrepeat(10); 1234repeat -- 循环体until 循环条件 end repeat; 3.loop ·····endloop– loop 与 leave,iterate 实现循环– loop 标志位无条件循环，leave 类似于break 语句，跳出循环，跳出 begin end，iterate 类似于continue ，结束本次循环 12345678910111213141516DROP PROCEDURE IF EXISTS myloop;DELIMITER //CREATE PROCEDURE myloop(IN a INT)BEGINloop_label: LOOPINSERT INTO user2 VALUES(NULL,a);SET a=a-1;IF a&lt;1 THEN LEAVE loop_label;END IF;END LOOP;END//DELIMITER ;CALL myloop(10); 4.LABLES 标号标号可以用在 begin repeat while 或者 loop 语句前，语句标号只能在合法的语句前面使用。可以跳出循环，使运行指令达到复合语句的最后一步。 ITERATE 通过引用复合语句的标号,来从新开始复合语句: 1234567891011121314151617181920DROP PROCEDURE IF EXISTS myiterate;DELIMITER //CREATE PROCEDURE myiterate(IN a INT)BEGINloop_label: LOOPIF a&lt;3 THEN SET a=a+1;ITERATE loop_label; -- 退出这次循环 继续下一次循环 类似于continueEND IF;INSERT INTO user2 VALUES(NULL,a);SET a=a+1;IF a&gt;=5 THEN LEAVE loop_label;END IF;END LOOP;END//DELIMITER ;CALL myiterate(1); 4. 存储过程操作语法4.1 存储过程查询查看某个数据库下面的存储过程 12345678-- 查询数据库中的存储过程SELECT * FROM mysql.proc WHERE db='数据库名'; -- MySQL存储过程和函数的信息存储在information_schema数据库下的Routines表中。通过查询该表的记录查询信息SELECT * FROM information_schema.routines WHERE routine_schema='数据库名';-- 这个语句是MySQL的扩展，它返回子程序的特征，如数据库、名字、类型、创建者及创建和修改日期。PROCEDURE和FUNCTION分别表示查看存储过程和函数SHOW PROCEDURE STATUS WHERE db='数据库名'; 查看详细的存储过程 1SHOW CREATE PROCEDURE 数据库.存储过程名; -- 它返回一个可用来重新创建已命名子程序的确切字符串 4.2 修改删除12345678910-- 修改ALTER &#123;PROCEDURE | FUNCTION&#125; proc_or_func [characterustic...]ALTER PROCEDURE 存储过程名字 ALTER PROCEDURE inout_param -- 删除DROP &#123;PROCEDURE | FUNCTION&#125; [IF EXISTS] proc_nameDROP PROCEDURE inout_param;DROP PROCEDURE IF EXISTS inout_param; 5. 参考http://www.runoob.com/w3cnote/mysql-stored-procedure.html https://www.2cto.com/database/201805/746743.html https://www.cnblogs.com/mark-chan/p/5384139.html]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几种常见排序算法的Java实现]]></title>
    <url>%2Fposts%2F82240bb6.html</url>
    <content type="text"><![CDATA[本文主要记录了几种常见的排序算法的Java实现，如冒泡排序、快速排序、直接插入排序、希尔排序、选择排序等等。在学数据结构与算法时的部分记录，感觉很难╮(╯▽╰)╭，还需继续努力。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 冒泡排序将序列中所有元素两两比较，将最大的放在最后面。 将剩余序列中所有元素两两比较，将最大的放在最后面。 重复第二步，直到只剩下一个数。 123456789101112131415161718/** * 冒泡排序：两两比较，大者交换位置,则每一轮循环结束后最大的数就会移动到最后. * 时间复杂度为O(n²) 空间复杂度为O(1) */private static void bubbleSort(int[] arr) &#123; //外层循环length-1次 for (int i = 0; i &lt; arr.length-1; i++) &#123; //外层每循环一次最后都会排好一个数 //所以内层循环length-1-i次 for (int j = 0; j &lt; arr.length - 1 - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125;&#125; 2. 快速排序快速排序（Quicksort）是对冒泡排序的一种改进，借用了分治的思想，由C. A. R. Hoare在1962年提出。它的基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列. 具体步骤 快速排序使用分治策略来把一个序列（list）分为两个子序列（sub-lists）。 ①. 从数列中挑出一个元素，称为”基准”（pivot）。 ②. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。 ③. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。 递归到最底部时，数列的大小是零或一，也就是已经排序好了。这个算法一定会结束，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。 123456789101112131415161718192021222324252627282930313233/** * 快速排序 * 时间复杂度为O(nlogn) 空间复杂度为O(1) */ public static void quickSort(int[] arr, int start, int end) &#123; if (start &lt; end) &#123; int baseNum = arr[start];//选基准值 int midNum;//记录中间值 int left = start;//左指针 int right = end;//右指针 while(left&lt;right)&#123; while ((arr[left] &lt; baseNum) &amp;&amp; left &lt; end) &#123; left++; &#125; while ((arr[right] &gt; baseNum) &amp;&amp; right &gt; start) &#123; right--; &#125; if (left &lt;= right) &#123; midNum = arr[left]; arr[left] = arr[right]; arr[right] = midNum; left++; right--; &#125; &#125; if (start &lt; right) &#123; quickSort(arr, start, right); &#125; if (end &gt; left) &#123; quickSort(arr, left, end); &#125; &#125; &#125; 3. 直接插入排序直接插入排序（Straight Insertion Sorting）的基本思想：将数组中的所有元素依次跟前面已经排好的元素相比较，如果选择的元素比已排序的元素小，则交换，直到全部元素都比较过为止。 首先设定插入次数，即循环次数，for(int i=1;i&lt;length;i++)，1个数的那次不用插入。 设定插入数和得到已经排好序列的最后一个数的位数。insertNum和j=i-1。 从最后一个数开始向前循环，如果插入数小于当前数，就将当前数向后移动一位。 将当前数放置到空着的位置，即j+1。 12345678910111213141516/** * 直接插入排序 * 时间复杂度O(n²) 空间复杂度O(1) */public static void straightInsertion(int[] arr) &#123; int current;//要插入的数 for (int i = 1; i &lt; arr.length; i++) &#123; //从1开始 第一次一个数不需要排序 current = arr[i]; int j = i - 1;//序列元素个数 while (j &gt;= 0 &amp;&amp; arr[j] &gt; current) &#123;//从后往前循环，将大于当前插入数的向后移动 arr[j + 1] = arr[j];//元素向后移动 j--; &#125; arr[j + 1] = current;//找到位置，插入当前元素 &#125;&#125; 4. 希尔排序是插入排序的一种高速而稳定的改进版本。 希尔排序是先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。 123456789101112131415161718192021/** * 希尔排序 * 时间复杂度O(n²) 空间复杂度O(1) */public static void shellSort(int[] arr) &#123; int gap = arr.length / 2; for (; gap &gt; 0; gap = gap / 2) &#123; //不断缩小gap，直到1为止 for (int j = 0; (j + gap) &lt; arr.length; j++) &#123; //使用当前gap进行组内插入排序 for (int k = 0; (k + gap) &lt; arr.length; k += gap) &#123; if (arr[k] &gt; arr[k + gap]) &#123; //交换操作 int temp = arr[k]; arr[k] = arr[k + gap]; arr[k + gap] = temp; &#125; &#125; &#125; &#125;&#125; 5. 选择排序遍历整个序列，将最小的数放在最前面。 遍历剩下的序列，将最小的数放在最前面。 重复第二步，直到只剩下一个数。 12345678910111213141516171819/** * 选择排序 * 时间复杂度O(n²) 空间复杂度O(1) */public static void selectSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; //循环次数 int min = arr[i];//等会用来放最小值 int index = i;//用来放最小值的索引 for (int j = i + 1; j &lt; arr.length; j++) &#123; //找到最小值 if (arr[j] &lt; min) &#123; min = arr[j]; index = j; &#125; &#125; //内层循环结束后进行交换 arr[index] = arr[i];//当前值放到最小值所在位置 arr[i] = min;//当前位置放最小值 &#125;&#125; 6. 堆排序对简单选择排序的优化。 将序列构建成大顶堆。 将根节点与最后一个节点交换，然后断开最后一个节点。 重复第一、二步，直到所有节点断开。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void heapSort(int[] a)&#123; int len=a.length; //循环建堆 for(int i=0;i&lt;len-1;i++)&#123; //建堆 buildMaxHeap(a,len-1-i); //交换堆顶和最后一个元素 swap(a,0,len-1-i); &#125; &#125; //交换方法 private void swap(int[] data, int i, int j) &#123; int tmp=data[i]; data[i]=data[j]; data[j]=tmp; &#125; //对data数组从0到lastIndex建大顶堆 private void buildMaxHeap(int[] data, int lastIndex) &#123; //从lastIndex处节点（最后一个节点）的父节点开始 for(int i=(lastIndex-1)/2;i&gt;=0;i--)&#123; //k保存正在判断的节点 int k=i; //如果当前k节点的子节点存在 while(k*2+1&lt;=lastIndex)&#123; //k节点的左子节点的索引 int biggerIndex=2*k+1; //如果biggerIndex小于lastIndex，即biggerIndex+1代表的k节点的右子节点存在 if(biggerIndex&lt;lastIndex)&#123; //若果右子节点的值较大 if(data[biggerIndex]&lt;data[biggerIndex+1])&#123; //biggerIndex总是记录较大子节点的索引 biggerIndex++; &#125; &#125; //如果k节点的值小于其较大的子节点的值 if(data[k]&lt;data[biggerIndex])&#123; //交换他们 swap(data,k,biggerIndex); //将biggerIndex赋予k，开始while循环的下一次循环，重新保证k节点的值大于其左右子节点的值 k=biggerIndex; &#125;else&#123; break; &#125; &#125; &#125; &#125; 7. 归并排序速度仅次于快速排序，内存少的时候使用，可以进行并行计算的时候使用。 选择相邻两个数组成一个有序序列。 选择相邻的两个有序序列组成一个有序序列。 重复第二步，直到全部组成一个有序序列。 1234567891011121314151617181920212223242526272829303132333435363738public void mergeSort(int[] a, int left, int right) &#123; int t = 1;// 每组元素个数 int size = right - left + 1; while (t &lt; size) &#123; int s = t;// 本次循环每组元素个数 t = 2 * s; int i = left; while (i + (t - 1) &lt; size) &#123; merge(a, i, i + (s - 1), i + (t - 1)); i += t; &#125; if (i + (s - 1) &lt; right) merge(a, i, i + (s - 1), right); &#125; &#125; private static void merge(int[] data, int p, int q, int r) &#123; int[] B = new int[data.length]; int s = p; int t = q + 1; int k = p; while (s &lt;= q &amp;&amp; t &lt;= r) &#123; if (data[s] &lt;= data[t]) &#123; B[k] = data[s]; s++; &#125; else &#123; B[k] = data[t]; t++; &#125; k++; &#125; if (s == q + 1) B[k++] = data[t++]; else B[k++] = data[s++]; for (int i = p; i &lt;= r; i++) data[i] = B[i]; &#125; 8. 基数排序用于大量数，很长的数进行排序时。 将所有的数的个位数取出，按照个位数进行排序，构成一个序列。 将新构成的所有的数的十位数取出，按照十位数进行排序，构成一个序列。 123456789101112131415161718192021222324252627282930313233343536373839404142public void baseSort(int[] a) &#123; //首先确定排序的趟数; int max = a[0]; for (int i = 1; i &lt; a.length; i++) &#123; if (a[i] &gt; max) &#123; max = a[i]; &#125; &#125; int time = 0; //判断位数; while (max &gt; 0) &#123; max /= 10; time++; &#125; //建立10个队列; List&lt;ArrayList&lt;Integer&gt;&gt; queue = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;(); queue.add(queue1); &#125; //进行time次分配和收集; for (int i = 0; i &lt; time; i++) &#123; //分配数组元素; for (int j = 0; j &lt; a.length; j++) &#123; //得到数字的第time+1位数; int x = a[j] % (int) Math.pow(10, i + 1) / (int) Math.pow(10, i); ArrayList&lt;Integer&gt; queue2 = queue.get(x); queue2.add(a[j]); queue.set(x, queue2); &#125; int count = 0;//元素计数器; //收集队列元素; for (int k = 0; k &lt; 10; k++) &#123; while (queue.get(k).size() &gt; 0) &#123; ArrayList&lt;Integer&gt; queue3 = queue.get(k); a[count] = queue3.get(0); queue3.remove(0); count++; &#125; &#125; &#125; &#125; 9. 总结 排序法 平均时间 最小时间 最大时间 稳定度 额外空间 备注 冒泡排序 O(n2) O(n) O(n2) 稳定 O(1) n小时较好 选择排序 O(n2) O(n2) O(n2) 不稳定 O(1) n小时较好 插入排序 O(n2) O(n) O(n2) 稳定 O(1) 大部分已排序时较好 基数排序 O(logRB) O(n) O(logRB) 稳定 O(n) B是真数(0-9)，R是基数(个十百) Shell排序 O(nlogn) - O(ns) 1&lt;s&lt;2 不稳定 O(1) s是所选分组 快速排序 O(nlogn) O(n2) O(n2) 不稳定 O(logn) n大时较好 归并排序 O(nlogn) O(nlogn) O(nlogn) 稳定 O(n) 要求稳定性时较好 堆排序 O(nlogn) O(nlogn) O(nlogn) 不稳定 O(1) n大时较好 参考https://www.cnblogs.com/shixiangwan/p/6724292.html]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java运行时数据区]]></title>
    <url>%2Fposts%2F9806100a.html</url>
    <content type="text"><![CDATA[本文主要讲的是Java运行时数据区，包括线程私有的程序计数器，虚拟机栈，本地方法栈和线程共享的堆，方法区等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 线程私有的：程序计数器 、虚拟机栈、本地方法栈 线程共享的： 堆、方法区 1.1 程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。 字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完。 另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 程序计数器主要有两个作用： 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程的情况下，程序计数器用于记录当前线程执行的位置，从而当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 注意：程序计数器是唯一一个不会出现OutOfMemoryError的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 1.2 虚拟机栈Java虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型。 Java 内存可以粗糙的区分为堆内存（Heap）和栈内存(Stack),其中栈就是现在说的虚拟机栈，或者说是虚拟机栈中局部变量表部分。 Java虚拟机栈是由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口。 每个方法在执行时都会创建一个栈帧,每一个方法从调用到执行完成的过程就是一个栈帧在虚拟机中的入栈到出栈的过程。 局部变量表存放了编译时期可知的各种基本类型（Boolean，byte，char,short,int.float.long,double）、对象引用（reference类型）和returnAddress（指向了一条字节码指令的地址）。局部变量表的创建是在方法被执行的时候,随着栈帧的创建而创建.而且,局部变量表的大小在编译时期就可以确定下来了,在创建的时候只需要分配实现规定好的大小即可.此外,在方法运行过程中局部变量表的大小是不会发生改变的。 操作数栈后进先出LIFO，最大深度由编译期确定。栈帧刚建立时，操作数栈为空，执行方法操作时，操作数栈用于存放JVM从局部变量表复制的常量或者变量，提供提取，及结果入栈，也用于存放调用方法需要的参数及接受方法返回的结果。操作数栈可以存放一个jvm中定义的任意数据类型的值。在任意时刻，操作数栈都一个固定的栈深度，基本类型除了long、double占用两个深度，其它占用一个深度. 动态链接每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用过程中的动态连接。Class文件的常量池中存在有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用，一部分会在类加载阶段或第一次使用的时候转化为直接引用（如final、static域等），称为静态解析，另一部分将在每一次的运行期间转化为直接引用，这部分称为动态连接。 方法返回地址当一个方法被执行后，有两种方式退出该方法：执行引擎遇到了任意一个方法返回的字节码指令或遇到了异常，并且该异常没有在方法体内得到处理。无论采用何种退出方式，在方法退出之后，都需要返回到方法被调用的位置，程序才能继续执行。方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。一般来说，方法正常退出时，调用者的PC计数器的值就可以作为返回地址，栈帧中很可能保存了这个计数器值，而方法异常退出时，返回地址是要通过异常处理器来确定的，栈帧中一般不会保存这部分信息。 方法退出的过程实际上等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，如果有返回值，则把它压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令。 Java 虚拟机栈会出现两种异常：StackOverFlowError 和 OutOfMemoryError。 StackOverFlowError： 若Java虚拟机栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前Java虚拟机栈的最大深度的时候，就抛出StackOverFlowError异常。 OutOfMemoryError： 若 Java 虚拟机栈的内存大小允许动态扩展，且当线程请求栈时内存用完了，无法再动态扩展了，此时抛出OutOfMemoryError异常。 Java 虚拟机栈也是线程私有的，每个线程都有各自的Java虚拟机栈，而且随着线程的创建而创建，随着线程的死亡而死亡。 1.3 本地方法栈和虚拟机栈所发挥的作用非常相似，区别是： 虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 StackOverFlowError 和 OutOfMemoryError 两种异常。 1.4 堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。Java虚拟机规范中说的是：所有的对象实例以及数组都要在堆上分配内存。但是随着JIT(just in time)编译器的发展与逃逸分析技术的成熟，栈上分配，标量替换优化技术将会导致一些微妙的变化，所有对象都分配在堆上也变得不是那么绝对了。 Java 堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）.从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代：再细致一点有：Eden空间、From Survivor空间、To Survivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。** 1.5 方法区方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非堆），目的应该是与 Java 堆区分开来。 HotSpot 虚拟机中方法区也常被称为 “永久代”，本质上两者并不等价。仅仅是因为 HotSpot 虚拟机设计团队用永久代来实现方法区而已，这样 HotSpot 虚拟机的垃圾收集器就可以像管理 Java 堆一样管理这部分内存了。但是这并不是一个好主意，因为这样更容易遇到内存溢出问题。 相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入方法区后就“永久存在”了。 1.6 常量池全局字符串池全局字符串池里的内容是在类加载完成，经过验证，准备阶段之后在堆中生成字符串对象实例，然后将该字符串对象实例的引用值存到string pool中（记住：string pool中存的是引用值而不是具体的实例对象，具体的实例对象是在堆中开辟的一块空间存放的。）。 在HotSpot VM里实现的string pool功能的是一个StringTable类，它是一个哈希表，里面存的是驻留字符串(也就是我们常说的用双引号括起来的)的引用（而不是驻留字符串实例本身），也就是说在堆中的某些字符串实例被这个StringTable引用之后就等同被赋予了”驻留字符串”的身份。这个StringTable在每个HotSpot VM的实例只有一份，被所有的类共享。 静态常量池也叫class文件常量池（class constant pool）,Class文件中除了有类的版本，字段，方法，接口等描述信息外还有一项信息是常量池,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池。 字面量就是我们所说的常量概念，如文本字符串、被声明为final的常量值等。 符号引用是一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可（它与直接引用区分一下，直接引用一般是指向方法区的本地指针，相对偏移量或是一个能间接定位到目标的句柄）。一般包括下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 运行时常量池运行时常量池是方法区的一部分。Class文件中除了有类的版本，字段，方法，接口等描述信息外还有一项信息是常量池,用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池。 既然运行时常量池时方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 JDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 JDK1.8后放在一个独立空间里面，叫做“元空间” jvm在执行某个类的时候，必须经过加载、连接、初始化，而连接又包括验证、准备、解析三个阶段。而当类加载到内存中后，jvm就会将class常量池中的内容存放到运行时常量池中，由此可知，运行时常量池也是每个类都有一个。在上面我也说了，class常量池中存的是字面量和符号引用，也就是说他们存的并不是对象的实例，而是对象的符号引用值。而经过解析（resolve）之后，也就是把符号引用替换为直接引用，解析的过程会去查询全局字符串池，也就是我们上面所说的StringTable，以保证运行时常量池所引用的字符串与全局字符串池中所引用的是一致的。 小结 1.全局常量池在每个VM中只有一份，存放的是字符串常量的引用值。 2.class常量池是在编译的时候每个class都有的，在编译阶段，存放的是常量的符号引用。 3.运行时常量池是在类加载完成之后，将每个class常量池中的符号引用值转存到运行时常量池中，也就是说，每个class都有一个运行时常量池，类在解析之后，将符号引用替换成直接引用，与全局常量池中的引用值保持一致。 1.7 直接内存直接内存并不是虚拟机运行时数据区的一部分，但是也频繁被用到，也可能导致OOM,虚拟机内存+直接内存超过物理内存时。 在JDK1.4出现的NIO类中引入了一个基于Channel和Buffer的IO方式，它可以直接使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作，能在一些场合中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 参考《深入理解Java虚拟机》 https://blog.csdn.net/qq_26222859/article/details/73135660]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下安装RabbitMQ]]></title>
    <url>%2Fposts%2Fb84a2c6c.html</url>
    <content type="text"><![CDATA[本章主要讲了如何通过解压方式在Linux下安装RabbitMQ和Erlang，超级详细的安装过程，和安装过程中遇到的一些问题。 更多文章欢迎访问我的个人博客–&gt;幻境云图 软件统一放在/usr/software下 解压后放在单独的文件夹下/usr/locac/opt/rabbitmq,/usr/local/opt/erlang RabbitMQ0. 环境准备1.版本问题Erlang和RabbitMQ版本必须对应才行，不然可能会出错。 官网信息如下 RabbitMQ Erlang Version Requirements Erlang/OTP versions older than 20.3 are not supported by RabbitMQ versions released in 2019. RabbitMQ versions prior to 3.7.7 do not support Erlang/OTP 21 or newer. RabbitMQ version3.7.7–3.7.10 需要的Erlang版本最低为20.3.X,最高为21.X RabbitMQ version Minimum required Erlang/OTP Maximum supported Erlang/OTP 3.7.7—3.7.10 20.3.X 21.X 3.7.0–3.7.6 19.3 20.3.X 具体信息在这里http://www.rabbitmq.com/which-erlang.html 这里选择的版本是 Erlang:21.2,RabbitMQ3.7.10,Linux:CentOS 7 2. 依赖下载安装rabbitmq需要下载以下依赖，这里可以提前下载上。 # yum -y install make gcc gcc-c++ kernel-devel m4 ncurses-devel openssl-devel # yum install xmlto -y 1. Erlang安装1.1 下载安装RabbitMQ之前需要先安装Erlang. 下载地址：http://www.erlang.org/downloads 文件otp_src_21.2.tar.gz 1.2 解压将压缩包上传到虚拟机中，我是放在/usr/software目录下的 # tar xvf otp_src_21.2.tar.gz 解压文件 复制一份到/usr/local/opt/erlang-software # cp otp_src_21.2 /usr/local/opt/erlang-software -r 创建erlang安装目录： /usr/local/opt/erlang 1.3 编译进入到/usr/local/opt/erlang-software目录下 # cd /usr/local/opt/erlang-software 配置安装路径编译代码：# ./configure --prefix=/usr/local/opt/erlang # make &amp;&amp; make install 执行编译 1.4 环境变量配置配置Erlang环境变量,# vi /etc/profile 添加以下内容 1export PATH=$PATH:/usr/local/opt/erlang/bin # source /etc/profile使得文件生效 1.5 验证验证erlang是否安装成功：# erl 进入如下界面就说明 配置好了 123456[root@localhost bin]# erlErlang/OTP 21 [erts-10.2] [source] [64-bit] [smp:1:1] [ds:1:1:10] [async-threads:1]Eshell V10.2 (abort with ^G)1&gt; ` 2. RabbitMQ安装2.1 下载官网：http://www.rabbitmq.com/releases/rabbitmq-server 这里下载3.7.10 :http://www.rabbitmq.com/install-generic-unix.html 文件：rabbitmq-server-generic-unix-3.7.10.tar.xz 2.2 解压文件是xz格式的，解压后得到tar格式文件。 # xz -d rabbitmq-server-generic-unix-3.7.10.tar.xz # tar -xvf rabbitmq-server-generic-unix-3.7.10.tar 复制到/usr/local/opt/rabbitmq目录下# cp -r rabbitmq_server-3.7.10/ /usr/local/opt/rabbitmq 2.3 环境变量配置配置rabbitmq环境变量,# vi /etc/profile 添加以下内容 export PATH=$PATH:/usr/local/opt/rabbitmq/sbin 环境变量生效：source /etc/profile 2.4 使用进入/usr/local/opt/rabbitmq/sbin目录 启动服务：# ./rabbitmq-server -detached 查看服务状态：# ./rabbitmqctl status 关闭服务：# ./rabbitmqctl stop 2.5 配置网页插件首先创建目录，否则可能报错：# mkdir /etc/rabbitmq 启用插件：# ./rabbitmq-plugins enable rabbitmq_management 启动mq：# ./rabbitmq-server -detached 配置linux 端口： 15672 网页管理， 5672 AMQP端口 然后访问http://192.168.5.154:15672/ 这里是需要登录了。 rabbitmq默认会创建guest账号，只能用于localhost登录页面管理员，需要自己创建账号。 2.6 添加账户查看mq用户：# rabbitmqctl list_users 查看用户权限：# rabbitmqctl list_user_permissions guest 新增用户： # rabbitmqctl add_user root root 用户名root,密码root 赋予管理员权限： rabbitmqctl set_user_tags root administrator rabbitmqctl set_permissions -p &quot;/&quot; root &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 3. 问题1.启动报错 1234567891011121314151617181920212223242526[root@localhost sbin]# ./rabbitmq-server startBOOT FAILED============INFO REPORT==== 21-Jan-2019::20:49:29.302765 ===Error description: noproc Log files (may contain more information): /usr/local/opt/rabbitmq/var/log/rabbitmq/rabbit@localhost.log /usr/local/opt/rabbitmq/var/log/rabbitmq/rabbit@localhost-sasl.logStack trace: [&#123;gen,do_for_proc,2,[&#123;file,"gen.erl"&#125;,&#123;line,228&#125;]&#125;, &#123;gen_event,rpc,2,[&#123;file,"gen_event.erl"&#125;,&#123;line,239&#125;]&#125;, &#123;rabbit,ensure_working_log_handlers,0, [&#123;file,"src/rabbit.erl"&#125;,&#123;line,856&#125;]&#125;, &#123;rabbit,'-boot/0-fun-0-',0,[&#123;file,"src/rabbit.erl"&#125;,&#123;line,288&#125;]&#125;, &#123;rabbit,start_it,1,[&#123;file,"src/rabbit.erl"&#125;,&#123;line,424&#125;]&#125;, &#123;init,start_em,1,[]&#125;, &#123;init,do_boot,3,[]&#125;]&#123;"init terminating in do_boot",noproc&#125;init terminating in do_boot (noproc)Crash dump is being written to: erl_crash.dump...done 这个问题网上查了一下，有的说是权限问题，也有说是erlang和rabbitmq版本对应不上，暂时没解决。 以解决，确实是版本问题，erlang版本和rabbitmq的版本对应不上，最前面单独写了这个关于版本的问题。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown语法与小技巧]]></title>
    <url>%2Fposts%2F9b0e40a3.html</url>
    <content type="text"><![CDATA[本文主要介绍了关于markdown的一些常用语法和技巧，让大家更好的写文章。自从17年前开始在 GitHub 玩耍，接触到 Markdown 之后，就感觉很有意思。不过也仅仅是了解一下基本语法，所以找了一下Markdown的语法用法来学习学习。 更多文章欢迎访问我的个人博客–&gt;幻境云图 如下： 注：如下技巧大多是利用 Markdown 兼容部分 HTML 标签的特性来完成，不一定在所有网站和软件里都完全支持，主要以 GitHub 支持为准。 标题123# This is an &lt;h1&gt; tag## This is an &lt;h2&gt; tag###### This is an &lt;h6&gt; tag 重点1234567*This text will be italic*_This will also be italic_**This text will be bold**__This will also be bold___You **can** combine them_ This text will be italicThis will also be italic This text will be boldThis will also be bold You can combine them 清单无序1234* Item 1* Item 2 * Item 2a * Item 2b Item 1 Item 2 Item 2a Item 2b 有序123451. Item 11. Item 21. Item 3 1. Item 3a 1. Item 3b Item 1 Item 2 Item 3 Item 3a Item 3b 图片12![GitHub Logo](/images/logo.png)Format: ![Alt Text](url) 链接12http://github.com - automatic![GitHub](http://github.com) http://github.com - automatic!GitHub 引用文字1234As Kanye West said:&gt; We&apos;re living the future so&gt; the present is our past. As Kanye West said: We’re living the future sothe present is our past. 内联代码12I think you should use an`&lt;addr&gt;` element here instead. I think you should use an&lt;addr&gt; element here instead. 删除线用两个波浪线（如~~this~~）包裹的任何单词都会显示为划掉。 这是被删除的内容 在表格单元格里换行借助于 HTML 里的 &lt;br /&gt; 实现。 示例代码： 123| Header1 | Header2 ||---------|----------------------------------|| item 1 | 1. one&lt;br /&gt;2. two&lt;br /&gt;3. three | 示例效果： Header1 Header2 item 1 1. one2. two3. three 引用 在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt; 这是引用的内容 这是引用的内容 分割线三个或者三个以上的 - 或者 * 都可以。 流程图123456789​```flowst=&gt;start: 开始op=&gt;operation: My Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op&amp; 12## 表格 左对齐标题 右对齐标题 居中对齐标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本 123456789&gt; //语法：&gt;&gt; 1）|、-、:之间的多余空格会被忽略，不影响布局。&gt; 2）默认标题栏居中对齐，内容居左对齐。&gt; 3）-:表示内容和标题栏居右对齐，:-表示内容和标题栏居左对齐，:-:表示内容和标题栏居中对齐。&gt; 4）内容和|之间的多余空格会被忽略，每行第一个|和最后一个|可以省略，-的数量至少有一个。表格在渲染之后很整洁好看，但是在文件源码里却可能是这样的： Header1 Header2 a a ab ab abc abc 1234不知道你能不能忍，反正我是不能忍。好在广大网友们的智慧是无穷的，在各种编辑器里为 Markdown 提供了表格格式化功能，比如我使用 Vim 编辑器，就有 [vim-table-mode](https://github.com/dhruvasagar/vim-table-mode) 插件，它能帮我自动将表格格式化成这样： Header1 Header2 a a ab ab abc abc 12345678910是不是看着舒服多了？如果你不使用 Vim，也没有关系，比如 Atom 编辑器的 [markdown-table-formatter](https://atom.io/packages/markdown-table-formatter) 插件，Sublime Text 3 的 [MarkdownTableFormatter](https://github.com/bitwiser73/MarkdownTableFormatter) 等等，都提供了类似的解决方案。## 使用 Emoji这个是 GitHub 对标准 Markdown 标记之外的扩展了，用得好能让文字生动一些。示例代码： 我和我的小伙伴们都笑了。:smile:123456789101112示例效果：我和我的小伙伴们都笑了。:smile:[Github支持的表情在这里哟](https://github.com/ikatyang/emoji-cheat-sheet/blob/master/README.md)## 行首缩进直接在 Markdown 里用空格和 Tab 键缩进在渲染后会被忽略掉，需要借助 HTML 转义字符在行首添加空格来实现，`&amp;ensp;` 代表半角空格，`&amp;emsp;` 代表全角空格。示例代码： &emsp;&emsp;春天来了，又到了万物复苏的季节。123456789101112131415161718示例效果：&amp;emsp;&amp;emsp;春天来了，又到了万物复苏的季节。## 展示数学公式如果是在 GitHub Pages，可以参考 &lt;http://wanguolin.github.io/mathmatics_rending/&gt; 使用 MathJax 来优雅地展示数学公式（非图片）。如果是在 GitHub 项目的 README 等地方，目前我能找到的方案只能是贴图了，以下是一种比较方便的贴图方案：1. 在 &lt;https://www.codecogs.com/latex/eqneditor.php&gt; 网页上部的输入框里输入 LaTeX 公式，比如 `$$x=\frac&#123;-b\pm\sqrt&#123;b^2-4ac&#125;&#125;&#123;2a&#125;$$`；2. 在网页下部拷贝 URL Encoded 的内容，比如以上公式生成的是 `https://latex.codecogs.com/png.latex?%24%24x%3D%5Cfrac%7B-b%5Cpm%5Csqrt%7Bb%5E2-4ac%7D%7D%7B2a%7D%24%24`； ![](D:\lillusory\MyProject\lillusory.github.io\images\posts\Markdown\Markdown_latex_img)3. 在文档需要的地方使用以上 URL 贴图，比如 12345678910 示例效果： ![](https://latex.codecogs.com/png.latex?%24%24x%3D%5Cfrac%7B-b%5Cpm%5Csqrt%7Bb%5E2-4ac%7D%7D%7B2a%7D%24%24)## 任务列表在 GitHub 和 GitLab 等网站，除了可以使用有序列表和无序列表外，还可以使用任务列表，很适合要列出一些清单的场景。示例代码： 购物清单 一次性水杯 西瓜 豆浆 可口可乐 小茗同学` 示例效果： 购物清单 一次性水杯 西瓜 豆浆 可口可乐 小茗同学 自动维护目录有时候维护一份比较长的文档，希望能够自动根据文档中的标题生成目录（Table of Contents），并且当标题有变化时自动更新目录，能减轻工作量，也不易出错。比如 Atom 编辑器的 markdown-toc 插件，Sublime Text 的 MarkdownTOC 插件等。 后话希望自己，也希望大家在了解这些之后能有所收获，更好地排版，专注写作。 参考 https://raw.githubusercontent.com/matiassingers/awesome-readme/master/readme.md https://www.zybuluo.com/songpfei/note/247346 支持的表情]]></content>
      <categories>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux安装MySQL教程]]></title>
    <url>%2Fposts%2F1be8c408.html</url>
    <content type="text"><![CDATA[本章主要讲了如何通过解压方式在Linux下安装MySQL，以及如何设置让我们可以远程连接到服务器上的mysql. 更多文章欢迎访问我的个人博客–&gt;幻境云图 软件统一放在/usr/software下 解压后放在单独的文件夹下/usr/local/java//usr/local/mysql 其中：#为Linux命令，mysql则是mysql下的命令 软件统一放在/usr/software下 解压后放在单独的文件夹下/usr/local/java//usr/local/mysql 安装包下载mysql-5.7.24-linux-glibc2.12-x86_64.tar 网址https://dev.mysql.com/downloads/mysql/5.7.html#downloads 1. 安装依赖1# yum install -y cmake make gcc gcc-c++ libaio ncurses ncurses-devel 2. 解压文件压缩包上传到虚拟机/usr/software目录下,进入这个目录 解压文件 1# tar zxvf mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz 将解压后的文件移动到/usr/local/mysql 1# mv mysql-5.7.24-linux-glibc2.12-x86_64 /usr/local/mysql 3. 添加用户和赋权1.添加用户和用户组 给mysql赋权的用户必须对当前目录具有读写权限，但是一般不用root账户，所以创建一个用户mysql。 执行命令：创建用户组mysqlgroupadd mysql` 创建用户也叫mysql 12// 命令中第一个mysql是用户，第二个mysql是用户组。# useradd -r -g mysql mysql 2.给用户赋权限 一定保证当前是在/usr/local/mysql 目录下 给用户组赋权限 12//mysql是用户组名# chgrp -R mysql. 给用户赋权限 12//这个mysql是用户名# chown -R mysql. 4. 数据库初始化安装数据库 : 12// 这里会生成临时密码，后边有用# bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data 执行以下命令创建RSA private key ： 1# bin/mysql_ssl_rsa_setup --datadir=/usr/local/mysql/data 5. 配置my.cnf1# vim /etc/my.cnf 内容如下： 12345678910[mysqld]character_set_server=utf8init_connect='SET NAMES utf8'basedir=/usr/local/mysqldatadir=/usr/local/mysql/datasocket=/tmp/mysql.sock#不区分大小写 (sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES 这个简单来说就是sql语句是否严格)lower_case_table_names = 1log-error=/var/log/mysqld.logpid-file=/usr/local/mysql/data/mysqld.pid 12# cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld# vim /etc/init.d/mysqld 添加以下内容，在46行 12basedir=/usr/local/mysqldatadir=/usr/local/mysql/data 6. 修改密码启动mysql 1# service mysqld start 加入开机起动 1# chkconfig --add mysqld 进入客户端 登录修改密码 1# mysql -uroot -p 上面初始化时的密码 如果出现错误 需要添加软连接 1# ln -s /usr/local/mysql/bin/mysql /usr/bin 如果出现Access denied for user &#39;root&#39;@&#39;localhost&#39; (using password: YES)应该是密码错了，直接强行修改密码好了。先停掉mysql. 1# service mysql stop 然后修改配置文件 1# vim /etc/my.cnf 在[mysqld]后面任意一行添加skip-grant-tables用来跳过密码验证的过程 接下来我们需要重启MySQL 1# /etc/init.d/mysqld restart 重启之后输入命令mysql即可进入mysql了，然后开始修改密码。 12345mysql&gt; use mysql;# 这里修改密码的命令在5.7以上和5.7以下是不同的 需要注意mysql&gt; update user set authentication_string=passworD(&quot;你的密码&quot;) where user=&apos;root&apos;;flush privileges;mysql&gt; quit 完成后可以把配置文件中的跳过密码验证去掉。 然后就可以正常使用啦。 7. 外部访问首先进入mysql， 1# mysql -u root -p 接着创建远程连接 MySQL 的用户 mysql命令 1234-- 创建用户、密码及权限范围 第一个 roo t为用户名 @后为适用的主机，‘%’表示所有电脑都可以访问连接，第二个 root 为密码mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;192.168.1.3&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION; -- 立即生效mysql&gt; flush privileges; 查看数据库用户： 1234567-- 使用 mysql 库mysql&gt; use mysql;-- 查看用户mysql&gt; SELECT DISTINCT CONCAT(&apos;User: [&apos;, user, &apos;&apos;&apos;@&apos;&apos;&apos;, host, &apos;];&apos;) AS USER_HOST FROM user; -- 查看端口mysql&gt; show global variables like &apos;port&apos;;--mysql 默认端口为3306 解决防火墙问题 防火墙默认只开放了22端口，要访问数据库要么关掉防火墙要么修改配置文件，开放3306端口 修改防火墙配置： 命令 1# vim /etc/sysconfig/iptables 添加以下内容 1-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 然后重启防火墙 1# service iptables restart 最后查看服务器IP 1# ip a 到这里应该就可以通过IP和端口号远程连接服务器上的MySQL了。 8. 问题mysql中执行命令出现以下错误： 1ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement. 解决： 修改用户密码 1mysql&gt; alter user &apos;root&apos;@&apos;localhost&apos; identified by &apos;你的密码&apos;; 参考https://blog.csdn.net/z13615480737/article/details/80019881 https://www.cnblogs.com/goodcheap/p/7103049.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下安装jdk和Tomcat]]></title>
    <url>%2Fposts%2F54978294.html</url>
    <content type="text"><![CDATA[本章主要讲了如何通过解压方式在Linux下安装JDK和Tomcat等软件。 更多文章欢迎访问我的个人博客–&gt;幻境云图 软件统一放在/usr/software下 解压后放在单独的文件夹下/usr/local/java//usr/local/mysql 1.JDK安装包下载jdk-8u191-linux-x64.tar.gz 注意32位和64位的别下载错了。 命令uname -a 查看Linux系统位数。 网址：https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html 1.首先将压缩包传到虚拟机。放在/usr/software下 2.然后解压文件tar zxvf jdk-8u191-linux-x64.tar.gz 按tab会自动补全。 3.将解压得到的文件移动到/usr/local/java,命令`mv jdk1.8.0_191/ /usr/local/jdk8 4.配置环境变量 命令vim /etc/profile 添加以下内容 123 export JAVA_HOME=/usr/local/jdk8/ export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 5.解析该文件 命令source /etc/profile 6.测试 命令 java -version 输出版本信息就说明配好了。 2.Tomcat安装包下载apache-tomcat-8.5.37.tar.gz 网址https://tomcat.apache.org/download-80.cgi 1.压缩包上传到虚拟机/usr/software目录下 2.解压文件 tar zxvf apache-tomcat-8.5.37.tar.gz 3.将解压后的文件移动到/usr/local/tomcat,命令mv apache-tomcat-8.5.37 /usr/local/tomcat 4.配置环境变量 命令vim /etc/profile 添加以下内容 12export TOMCAT_HOME=/usr/local/tomcatexport CATANILA_HOME=/usr/local/tomcat 5.解析该文件 命令source /etc/profile]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的网络配置]]></title>
    <url>%2Fposts%2Fb0d13a6d.html</url>
    <content type="text"><![CDATA[本章主要讲了linux如何配置网络，让虚拟机能够连上外网，如何让虚拟机和主机联通，同时介绍了ssh客户端工具连接虚拟机。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Xshell在安装好虚拟机后就可以正常使用了。但是在正常工作中不可能真的在服务器上操作，一般都是通过ssh客户端工具连接服务器进行操作。 这里用到的客户端工具是Xshell,通过该工具连上服务器后就可以在自己的电脑上操作了。而且还可以开多个窗口，比较方便。 这里新建连接时需要输入要连接的服务器的IP和端口号，账户和密码，端口号默认是22，一般不用改。 2. 网络配置2.1 桥接模式和NAT模式按照上面的方法就可以连上虚拟机了，但是现在虚拟机的IP是自动获取的，每次重启后都IP都会变，这肯定不行呀，所以我们需要为虚拟机设置静态IP. 由于我们这里使用的是NAT模式。这个模式下虚拟机可以上网，但是无法和主机联通。 桥接模式和NAT模式的区别： 桥接模式下虚拟机可以看做一台真正的独立的电脑，所以桥接模式下需要为虚拟机分配独立的IP，在家里到时无所谓，在公司的话由于IP和电脑绑定的，所以需要网络管理人员给你的虚拟机分配一个IP才行。 NAT模式下，虚拟机会动态获取IP,虽然有自己的IP但是最终上网还是通过主机上网的。所以NAT模式下不用分配独立的IP,但是NAT模式下主机和虚拟机无法联通。 为了主机和虚拟机联通，我们必须让主机和虚拟机在同一个网段下。 为了主机和虚拟机联通，我们必须让主机和虚拟机在同一个网段下。 为了主机和虚拟机联通，我们必须让主机和虚拟机在同一个网段下。 2.2 设置静态IP在设置静态IP前我们需要知道主机的IP. windows下命令行输入 ipconfig 即可获取到本机IP. 然后通过VMware软件对网络进行配置。 接着在虚拟机中配置具体网络信息。 2.3 网络配置2.3.1 网卡配置网络配置文件在/etc/sysconfig/network-scripts/ifcfg-ens33目录下，一般是叫ifcfg-ens33 编辑配置文件 命令：vi /etc/sysconfig/network-scripts/ifcfg-ens33 配置如下 ： 其中ip地址必须和主机在同一网段下，网关就是上边的那个网关。DNS可填可不填。 1234567BOOTPROTO="static" # 手动分配ipONBOOT="yes" # 该网卡是否随网络服务启动IPADDR="192.168.1.111" # 该网卡ip地址就是你要配置的固定IPGATEWAY="192.168.1.2" # 网关NETMASK="255.255.255.0" # 子网掩码 固定值DNS1="8.8.8.8" # DNS，8.8.8.8为Google提供的免费DNS服务器的IP地址DNS2="192.168.1.2" 2.3.2 网络配置命令：vi /etc/sysconfig/network 添加以下内容 1234NETWORKING=yes # 网络是否工作，此处一定不能为noNETWORKING_IPV6=noHOSTNAME=localhost.localdomainGATEWAY=192.168.1.2 2.3.3 配置公共DNS服务vi /etc/resolv.conf 123search localdomainnameserver 8.8.8.8nameserver 192.168.1.2 2.3.4 关闭防火墙12systemctl stop firewalld # 临时关闭防火墙systemctl disable firewalld # 禁止开机启动 2.3.5 重启网络服务service network restart 到此为止网络配置就完成了，现在虚拟机的IP重启后不会变了，也可以连上外网了，还可以和主机联通了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超详细的VMware虚拟机安装CentOS7教程]]></title>
    <url>%2Fposts%2F4d7cca6f.html</url>
    <content type="text"><![CDATA[这是一个十分详细的CentOS7的安装教程，对自己的安装过程做了一个记录。主要记录了如何通过VMware虚拟机安装Linux，从软件下载到虚拟机安装等等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 准备工作1.1 VMware下载百度网盘下载（内含注册机） 链接: https://pan.baidu.com/s/1wz4hdNQBikTvyUMNokSVYg提取码: yed7 怎么安装就不用写了吧。 1.2 CentOS下载http://mirrors.163.com/centos/7.6.1810/isos/x86_64/ 2. CentOS 7安装 创建虚拟机，这里我们选择自定义安装类型。 然后选择版本，需要注意兼容问题，一般是向下兼容，14上的虚拟机复制到15上可以用，15的复制到14上可能会用不了。 这里选择稍后再安装。 接着选择系统，这里是CentOS 7 64位。 这个是保存的文件名字。 这里一般默认的就行了,电脑配置好的可以调高点。 网络这里,如果仅仅是让虚拟机能上网，两种模式都可以的，用桥接的话只要你在局域网内有合法的地址，比如你的ADSL猫是带路由功能的，如果是在单位，那就要网络管理人员给你合法IP才行。NAT模式下，虚拟机从属于主机，也就是访问外部网络必须通过主机来访问，因此虚拟机的IP只有主机才能识别。而桥接模式下，虚拟机和主机是平行关系，共享一张网卡（使用网卡的多个接口），可以直接访问外部网络。 这些都默认的就行了。 这个是虚拟机文件的名字。 这里选择自定义硬件。 选择镜像文件。 到这里就结束了，点击开启虚拟机后会自动开始安装。 选择安装CentOS 7 语言选择 调一下时间和地区。 选择要安装的软件，新手还是安装一个GUI比较好。 查看一下网络连接 开始安装。 安装过程中可以设置一下账号密码，一个root账户，一个普通账户。 然后耐心等待安装完成就好了。 安装完成后重启就可以登录系统了。 3. 快照快照相当于windows中的还原点。在安装好后可以拍摄一张快照，方便恢复或者克隆虚拟机。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客优化之（五）--压缩篇]]></title>
    <url>%2Fposts%2F70deabab.html</url>
    <content type="text"><![CDATA[本章主要记录了如何通过gulp工具压缩压缩博客静态文件以加快网站加载速度。 这是一个基于Hexo的个人博客的教程，包含了从博客搭建到主题优化，最后部署到云端的全过程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 在本系列文章的第二章中也有类似静态资源压缩的教程，是用的hexo-neat插件，最近用着用着出现了一点点问题，无奈之下换用了gulp。这个工具也可以很方便的压缩静态资源。 1. 插件安装首先需要安装gulp工具 命令：npm install gulp 接着安装功能模块，包括 1234gulp-htmlclean // 清理htmlgulp-htmlmin // 压缩htmlgulp-minify-css // 压缩cssgulp-uglify // 混淆js 命令：npm install gulp-htmlclean gulp-htmlmin gulp-minify-css gulp-uglify --save 2. 创建任务在站点根目录下，新建gulpfile.js文件，文件内容如下: 123456789101112131415161718192021222324252627282930313233343536373839404142var gulp = require('gulp');//Plugins模块获取var minifycss = require('gulp-minify-css');var uglify = require('gulp-uglify');var htmlmin = require('gulp-htmlmin');var htmlclean = require('gulp-htmlclean');//压缩cssgulp.task('minify-css', function () &#123;return gulp.src('./public/**/*.css').pipe(minifycss()).pipe(gulp.dest('./public'));&#125;);//压缩htmlgulp.task('minify-html', function () &#123;return gulp.src('./public/**/*.html').pipe(htmlclean()).pipe(htmlmin(&#123;removeComments: true,minifyJS: true,minifyCSS: true,minifyURLs: true,&#125;)).pipe(gulp.dest('./public'))&#125;);//压缩js 不压缩min.jsgulp.task('minify-js', function () &#123;return gulp.src(['./public/**/*.js', '!./public/**/*.min.js']).pipe(uglify()).pipe(gulp.dest('./public'));&#125;);//4.0以前的写法 //gulp.task('default', [ // 'minify-html', 'minify-css', 'minify-js'//]);//4.0以后的写法// 执行 gulp 命令时执行的任务gulp.task('default', gulp.parallel('minify-html', 'minify-css', 'minify-js', function() &#123; // Do something after a, b, and c are finished.&#125;)); 3. 使用使用时按照以下顺序就可以了： 1234hexo clean //先清理文件hexo g //编译生成静态文件gulp //gulp插件执行压缩任务hexo s //开启服务 4. 问题刚开始弄这个的时候也是各种百度，Google，大部分的文章也是这么写的但是，第二部的js 代码却都有问题，也不能说有问题吧，大部分都是4.0以前的写法，导致现在gulp更新到4.0之后全都无法使用了。可能在看到这篇文章之前也试了各种办法。然后每次都出现这样的问题： 12345678assert.js:85 throw new assert.AssertionError(&#123; ^AssertionError: Task function must be specified at Gulp.set [as _setTask] (/home/hope/web/node_modules/undertaker/lib/set-task.js:10:3) at Gulp.task (/home/hope/web/node_modules/undertaker/lib/task.js:13:8)................. 在看了下gulp相关资料后才发现了问题，接着把js代码稍微改了改终于能用了。不过运行的时候好像也有点问题，不过不影响使用，对这些工具还是不太了解。 123[21:35:20] The following tasks did not complete: default, &lt;anonymous&gt;[21:35:20] Did you forget to signal async completion?//代码里也没这个任务呀]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synchronize和Volatile底层实现原理]]></title>
    <url>%2Fposts%2Fcf1a701a.html</url>
    <content type="text"><![CDATA[最近在看并发编程的艺术这本书，希望加深对并发这块的理解。毕竟并发相关还是十分重要的。本文主要是关于第二章Java并发机制的底层实现原理的相关笔记。主要包括volatile,synchronized,原子操作等实现原理的分析。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 上下文切换多线程 即使是单核处理器也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。 什么是上下文切换 CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。 所以任务从保存到再加载的过程就是一次上下文切换。 上下文切换也会影响多线程的执行速度 因为线程有创建和上下文切换的开销，所以有时候并发不一定比串行快。 减少上下文切换的办法 减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 2. volatile关键字如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。 有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，其中就包括了Lock前缀.Lock前缀的指令在多核处理器下会引发了两件事情。 1）将当前处理器缓存行的数据写回到系统内存。 Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存。 如果访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。相反，它会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。 2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。 处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。 3. synchronized原理与应用Java SE 1.6中为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁，以及锁的存储结构和升级过程。 Java中的每一个对象都可以作为锁。具体表现为以下3种形式。 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。 3.1 底层实现JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。 代码块同步是使用monitorenter和monitorexit指令实现的. 而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。 monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。 3.2 Java对象头synchronized用的锁是存在Java对象头里的。 java的对象头由以下三部分组成： 1，Mark Word 2，指向类的指针 3，数组长度（只有数组对象才有） 3.3 锁的升级与对比Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。 偏向锁 HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。 当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 偏向锁解除 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程. 轻量级锁 （1）轻量级锁加锁线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。（2）轻量级锁解锁轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。 优缺点比较 4. 原子操作的实现原理原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。 4.1 处理器如何实现原子操作处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 第一个机制是通过总线锁保证原子性。 所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。 第二个机制是通过缓存锁定来保证原子性。 总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效. 4.2 Java如何实现原子操作使用循环CAS实现原子操作 JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到成功为止。 CAS实现原子操作的三大问题 1.ABA问题 但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。 ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1。 2.循环时间长开销大 自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。 3.只能保证一个共享变量的原子操作 操作多个共享变量时无法使用CAS操作，这个时候就可以用锁。还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。 使用锁机制实现原子操作 锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当它退出同步块的时候使用循环CAS释放锁。 参考本文内容来自Java并发编程的艺术]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客之（四）--管理篇]]></title>
    <url>%2Fposts%2F33469.html</url>
    <content type="text"><![CDATA[本章主要记录了如何通过使用Github的分支功能解决更换电脑后博客更新不方便的问题，让你的博客能在各个电脑上灵活切换。在也不用担心换电脑后博客配置丢失等问题了。 这是一个基于Hexo的个人博客的教程，包含了从博客搭建到主题优化，最后部署到云端的全过程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 到此为止，我们已经完成了差不多所有的步骤。 1.搭建博客 2.优化主题 3.部署收录 新问题： ​ 现在博客只能在自己的电脑上更新，如果换电脑了就很麻烦。配置文件主题什么的都要重新弄。所以网上找了找多台电脑同时操作的办法，我们可以利用Github的分支功能。 ​ 将博客文件夹下所有文件全push到Github。这样换电脑后直接pull就可以了。 1. 新建分支 1.在Github的lillusory.github.io（hexo仓库）上新建一个分支，例如Hexo，并切换到该分支. 2.并在该仓库Settings-&gt;Branches-&gt;Default branch中将默认分支设为Hexo.Hexo分支是博客的开发环境，用来写博客，保存原始文件,master分支用于显示，保存生产的静态文件。 3.新建分支后将博客目录下的所有文件上传到该分支，注意由于一个git仓库中不能包含其他仓库，所以需要删除掉主题文件夹中的.git目录。 4.如果按照前面的博文添加了背景，则需要删掉站点目录\themes\next\source\lib\canvas-nest文件夹中的.git目录。以后需要更新主题时，可以先克隆到本地在复制到相应目录. 2. 写博客在本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理。 依次执行git add .、git commit -m &quot;这里写备注&quot;、git push origin 这里写分支名字指令将改动推送到GitHub（此时当前分支应为hexo）。 然后才执行hexo g -d发布网站到master分支上。 3. 博客迁移当重装电脑之后，或者想在其他电脑上修改博客，可以使用下列步骤： 克隆仓库 使用git clone git@github.com:illusorycloud/illusorycloud.github.io.git拷贝仓库（默认分支为hexo）；//修改成自己的 安装插件 在前面克隆下的项目中安装插件 执行命令npm install hexo、npm install、npm install hexo-deployer-git 4. 参考如何在多台电脑上更新博客]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android平台自动发送邮件demo]]></title>
    <url>%2Fposts%2F9a79dc9b.html</url>
    <content type="text"><![CDATA[一个Android平台自动发送邮件的小demo，记录了一下实现的过程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 导包使用邮件发送功能,需要导入3个jar包. 123456789101112additional.jarmail.jaractivation.jar//用的是AndroidStudio //1.切换到Project视图 //2.将这3个jar包放到app下的lib文件夹中 //3.选择这个三个jar包右键 Add As Library //4.如果导入成功 在Module 的build.gradle中就能看到这个 和平常引入第三方库一样 implementation files('libs/activation.jar') implementation files('libs/additionnal.jar') implementation files('libs/mail.jar') 2. 创建Helper工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209package lillusory.com.androidemail;import android.os.AsyncTask;import android.util.Log;import java.util.Date;import java.util.List;import java.util.Properties;import javax.activation.CommandMap;import javax.activation.MailcapCommandMap;import javax.mail.Authenticator;import javax.mail.Message;import javax.mail.Multipart;import javax.mail.PasswordAuthentication;import javax.mail.Session;import javax.mail.Transport;import javax.mail.internet.InternetAddress;import javax.mail.internet.MimeBodyPart;import javax.mail.internet.MimeMessage;import javax.mail.internet.MimeMultipart;public class MyEmailHelper &#123; private static final String TAG = MyEmailHelper.class.getSimpleName(); private int port = 25; //smtp协议使用的端口 private String host = "smtp.163.com"; // 发件人邮件服务器 //TODO 需要改成自己的账号和授权密码 private String user = "xxx@163.com"; // 使用者账号 private String password = "xxx"; //使用者SMTP授权密码 private List&lt;String&gt; emailTos; private List&lt;String&gt; emailCCs; private String title; private String context; private List&lt;String&gt; paths; public enum SendStatus &#123; SENDING, UNDO, SENDOK, SENDFAIL, BADCONTEXT &#125; private SendStatus sendStatus; public interface EmailInfterface &#123; void startSend(); void SendStatus(SendStatus sendStatus); &#125; private EmailInfterface EmailInfterface; public void setJieEmailInfterface(EmailInfterface EmailInfterface) &#123; this.EmailInfterface = EmailInfterface; &#125; public MyEmailHelper() &#123; sendStatus = SendStatus.UNDO; &#125; //构造发送邮件帐户的服务器，端口，帐户，密码 public MyEmailHelper(String host, int port, String user, String password) &#123; this.port = port; this.user = user; this.password = password; this.host = host; sendStatus = SendStatus.UNDO; &#125; /** * @param emailTos 主要接收人的电子邮箱列表 * @param emailCCs 抄送人的电子邮箱列表 * @param title 邮件标题 * @param context 正文内容 * @param paths 发送的附件路径集合 */ public void setParams(List&lt;String&gt; emailTos, List&lt;String&gt; emailCCs, String title, String context, List&lt;String&gt; paths) &#123; this.emailTos = emailTos; this.emailCCs = emailCCs; this.title = title; this.context = context; this.paths = paths; &#125; public void sendEmail() &#123; new MyAsynTask().execute(); &#125; private void sendEmailBg() throws Exception &#123; Properties properties = new Properties(); properties.put("mail.smtp.host", host); properties.put("mail.smtp.port", port); properties.put("mail.smtp.auth", "true");//true一定要加引号 properties.put("mail.transport.protocol", "smtp"); MyAuthenticator jieAuth = new MyAuthenticator(user, password); Session session = Session.getInstance(properties, jieAuth); //创建一个消息 MimeMessage msg = new MimeMessage(session); //设置发送人 msg.setFrom(new InternetAddress(user)); //设置主要接收人 if (emailTos != null &amp;&amp; !emailTos.isEmpty()) &#123; int size = emailTos.size(); InternetAddress[] addresses = new InternetAddress[size]; for (int i = 0; i &lt; size; i++) &#123; addresses[i] = new InternetAddress(emailTos.get(i)); &#125; msg.setRecipients(Message.RecipientType.TO, addresses); &#125; //设置抄送人的电子邮件 if (emailCCs != null &amp;&amp; !emailCCs.isEmpty()) &#123; int size = emailCCs.size(); InternetAddress[] addresses = new InternetAddress[size]; for (int i = 0; i &lt; size; i++) &#123; addresses[i] = new InternetAddress(emailCCs.get(i)); &#125; msg.setRecipients(Message.RecipientType.CC, addresses); &#125; msg.setSubject(title); //创建一个消息体 MimeBodyPart msgBodyPart = new MimeBodyPart(); msgBodyPart.setText(context); //创建Multipart增加其他的parts Multipart mp = new MimeMultipart(); mp.addBodyPart(msgBodyPart); //创建文件附件 if (paths != null) &#123; for (String path : paths) &#123; MimeBodyPart fileBodyPart = new MimeBodyPart(); fileBodyPart.attachFile(path); mp.addBodyPart(fileBodyPart); &#125; &#125; //增加Multipart到消息体中 msg.setContent(mp); //设置日期 msg.setSentDate(new Date()); //设置附件格式 MailcapCommandMap mc = (MailcapCommandMap) CommandMap.getDefaultCommandMap(); mc.addMailcap("text/html;; x-java-content-handler=com.sun.mail.handlers.text_html"); mc.addMailcap("text/xml;; x-java-content-handler=com.sun.mail.handlers.text_xml"); mc.addMailcap("text/plain;; x-java-content-handler=com.sun.mail.handlers.text_plain"); mc.addMailcap("multipart/*;; x-java-content-handler=com.sun.mail.handlers.multipart_mixed"); mc.addMailcap("message/rfc822;; x-java-content-handler=com.sun.mail.handlers.message_rfc822"); CommandMap.setDefaultCommandMap(mc); //发送消息 Transport.send(msg); &#125; class MyAuthenticator extends Authenticator &#123; private String strUser; private String strPwd; public MyAuthenticator(String user, String password) &#123; this.strUser = user; this.strPwd = password; &#125; protected PasswordAuthentication getPasswordAuthentication() &#123; return new PasswordAuthentication(strUser, strPwd); &#125; &#125; class MyAsynTask extends AsyncTask&lt;Void, Void, SendStatus&gt; &#123; @Override protected void onPreExecute() &#123; super.onPreExecute(); if (EmailInfterface != null) &#123; EmailInfterface.startSend(); &#125; &#125; @Override protected void onPostExecute(SendStatus result) &#123; super.onPostExecute(result); if (EmailInfterface != null) &#123; EmailInfterface.SendStatus(result); &#125; sendStatus = SendStatus.UNDO; &#125; @Override protected SendStatus doInBackground(Void... params) &#123; try &#123; sendStatus = SendStatus.SENDING; sendEmailBg(); sendStatus = SendStatus.SENDOK; &#125; catch (Exception e) &#123; String message = e.getMessage(); Log.v(TAG, "邮件发送失败的原因--》" + message); SendStatus sendStatus = CheckErrorUtils.checkExcption(message); e.printStackTrace();// MyEmailHelper.this.sendStatus = SendStatus.SENDFAIL; MyEmailHelper.this.sendStatus = sendStatus; &#125; return sendStatus; &#125; &#125;&#125; 3. 具体发送方法1234567891011121314151617181920212223242526272829303132333435363738 public void sendMail(String from, String to, String title, String context) &#123;// 附件// List&lt;String&gt; files = new ArrayList&lt;String&gt;();// files.add("/mnt/sdcard/test.txt"); //主要接收人的电子邮箱列表 List&lt;String&gt; toEmail = new ArrayList&lt;String&gt;(); toEmail.add(to); List&lt;String&gt; ccEmail = new ArrayList&lt;String&gt;(); //抄送人的电子邮箱列表 抄送给自己 防止被检测为垃圾邮件 ccEmail.add(from); helper.setParams(toEmail, ccEmail, title, context, null); Log.v(TAG, "toEmail:" + toEmail + " ccEmail:" + ccEmail + " EMAIL_TITLE_APP:" + title + " appEmailContext:" + context); helper.setJieEmailInfterface(new MyEmailHelper.EmailInfterface() &#123; @Override public void startSend() &#123; Toast.makeText(MainActivity.this, "邮件发送中~", Toast.LENGTH_LONG).show(); &#125; @Override public void SendStatus(MyEmailHelper.SendStatus sendStatus) &#123; switch (sendStatus) &#123; case SENDOK: Toast.makeText(MainActivity.this, "发送邮件成功~", Toast.LENGTH_LONG).show(); break; case SENDFAIL: Toast.makeText(MainActivity.this, "发送邮件失败~", Toast.LENGTH_LONG).show(); break; case SENDING: Toast.makeText(MainActivity.this, "邮件正在发送中，请稍后重试~", Toast.LENGTH_LONG).show(); break; case BADCONTEXT: Toast.makeText(MainActivity.this, "邮件内容或标题被识别为垃圾邮件，请修改后重试~", Toast.LENGTH_LONG).show(); break; &#125; &#125; &#125;); helper.sendEmail(); &#125; 4. 发送失败原因检查12345678910111213package lillusory.com.androidemail;import android.util.Log;public class CheckErrorUtils &#123; public static MyEmailHelper.SendStatus checkExcption(String message)&#123; if(message.contains("554 DT:SPM"))&#123; //发送失败原因有很多 这个是比较常见的问题 Log.v("Az","邮件被识别为垃圾邮件了~"); &#125; return MyEmailHelper.SendStatus.BADCONTEXT; &#125;&#125; 5. 网络权限记得添加网络权限 点击下载Demo]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客之（三）--部署篇]]></title>
    <url>%2Fposts%2F41257.html</url>
    <content type="text"><![CDATA[本章主要记录了如何将博客部署至云端，怎么设置个性域名，怎么将自己的网站提交到百度Google。让自己的网站能够出现在各大搜索引擎的具体方法和过程，希望能对大家有帮助。 这是一个基于Hexo的个人博客的教程，包含了从博客搭建到主题优化，最后部署到云端的全过程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 购买个性域名估计大家折腾了这么久也就是为 了拥有一个自己的个性站点,所以强烈建议大家为自己的博客站点配置一个独一无二的个性域名.我这里选择阿里旗下的万网。我的域名是www.lixueduan.com 大家可以选择一个自己喜欢的域名。等部署完毕就可以通过域名访问自己的博客了。 问题： GithubPages/CodingPages Github Pages是Github免费提供给开发者的一款托管个人网站的产品。 Coding Pages也是Coding免费提供给开发者的一款托管个人网站的产品。 关于为什么要部署两次 虽然可以根据自定义域名来访问自己的博客了，但是百度谷歌上都搜索不到，那岂不是很难受╮(╯▽╰)╭。 所以接下来为了让自己的博客能够被搜索出来，就需要让百度谷歌收录我们的网站。在部署收录过程中发现，Github屏蔽了百度的爬虫，所以搭建上GithubPages的话无法提交至百度，只有Google可以收录。 所以为了让百度收录我们网站，就得在Coding上也搭建一个。 同时在搭建的过程中发现如果先搭建在Github上，然后再搭建Coding时会出现DNS解析冲突。所以需要：先搭建Coding上的，再搭建Github上的，国外的访问则走Github，国内的访问会走Coding，完美 2. 部署到CodingPages2.1 注册coding账户 点击这里注册Coding](https://coding.net/) 2.2 创建新项目 注册好后创建一个项目用来部署个人博客，项目路径和项目名称最好和用户名一致 2.3 开启CodingPages 点击Pages服务，然后一键开启。 部署master分支 自定义域名 可以填两个 www.xxx.com 和xxx.com 绑定自定义域名的时候需要在买域名的地方(我这里是阿里的万网)配置DNS解析 1234567添加两条CNAME解析主机记录 一个@，一个www//@就是无前缀，xxx.com, www就是www.xxx.com解析路线 默认就行记录值 lillusory.coding.me //这里改成自己的 然后可以开启Https访问。 到这里就可以通过个性域名访问啦。不过现在博客代码还没有push到项目里。 2.4 Push代码到Coding配置SSH key 首先需要配置一个SSHkey，Git有Http协议和Git协议两种。我们这里使用Git协议就需要配置一个SSH key,等会部署到Github上也需要配置这个。 具体配置方法如下： Git 配置及SSH key 修改站点配置文件 这里只配置了Coding，可以先把Github的注释掉 12345678# Deployment 部署到云端相关配置## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: github: git@github.com:illusorycloud/illusorycloud.github.io.git coding: git@git.coding.net:illusorycloud/illusorycloud.git branch: master 地址在这里： 配置好后，运行hexo g时就可以把博客部署到Coding上了，也可以通过个性域名访问了。 3. 收录到百度3.1 网站添加直接百度搜索你的域名,比如我的www.lixueduan.com ，如果没有收录就会提示暂未收录，点击提交网址。 点击这个链接进入百度站长平台，登录成功后选择`用户中心–&gt;站点管理–&gt;添加网站 输入自己的网站，如www.lixueduan.com 协议头如果开启了https就选https 3.2 网站验证然后会验证这个网站是不是你的，选CNAME验证 然后去域名哪里添加一条解析即可。 记录类型–&gt;CNAME 主机记录—&gt;前面那一串l3rUDBLOMX 记录值–&gt;后面那个ziyuan.baidu.com 其他的都按默认的就行了，添加后别删除，需要一直留着。 3.3 站点地图接下来我们需要生成网站地图sitemap,使用sitemap方式向百度提交我们的网址 站点地图是一种文件，您可以通过该文件列出您网站上的网页，从而将您网站内容的组织架构告知Google和其他搜索引擎。搜索引擎网页抓取工具会读取此文件，以便更加智能地抓取您的网站。 先安装一下，打开你的hexo博客根目录，分别用下面两个命令来安装针对谷歌和百度的插件 12npm install hexo-generator-sitemap --save #sitemap.xml适合提交给谷歌搜素引擎npm install hexo-generator-baidu-sitemap --save #baidusitemap.xml适合提交百度搜索引擎 在站点配置文件中添加如下代码 12345678Plugins:- hexo-generator-baidu-sitemap- hexo-generator-sitemapbaidusitemap: path: baidusitemap.xmlsitemap: path: sitemap.xml 在你的博客根目录的public下面发现生成了sitemap.xml以及baidusitemap.xml就表示成功了. 然后将博客重新部署后就可以直接访问站点地图了。如https://www.lixueduan.com/baidusitemap.xml 然后将这个站点地图提交到百度 站点管理--&gt;站点属性--&gt;链接提交--&gt;自动提交--&gt;sitemap 完成后就算是提交成功了，百度比较慢，要好几天才能收录。 4. 部署到GitHub步骤和Coding差不多的。 4.1 注册Github账号点这里注册Github账号 4.2 创建新仓库也是名字必须和用户名一样，必须按照这个格式username.github.io，例如lillusorycloud.github.io 创建好仓库后找到Setings 往下拉，找到Github Pages 设置Custom domain填下自定义域名，如www.lixueduan.com.如果有Enforce HTTPS选项也可以勾上。 4.3 Push代码到Github配置SSH key 首先需要配置一个SSHkey，Git有Http协议和Git协议两种。我们这里使用Git协议就需要配置一个SSH key,等会部署到Github上也需要配置这个。 具体配置方法： Git 配置及SSH key 修改站点配置文件 repository中添加一个github 12345678# Deployment 部署到云端相关配置## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: github: git@github.com:illusorycloud/illusorycloud.github.io.git coding: git@git.coding.net:illusorycloud/illusorycloud.git branch: master 配置好后，运行hexo g时就可以把博客同时部署到Coding和Github上了，也可以通过个性域名访问了。 5. 收录到Google和百度差不多。 5.1 网站添加首先进入Google站点平台 然后添加资源，注意http和https 5.2 验证所有权然后验证所有权,选择DNS供应商 供应商选择其他，然后选择添加CNAME记录，在域名解析中添加一条记录。也是添加后不要删除。 5.3 站点地图验证后就可以添加站点地图了 提交成功后,我们的站点就已经被Google收录了.大概一天就能收录成功，比百度块一些。 6. 总结本文主要讲了怎么将博客部署到Coding和Github和怎么让百度,Google收录我们的网站。 7.参考Hexo官方文档 基于Hexo的个人博客 Hex博客搭建]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客之（二）--主题优化篇]]></title>
    <url>%2Fposts%2F58273.html</url>
    <content type="text"><![CDATA[本章主要包含了博客主题优化相关内容，第三方服务和插件的配置与使用。如：炫酷头像动态背景、链接变色、鼠标点击效果、站点字数、访客数统计等。 这是一个基于Hexo的个人博客的教程，包含了从博客搭建到主题优化，最后部署到云端的全过程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 0. 选择主题你可以点击这里选择你喜欢的Themes,里面有大量美观的主题 我这里用的是简约著称的Next主题. 下载主题 使用git命令下载该主题到本地. git clone https://github.com/theme-next/hexo-theme-next themes/next clone成功后,你的Themes文件夹下就会有next主题文件了. Hexo配置文件: 都叫_config.yml 一份位于站点根目录下，主要包含 Hexo 本身的配置,称为 站点配置文件 另一份位于主题目录下主要用于配置主题相关的选项,称为主题配置文件 开启主题 站点配置文件进行修改: 将theme: landscape修改为 theme: next 1. 侧边栏头像设置新版next注意引入了该功能,直接在主题配置文件修改即可,如下: 123456789# Sidebar Avatar 头像avatar: url: /images/avatar.gif # 圆形头像 rounded: true # 透明度 0~1之间 opacity: 1 # 头像旋转 rotated: true 2. 设置个人社交图标链接直接在主题配置文件修改即可,如下: 123456789101112131415161718192021# Social Links. 社交链接 前面为链接地址 后面是图标 social: GitHub: https://github.com/illusorycloud || github E-Mail: mailto:xueduan.li@gmail.com || envelope #Weibo: https://weibo.com/yourname || weibo #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skype# 图标配置 social_icons: #是否显示图标 enable: true #是否只显示图标 icons_only: false #是否开启图标变化(就是刷新后会变颜色) transition: false 3. 添加菜单项1.先在主题配置文件修改 12345678menu: home: / || home about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive AAAAA: /BBBBB/ || CCC其中AAA 为菜单项的名字,BBB是路径,CCC是菜单项显示的图标 next 使用的是 Font Awesome 提供的图标 ,在这里可以选择自己喜欢的图标. 2.生成上述路径的文件 git命令行输入 hexo new page BBB –其中BBB替换为具体的名字,会在站点目录\source下新增一个BBB文件夹,文件夹中有一个index.md文件，需要在文件头中增加一句type: XXX,例如type: categories。这样就会在这个页面显示所有的分类了。 3.修改主题文件下的对应语言的配置文件,这里是中文就修改zh-CN.yml 12345menu: home: 首页 archives: 归档 AAAA : XXXXAAA为上边的菜单项名字,XXX为中文的名字 4. 添加RSS 1.安装插件 首先在Git中运行npm install --save hexo-generator-feed命令,安装插件,插件会放在 node_modules文件夹里面. 2.修改站点配置文件 安装好插件后,打开站点配置文件_config.yml`,在末尾加入以下代码: 123# Extensions## Plugins: http://hexo.io/plugins/plugins: hexo-generate-feed 3.修改主题配置文件 打开主题配置文件_config.yml,找到rss 添加配置:rss: /atom.xml 5. 设置酷炫动态背景next主题提供了两种背景可以选择. 第一种背景（我是用的这种） 新版本的next主题的话直接在主题配置文件中,找到canvas-nest 修改为canvas-nest: true, 123456789# Canvas-nest# Dependencies: https://github.com/theme-next/theme-next-canvas-nestcanvas_nest: enable: true onmobile: true # display on mobile or not color: '0,0,255' # RGB values, use ',' to separate opacity: 0.5 # the opacity of line: 0~1 zIndex: -1 # z-index property of the background count: 99 # the number of lines 进入theme/next目录 执行命令git clone https://github.com/theme-next/theme-next-canvas-nest source/lib/canvas-nest 第二种背景 12345678# JavaScript 3D library.# Dependencies: https://github.com/theme-next/theme-next-three# three_wavesthree_waves: false# canvas_linescanvas_lines: false# canvas_spherecanvas_sphere: false 也是需要下载依赖 进入theme/next目录 执行命令：git clone https://github.com/theme-next/theme-next-three source/lib/three 4个背景中只能开启一种背景,不然会出错 6. 设置网站logo把你的图片放在themes/next/source/images里 打开主题配置文件_config.yml ,找到字段favicon: 都修改为对应路径 12345favicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png apple_touch_icon: /images/apple-touch-icon-next.png safari_pinned_tab: /images/logo.svg 7. 实现点击出现桃心效果themes/next/source/js/src里面 新建一个love.js, 复制下面的代码进去 1!function(e,t,a)&#123;function n()&#123;c(".heart&#123;width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);&#125;.heart:after,.heart:before&#123;content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;&#125;.heart:after&#123;top: -5px;&#125;.heart:before&#123;left: -5px;&#125;"),o(),r()&#125;function r()&#123;for(var e=0;e&lt;d.length;e++)d[e].alpha&lt;=0?(t.body.removeChild(d[e].el),d.splice(e,1)):(d[e].y--,d[e].scale+=.004,d[e].alpha-=.013,d[e].el.style.cssText="left:"+d[e].x+"px;top:"+d[e].y+"px;opacity:"+d[e].alpha+";transform:scale("+d[e].scale+","+d[e].scale+") rotate(45deg);background:"+d[e].color+";z-index:99999");requestAnimationFrame(r)&#125;function o()&#123;var t="function"==typeof e.onclick&amp;&amp;e.onclick;e.onclick=function(e)&#123;t&amp;&amp;t(),i(e)&#125;&#125;function i(e)&#123;var a=t.createElement("div");a.className="heart",d.push(&#123;el:a,x:e.clientX-5,y:e.clientY-5,scale:1,alpha:1,color:s()&#125;),t.body.appendChild(a)&#125;function c(e)&#123;var a=t.createElement("style");a.type="text/css";try&#123;a.appendChild(t.createTextNode(e))&#125;catch(t)&#123;a.styleSheet.cssText=e&#125;t.getElementsByTagName("head")[0].appendChild(a)&#125;function s()&#123;return"rgb("+~~(255*Math.random())+","+~~(255*Math.random())+","+~~(255*Math.random())+")"&#125;var d=[];e.requestAnimationFrame=function()&#123;return e.requestAnimationFrame||e.webkitRequestAnimationFrame||e.mozRequestAnimationFrame||e.oRequestAnimationFrame||e.msRequestAnimationFrame||function(e)&#123;setTimeout(e,1e3/60)&#125;&#125;(),n()&#125;(window,document); 然后打开\themes\next\layout\_layout.swig文件,在末尾 添加以下代码： 12&lt;!-- 页面点击小红心 --&gt;&lt;script type="text/javascript" src="/js/src/love.js"&gt;&lt;/script&gt; 8. 修改文章内链接文本样式鼠标移动到连接上变颜色 修改文件 themes\next\source\css\_common\components\post\post.styl，在末尾添加如下css样式，： 1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; border-bottom: none; border-bottom: 1px solid #0593d3; &amp;:hover &#123; color: #fc6423; border-bottom: none; border-bottom: 1px solid #fc6423; &#125;&#125; 9. 设置顶部滚动加载条打开next\layout\_partials\head文件，在文件末尾添加以下代码: 123456789101112131415&lt;script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"&gt;&lt;/script&gt;&lt;link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet"&gt;&lt;style&gt; .pace .pace-progress &#123; background: #1E92FB; /*进度条颜色*/ height: 3px; &#125; .pace .pace-progress-inner &#123; box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/ &#125; .pace .pace-activity &#123; border-top-color: #1E92FB; /*上边框颜色*/ border-left-color: #1E92FB; /*左边框颜色*/ &#125;&lt;/style&gt; 10. 在每篇文章末尾统一添加“本文结束”标记在路径 \themes\next\layout\_macro 中新建 page-end-tag.swig 文件,并添加以下内容： 123456&lt;!--文字可以自己修改--&gt;&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style="text-align:center;color: #A2CD5A;font-size:15px;"&gt;------------------本文到此结束&lt;i class="fa fa-paw"&gt;&lt;/i&gt;感谢您的阅读------------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 接着打开\themes\next\layout\_macro\post.swig文件，在post-body 之后， post-footer 之前添加下面的代码 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include 'page-end-tag.swig' %&#125; &#123;% endif %&#125;&lt;/div&gt; 然后打开主题配置文件（_config.yml),在末尾添加： 123# 文章末尾添加“本文结束”标记page_end_tag: enabled: true 11. 静态资源压缩Hexo自动生成的html中有很多空白的地方,会影响加载速度,所以最好还是压缩一下. 这里使用hexo-neat插件来压缩。 安装插件 npm install hexo-neat --save 在站点配置文件添加配置 1234567891011121314151617181920212223242526# hexo-neat# 博文压缩neat_enable: true# 压缩htmlneat_html: enable: true exclude: # 压缩css 跳过min.cssneat_css: enable: true exclude: - '**/*.min.css' # 压缩js 跳过min.jsneat_js: enable: true mangle: true output: compress: exclude: - '**/*.min.js' - '**/jquery.fancybox.pack.js' - '**/index.js' - '**/love.js'# 压缩博文配置结束 3.使用 以后再执行hexo g命令时就会自动压缩了 12. 主页文章添加阴影效果打开\themes\next\source\css\_custom\custom.styl,向里面加入： 12345678// 主页文章添加阴影效果 .post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 13. 修改文章底部的的标签样式打开模板文件/themes/next/layout/_macro/post.swig，找到rel=&quot;tag&quot;&gt;#字段， 将# 换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;,其中tag是你选择标签图标的名字,也是可以自定义的 1&lt;a href="&#123;&#123; url_for(tag.path) &#125;&#125;" rel="tag"&gt; &lt;i class="fa fa-tag"&gt;&lt;/i&gt; &#123;&#123; tag.name &#125;&#125;&lt;/a&gt; 14. 实现文章字数统计和预计阅读时间1.在站点根目录下使用GitBash命令安装 hexo-wordcount插件: 1npm install hexo-symbols-count-time --save 2.在全局配置文件_config.yml中激活插件: 12345symbols_count_time: symbols: true time: true total_symbols: true total_time: true 3.在主题的配置文件_config.yml中进行如下配置: 1234567#字数统计symbols_count_time: separated_meta: true item_text_post: true item_text_total: true awl: 4 wpm: 275 到此,我们就实现了文章字数统计和预估时间的显示功能 15. 在文章底部增加版权信息修改主题配置文件,找到creative_commons字段 12345678910# Creative Commons 4.0 International License.# https://creativecommons.org/share-your-work/licensing-types-examples# Available: by | by-nc | by-nc-nd | by-nc-sa | by-nd | by-sa | zerocreative_commons: #选择一个License license: by-nc-sa #是否在侧边栏显示 sidebar: false #是否在文章末尾显示 post: true 16. 文章置顶打开文件：node_modules/hexo-generator-index/lib/generator.js,将原来的代码用下面的代码替换掉 12345678910111213141516171819202122232425262728'use strict';var pagination = require('hexo-pagination');module.exports = function(locals)&#123; var config = this.config; var posts = locals.posts; posts.data = posts.data.sort(function(a, b) &#123; if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排 &#125; else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1; &#125; else if(!a.top &amp;&amp; b.top) &#123; return 1; &#125; else return b.date - a.date; // 都没定义按照文章日期降序排 &#125;); var paginationDir = config.pagination_dir || 'page'; return pagination('', posts, &#123; perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: &#123; __index: true &#125; &#125;);&#125;; 写文章的时候,在标题加上top值,数值越大排在越前面. 1234tag: hexo copyright: truepassword: xxxtop: 150 17. 在网站底部加上访问量Next主题配置这个就比较方便了 打开主题配置文件，找到如下配置： 12345678busuanzi_count: enable: true total_visitors: true total_visitors_icon: user total_views: true total_views_icon: eye post_views: true post_views_icon: eye 将enable的值由false改为true，便可以看到页脚出现访问量. 另外本地预览时访客数异常是正常的,部署至云端后就不会出现这样的问题. 18. 网站搜索功能1.安装插件 ​ 站点目录下执行命令npm install hexo-generator-searchdb --save 2.修改站点配置文件 12345search: path: search.xml field: post format: html limit: 10000 3.修改主题配置文件 1234567891011# Local search# Dependencies: https://github.com/theme-next/hexo-generator-searchdblocal_search: enable: enable # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 # unescape html strings to the readable one unescape: false 重新开启服务后即可看到效果。 TODO开启留言评论功能//TODO 待更新 参考Hexo官方文档 Next官方文档]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo搭建个人博客之（一）--基础篇]]></title>
    <url>%2Fposts%2F18973.html</url>
    <content type="text"><![CDATA[本文主要记录了如何搭建自己的博客。基于Hexo框架在本地搭建自己博客的全过程，包括了环境准备到Hexo初始化，再到服务的开启等。 这是一个基于Hexo的个人博客的教程，包含了从博客搭建到主题优化，最后部署到云端的全过程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 环境准备 Git Git下载地址 Node.js Node.js下载地址 小白式安装，一直下一步就ok了。 都安装好后就可以开始安装Hexo啦. 2. 安装Hexo 1.新建一个文件夹,用于安装Hexo,以后这个就是放博客文件的. 2.在此文件夹右键,Git Bash Here,打开Git 3.安装Hexo 命令npm install -g hexo 4.初始化Hexo 命令hexo init 5.安装组件 命令npm install 到此为止,Hexo就算是安装完成了。 3. 开启服务 1.hexo generate或者简写hexo g 编译,生成静态文件,就是生成一个个html文件. 2.开启服务hexo server或者hexo s 成功开启后就可以在本地访问了。 http://localhost:4000 假如页面一直无法跳转，那么可能端口被占用了。此时我们ctrl+c停止服务器，hexo server -p 端口号来改变端口号 如hexo server -p 5000 将端口号换为5000,默认是4000 3.常用命令 hexo clean 清除缓存文件 hexo deploy或者hexo d 部署网站到云端,这个后面再讲。 参考Hexo官方文档]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVC和三层架构 (集中式)及SSM框架整合]]></title>
    <url>%2Fposts%2F760fc833.html</url>
    <content type="text"><![CDATA[本文主要讲了MVC和三层架构的关系，和SSM框架整合教程。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1.三层架构整体分为三层,表现层UI,业务逻辑层BLL,数据访问层DAL. 表现层 Controller 用户界面,负责与用户进行交互 业务逻辑层 Service 具体的业务操作 数据访问层 Dao 对数据库进行操作,为上层提供数据 为了更好的降低各层间的耦合度，在三层架构程序设计中，采用面向抽象编程。即上层对下层的调用，是通过接口实现的。而下层对上层的真正服务提供者，是下层接口的实现类。服务标准（接口）是相同的，服务提供者（实现类）可以更换。这就实现了层间的耦合。 2.MVC MVC全名是Model View Controller，是模型(model)－视图(view)－控制器(controller)的缩写 . Model（模型） - 模型代表一个存取数据的对象或 JAVA POJO。它也可以带有逻辑，在数据变化时更新控制器。 View（视图） - 视图代表模型包含的数据的可视化。 Controller（控制器） - 控制器作用于模型和视图上。它控制数据流向模型对象，并在数据变化时更新视图。它使视图与模型分离开。 3.MVC与三层架构 经典三层架构和MVC的关系？—–&gt; 他们是两个毫无相关的东西 经典三层架构是一种分层思想，将开发模式分为了这三层 MVC是一种设计模式，目的是让HTML代码和业务逻辑代码分开，让代码看起来更加清晰，便于开发 4.SSM框架和三层架构SSM即SpringMVC、Spring、Mybatis三个框架。它们在三层架构中所处的位置是不同的，即它们在三层架构中的功能各不相同，各司其职。 SpringMVC：作为View层的实现者，完成用户的请求接收功能。SpringMVC的Controller作为整个应用的控制器，完成用户请求的转发及对用户的响应。 MyBatis：作为 Dao层的实现者，完成对数据库的增、删、改、查功能。 Spring：以整个应用大管家的身份出现。整个应用中所有的Bean的生命周期行为，均由Spring来管理。即整个应用中所有对象的创建、初始化、销毁，及对象间关联关系的维护，均由Spring进行管理。 5.SSM框架配置5.1 目录 Controller springmvc.xml 包扫描–controller 注解驱动 视图解析器 web.xml DispatcherServlet 监听器 Service applicationContext-service.xml 包扫描–service applicationContext-trans.xml 事务管理器 通知 切面 Dao SqlMapConfig.xml applicationContext-dao.xml dataSource SqlSessionFactory 包扫描–mapper 5.2 springmvc.xml123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:p="http://www.springframework.org/schema/p" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd"&gt; &lt;!-- 配置Controller扫描 --&gt; &lt;context:component-scan base-package="com.lillusory.crm.controller" /&gt; &lt;!-- 加载属性文件--&gt; &lt;context:property-placeholder location="classpath:crm.properties"/&gt; &lt;!-- 配置注解驱动 --&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- 配置视图解析器 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;!-- 前缀 --&gt; &lt;property name="prefix" value="/WEB-INF/jsp/" /&gt; &lt;!-- 后缀 --&gt; &lt;property name="suffix" value=".jsp" /&gt; &lt;/bean&gt;&lt;/beans&gt; 5.3 applicationContext-dao123456789101112131415161718192021222324252627282930313233343536&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd"&gt;&lt;!-- 配置 读取properties文件 jdbc.properties --&gt; &lt;context:property-placeholder location="classpath:jdbc.properties" /&gt; &lt;!-- 配置 数据源 --&gt; &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driver&#125;" /&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;" /&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;" /&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactory --&gt; &lt;bean class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;!-- 设置MyBatis核心配置文件 --&gt; &lt;property name="configLocation" value="classpath:SqlMapConfig.xml" /&gt; &lt;!-- 设置数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;property name="typeAliasesPackage" value="com.lillusory.crm.domain"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置Mapper扫描 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;!-- 设置Mapper扫描包 --&gt; &lt;property name="basePackage" value="com.lillusory.crm.mapper" /&gt; &lt;/bean&gt;&lt;/beans&gt; 5.4 applicationContext-service.xml123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd"&gt;&lt;!-- 包扫描 --&gt;&lt;context:component-scan base-package="com.lillusory.crm.service"/&gt;&lt;/beans&gt; 5.5 applicationContext-trans.xml123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd"&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!-- 数据源 --&gt; &lt;property name="dataSource" ref="dataSource" /&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt; &lt;tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name="save*" propagation="REQUIRED" /&gt; &lt;tx:method name="insert*" propagation="REQUIRED" /&gt; &lt;tx:method name="add*" propagation="REQUIRED" /&gt; &lt;tx:method name="create*" propagation="REQUIRED" /&gt; &lt;tx:method name="delete*" propagation="REQUIRED" /&gt; &lt;tx:method name="update*" propagation="REQUIRED" /&gt; &lt;tx:method name="find*" propagation="SUPPORTS" read-only="true" /&gt; &lt;tx:method name="select*" propagation="SUPPORTS" read-only="true" /&gt; &lt;tx:method name="get*" propagation="SUPPORTS" read-only="true" /&gt; &lt;tx:method name="query*" propagation="SUPPORTS" read-only="true" /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 切面 --&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref="txAdvice" pointcut="execution(* com.lillusory.crm.service.*.*(..))" /&gt; &lt;/aop:config&gt;&lt;/beans&gt; 5.6 SqlMapConfig.xml123456&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN""http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt;&lt;!-- 暂时什么都不用配置 --&gt;&lt;/configuration&gt; 5.7 web.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" id="WebApp_ID" version="2.5"&gt; &lt;display-name&gt;Demo-CRM&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 配置spring --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/applicationContext-*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 配置监听器加载spring --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置过滤器，解决post的乱码问题 --&gt; &lt;filter&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;encoding&lt;/filter-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- 配置SpringMVC --&gt; &lt;servlet&gt; &lt;servlet-name&gt;demo-crm&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 配置springmvc什么时候启动，参数必须为整数 --&gt; &lt;!-- 如果为0或者大于0，则springMVC随着容器启动而启动 --&gt; &lt;!-- 如果小于0，则在第一次请求进来的时候启动 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;demo-crm&lt;/servlet-name&gt; &lt;!-- 所有的请求都进入springMVC / 拦截所有除了jsp /* jsp也拦截 --&gt; &lt;url-pattern&gt;*.action&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; 5.8其他常用配置jdbc1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/kct?characterEncoding=utf-8jdbc.username=rootjdbc.password=root log4j123456# Global logging configurationlog4j.rootLogger=debug, stdout# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n 参考https://juejin.im/post/5929259b44d90400642194f3]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络(五)--从输入URL到页面加载的过程中发生了什么]]></title>
    <url>%2Fposts%2F5863.html</url>
    <content type="text"><![CDATA[本文主要对用户从浏览器输入URL到页面加载的这一过程进行了具体分析与叙述。包括：DNS解析、发送HTTP请求、TCP连接、服务器响应、浏览器解析渲染页面等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 总体来说分为以下几个过程: 1.DNS解析 2.TCP连接 3.发送HTTP请求 4.服务器处理请求并返回HTTP报文 5.浏览器解析渲染页面 6.连接结束 1. DNS解析解析域名，找到主机IP。如百度对应的IP为180.97.33.108 ,浏览器输入IP也可以访问到百度。 （1）浏览器会缓存DNS一段时间，一般2-30分钟不等。如果有缓存，直接返回IP，否则下一步。 （2）缓存中无法找到IP，浏览器会进行一个系统调用，查询hosts文件。如果找到，直接返回IP，否则下一步。（在计算机本地目录etc下有一个hosts文件，hosts文件中保存有域名与IP的对应解析，通常也可以修改hosts科学上网或破解软件。） （3）进行了（1）（2）本地查询无果，只能借助于网络。路由器一般都会有自己的DNS缓存，ISP服务商DNS缓存，这时一般都能够得到相应的IP。如果还是无果，只能借助于DNS递归解析了。 （4）这时，ISP的DNS服务器就会开始从根域名服务器开始递归搜索，从.com顶级域名服务器，到baidu的域名服务器。 到这里，浏览器就获得了IP。在DNS解析过程中，常常会解析出不同的IP。比如，电信的是一个IP，网通的是另一个IP。这是采取了智能DNS的结果，降低运营商间访问延时，在多个运营商设置主机房，就近访问主机。电信用户返回电信主机IP，网通用户返回网通主机IP。当然，劫持DNS，也可以屏蔽掉一部分网点的访问，某防火长城也加入了这一特性。 2. TCP连接浏览器与网站建立TCP连接 浏览器利用IP直接与网站主机通信。浏览器发出TCP（SYN标志位为1）连接请求，主机返回TCP（SYN，ACK标志位均为1）应答报文，浏览器收到应答报文发现ACK标志位为1，表示连接请求确认。浏览器返回TCP（）确认报文，主机收到确认报文，三次握手，TCP链接建立完成。 3. 发送HTTP请求浏览器发起HTTP请求 其实这部分又可以称为前端工程师眼中的HTTP，它主要发生在客户端。发送HTTP请求的过程就是构建HTTP请求报文并通过TCP协议中发送到服务器指定端口(HTTP协议80/8080, HTTPS协议443)。HTTP请求报文是由三部分组成: 请求行, 请求报头和请求正文。 请求行 请求行包括：请求方法，URL ， 协议版本 12请求行：请求方法 URL 协议版本 eg: GET index.html HTTP/1.1 请求报头 请求报头允许客户端向服务器传递请求的附加信息和客户端自身的信息。PS: 客户端不一定特指浏览器，有时候也可使用Linux下的CURL命令以及HTTP客户端测试工具等。常见的请求报头有: Accept,Accept-Charset,Accept-Encoding,Accept-Language, Content-Type, Authorization, Cookie, User-Agent等。 请求正文 当使用POST, PUT等方法时，通常需要客户端向服务器传递数据。这些数据就储存在请求正文中。在请求包头中有一些与请求正文相关的信息，例如: 现在的Web应用通常采用Rest架构，请求的数据格式一般为json。这时就需要设置Content-Type: application/json 浏览器向主机发起一个HTTP请求。请求中包含访问的URL，也就是http://www.baidu.com/ ，还有User-Agent用户浏览器操作系统信息，编码等。值得一提的是Accep-Encoding和Cookies项。Accept-Encoding一般采用gzip，压缩之后传输html文件。Cookies如果是首次访问，会提示服务器建立用户缓存信息，如果不是，可以利用Cookies对应键值，找到相应缓存，缓存里面存放着用户名，密码和一些用户设置项。 4. 服务器响应服务器对请求做出响应并返回HTTP响应报文。自然而然这部分对应的就是后端工程师眼中的HTTP。后端从在固定的端口接收到TCP报文开始，这一部分对应于编程语言中的socket。它会对TCP连接进行处理，对HTTP协议进行解析，并按照报文格式进一步封装成HTTP Request对象，供上层使用。这一部分工作一般是由Web服务器去进行，例如Tomcat。 HTTP响应报文也是由三部分组成: 响应行, 响应报头和响应报文。 响应行 响应行包括：协议版本 状态码 状态码描述 12响应行包括：协议版本 状态码 状态码描述 eg: HTTP/1.1 200 OK 响应报头 常见的响应报头字段有: Server, Connection…。 响应报文 服务器返回给浏览器的文本信息，通常HTML, CSS, JS, 图片等文件就放在这一部分。 5. 浏览器解析渲染页面返回状态码200 OK，表示服务器可以相应请求，返回报文，由于在报头中Content-type:“text/html”，浏览器以HTML形式呈现，而不是下载文件。 浏览器在收到HTML,CSS,JS文件后，它是如何把页面呈现到屏幕上的? 浏览器是一个边解析边渲染的过程。首先浏览器解析HTML文件构建DOM树，然后解析CSS文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。这个过程比较复杂，涉及到两个概念: reflow(回流)和repain(重绘)。DOM节点中的各个元素都是以盒模型的形式存在，这些都需要浏览器去计算其位置和大小等，这个过程称为relow;当盒模型的位置,大小以及其他属性，如颜色,字体,等确定下来之后，浏览器便开始绘制内容，这个过程称为repain。页面在首次加载时必然会经历reflow和repain。reflow和repain过程是非常消耗性能的，尤其是在移动设备上，它会破坏用户体验，有时会造成页面卡顿。所以我们应该尽可能少的减少reflow和repain。 重定向 负载均衡 但是，对于大型网站存在多个主机站点，往往不会直接返回请求页面，而是重定向。返回的状态码就不是200 OK，而是301,302以3开头的重定向码，浏览器在获取了重定向响应后，在响应报文中Location项找到重定向地址，浏览器重新第一步访问即可。 补充一点的就是，重定向是为了负载均衡或者导入流量，提高SEO排名。利用一个前端服务器接受请求，然后负载到不同的主机上，可以大大提高站点的业务并发处理能力；重定向也可将多个域名的访问，集中到一个站点；由于lixueduan.com，www.lixueduan.com会被搜索引擎认为是两个网站，照成每个的链接数都会减少从而降低排名，永久重定向会将两个地址关联起来，搜索引擎会认为是同一个网站，从而提高排名。 6. 连接结束在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 7. 计算机网络常见问题看完系列文章，下面这些问题应该也不是问题了。 1.TCP三次握手和四次挥手 2.在浏览器中输入url地址-&gt;&gt;显示主页的过程 3.HTTP和HTTPS的区别 4.TCP、UDP协议的区别 5.常见的状态码。 8. 参考https://segmentfault.com/a/1190000006879700]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络(四)--HTTP与HTTPS]]></title>
    <url>%2Fposts%2F21307.html</url>
    <content type="text"><![CDATA[本文主要介绍了HTTP、HTTPS的基本概念及两者的区别，HTTPS的工作原理及优缺点，最后介绍了HTTP的响应状态码。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. HTTP和HTTPS基本概念 HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。 HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。 12HTTP--&gt; HTTP--&gt;TCP--&gt;IPHTTPS-&gt; HTTP--&gt;SSL--&gt;TCP--&gt;IP HTTPS协议的主要作用：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。 2. HTTP与HTTPS的区别 HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全。 HTTPS和HTTP的区别: 1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。 2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。 4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。 3. HTTPS工作原理 我们都知道HTTPS能够加密信息，以免敏感信息被第三方获取，所以很多银行网站或电子邮箱等等安全级别较高的服务都会采用HTTPS协议。 SSL协议的握手过程 分为五个步骤: 第一步，客户端给出SSL协议版本号、一个客户端生成的随机数1（Client random），以及客户端支持的加密方法。 第二步，服务端根据客服端支持的加密方法选出双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数2（Server random）。 第三步，客户端确认数字证书有效，然后生成一个新的随机数3（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务端。 第四步，服务端使用自己的私钥，获取客户端发来的随机数3（即Premaster secret）。到这里双方都拥有三个随机数了，为什么要使用三个随机数呢？这是因为 SSL/TLS 握手过程的数据都是明文传输的，并且多个随机数种子来生成秘钥不容易被暴力破解出来。 第五步，客户端和服务端根据约定的加密方法，使用前面的三个随机数，生成”对话密钥”（session key），用来加密接下来的整个对话过程。 第六步，客户端将前面的握手消息生成摘要再用协商好的秘钥加密，这是客户端发出的第一条加密消息。服务端接收后会用秘钥解密，能解出来说明前面协商出来的秘钥是一致的。 第七步，服务端也会将握手过程的消息生成摘要再用秘钥加密，这是服务端发出的第一条加密消息。客户端接收后会用秘钥解密，能解出来说明协商的秘钥是一致的。 到这里，双方已安全地协商出了同一份秘钥，所有的应用层数据都会用这个秘钥加密后再通过 TCP 进行可靠传输。 4. HTTPS的优缺点 优点: （1）使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器； （2）HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。 （3）HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。 （4）谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高” 缺点: （1）HTTPS协议握手阶段比较费时，会使页面的加载时间延长近50%，增加10%到20%的耗电； （2）HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响； （3）SSL证书需要钱，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。 （4）SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。 （5）HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。 5. HTTP响应状态码状态码以3位数字和原因短语组成，例如 200 OK 。 数字的第一位指定了响应类型，后两位无分类。响应类别一共有5种： 1XX Informational(信息性状态码) 2XX Success(成功状态码) 3XX Redirection(重定向状态码) 4XX Client Error(客户端错误状态码) 5XX Server Error(服务器错误状态码) 1234567891011121314151617181920212223200：请求成功 处理方式：获得响应的内容，进行处理 201：请求完成，结果是创建了新资源。新创建资源的URI可在响应的实体中得到 处理方式：爬虫中不会遇到 202：请求被接受，但处理尚未完成 处理方式：阻塞等待 204：服务器端已经实现了请求，但是没有返回新的信 息。如果客户是用户代理，则无须为此更新自身的文档视图。 处理方式：丢弃300：该状态码不被HTTP/1.0的应用程序直接使用， 只是作为3XX类型回应的默认解释。存在多个可用的被请求资源。 处理方式：若程序中能够处理，则进行进一步处理，如果程序中不能处理，则丢弃301：请求到的资源都会分配一个永久的URL，这样就可以在将来通过该URL来访问此资源 处理方式：重定向到分配的URL302：请求到的资源在一个不同的URL处临时保存 处理方式：重定向到临时的URL 304 请求的资源未更新 处理方式：丢弃 400 非法请求 处理方式：丢弃 401 未授权 处理方式：丢弃 403 禁止 处理方式：丢弃 404 没有找到 处理方式：丢弃 5XX 回应代码以“5”开头的状态码表示服务器端发现自己出现错误，不能继续执行请求 处理方式：丢弃 6. HTTP长连接、短连接在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 而从HTTP/1.1起，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码： 1Connection:keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 https加密是在传输层 https报文在被包装成tcp报文的时候完成加密的过程，无论是https的header域也好，body域也罢都是会被加密的。 当使用tcpdump或者wireshark之类的tcp层工具抓包，获取是加密的内容，而如果用应用层抓包，使用Charels(Mac)、Fildder(Windows)抓包工具，那当然看到是明文的。 7. 参考https://www.cnblogs.com/qiangxia/p/5261813.html https://www.cnblogs.com/wqhwe/p/5407468.html http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络(三)--TCP如何保证传输可靠性]]></title>
    <url>%2Fposts%2F18422.html</url>
    <content type="text"><![CDATA[本文主要叙述了TCP协议是如何保证传输的可靠性的，主要保证手段包括：序列号、校验和 、流量控制、拥塞控制、停止等待协议、超时重传、连接管理等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 主要保证方式 序列号:应用数据被分割成 TCP 认为最适合发送的数据块,同时给每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 校验和： TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到端的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 流量控制： TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制） 拥塞控制： 当网络拥塞时，减少数据的发送。 停止等待协议(确认应答) 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。 超时重传： 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 连接管理: 三次握手四次挥手,保证可靠的连接，是保证可靠性的前提。 2. 停止等待协议 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组； 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认； 1) 无差错情况: 发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。 2) 出现差错情况（超时重传）: [ 停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 自动重传请求 ARQ 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。连续 ARQ 协议 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。 3) 确认丢失和确认迟到 确认丢失：当确认消息在传输过程丢失 A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施： 丢弃这个重复的M1消息，不向上层交付。 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。 确认迟到 ：确认消息在传输过程中迟到 [A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下： A收到重复的确认后，直接丢弃。 B收到重复的M1后，也直接丢弃重复的M1。 3. ARQ协议即自动重传请求 ARQ 协议(Automatic Repeat reQuest )，停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求ARQ。 优点： 简单 缺点： 信道利用率低 4. 连续ARQ协议连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。 优点： 信道利用率高，容易实现，即使确认丢失，也不必重传。 缺点： 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。 5. 流量控制 滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。 TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。 TCP 利用滑动窗口实现流量控制的机制。 流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 6. 拥塞控制防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。 拥塞：即对资源的需求超过了可用的资源。若网络中许多资源同时供应不足，网络的性能就要明显变坏，整个网络的吞吐量随之负荷的增大而下降 拥塞控制所要做的都有一个前提：网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络传输性能有关的所有因素。 几种拥塞控制方法 ​ 慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )。 慢开始和拥塞避免 ​ 发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞。 ​ 发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始算法：当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。 拥塞避免算法：让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。 快重传与快恢复 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。 7.参考https://blog.csdn.net/liuchenxia8/article/details/80428157 https://blog.csdn.net/yangbodong22011/article/details/48473183]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络(二)--TCP三次握手四次挥手]]></title>
    <url>%2Fposts%2F25338.html</url>
    <content type="text"><![CDATA[本文主要介绍了TCP/IP的三次握手和四次挥手具体步骤及其原因分析。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 三次握手 step1:第一次握手建立连接时，客户端发送SYN包到服务器，其中包含客户端的初始序号seq=x，并进入SYN_SENT状态，等待服务器确认。（其中，SYN=1，ACK=0，表示这是一个TCP连接请求数据报文；序号seq=x，表明传输数据时的第一个数据字节的序号是x）。 step2:第二次握手服务器收到请求后，必须确认客户的数据包。同时自己也发送一个SYN包，即SYN+ACK包，此时服务器进入SYN_RCVD状态。（其中确认报文段中，标识位SYN=1，ACK=1，表示这是一个TCP连接响应数据报文，并含服务端的初始序号seq(服务器)=y，以及服务器对客户端初始序号的确认号ack(服务器)=seq(客户端)+1=x+1）。 step3:第三次握手 客户端收到服务器的SYN+ACK包，向服务器发送一个序列号(seq=x+1)，确认号为ack(客户端)=y+1，此包发送完毕，客户端和服务器进入ESTABLISHED (TCP连接成功)**状态，完成三次握手。 123456建立连接前要确认客户端和服务端的接收和发送功能是否正常。第一次客户端发送SYN时 什么也确认不了第二次服务端发送SYN+ACK 可以确认服务端发送功能正常第三次 客户端收到服务端发送的YSN+ACK 可以确认客户端发送接收功能正常最后客户端发送ACK 服务端接收到后 可以确认服务端发送功能正常到此就确认完毕了。 2. 四次挥手 step1：第一次挥手首先，客户端发送一个FIN，用来关闭客户端到服务器的数据传送，然后等待服务器的确认。其中终止标志位FIN=1，序列号seq=u。 客户端进入FIN_WAIT1状态 1我（Client端）没有数据要发给你（Server端）了&quot;，但是如果你（Server端）还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK step2：第二次挥手服务器收到这个FIN进入CLOSE_WAIT状态，然后它给客户端发送一个ACK，确认ack为收到的序号加一。 客户端收到ACK应答后进入FIN_WAIT2状态 1告诉Client端，你的请求我收到了，但是我（Server端）还没准备好，请继续你等我的消息&quot; step3：第三次挥手服务端关闭服务器到客户端的连接，发送一个FIN给客户端。服务端进入LAST_ACK状态 1告诉Client端，好了，我（Server端）这边数据发完了，准备好关闭连接了 step4：第四次挥手 客户端收到FIN后，进入TIME_WAIT状态 并发回一个ACK报文确认，并将确认序号seq设置为收到序号加一。 服务端收到客户端回复的ACK后立即关闭，服务端进入CLOASED状态 而客户端要等待2MSL后关闭 进入CLOASED状态 1Client端收到FIN报文后，&quot;就知道可以关闭连接了，所以发送ACK。但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后没有立即，而是进入TIME_WAIT状态，如果Server端没有收到ACK那么自己还可以重传。Server端收到ACK后，&quot;就知道可以断开连接了&quot;。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！ 3. TIME-WAIT状态详解为什么Client端要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？ 保证TCP协议的全双工连接能够可靠关闭，保证这次连接的重复数据段从网络中消失 假设由于IP协议的不可靠性或者是其它网络原因，导致Server没有收到Client最后回复的ACK。那么Server就会在超时之后继续发送FIN，Client端在等待2MSL时间后都没收到信息，说明Server端已经收到自己发送的ACK并且成功关闭了。假设CLient端直接关闭了： 1231.由于IP协议的不可靠性或者是其它网络原因，导致Server没有收到Client最后回复的ACK。那么Server就会在超时之后继续发送FIN，此时由于Client已经CLOSED了，就找不到与重发的FIN对应的连接，最后Server就会收到RST而不是ACK，Server就会以为是连接错误把问题报告给高层。这样的情况虽然不会造成数据丢失，但是却导致TCP协议不符合可靠连接的要求。所以，Client不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。2.如果Client直接CLOSED，然后又再向Server发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达Server，由于新连接和老连接的端口号是一样的，又因为TCP协议判断不同连接的依据是socket pair，于是，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。 2MSL:Maximum Segment Lifetime 即数据在网络中保存的最大时间。 简单易懂的说法: 1假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说&quot;我Client端没有数据要发给你了&quot;，但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，&quot;告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息&quot;。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，&quot;告诉Client端，好了，我这边数据发完了，准备好关闭连接了&quot;。Client端收到FIN报文后，&quot;就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，&quot;就知道可以断开连接了&quot;。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！ 4. TCP 的有限状态机红色为客户端 蓝色为服务端 细箭头为异常变化 5. 参考https://www.baidu.com/link?url=_mlor11BLttd1jmMU4k9OP0gqcjNKhZQ9fJuvbMOhkuH9-lVeB-y3VIVK1neZURi_tmR3rg1lj2lfgvvGhTV-q&amp;wd=&amp;eqid=d0144c250007b69c000000035bfdfafc]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络(一)--OSI七层模型]]></title>
    <url>%2Fposts%2F25470.html</url>
    <content type="text"><![CDATA[本文主要通过OSI七层模型与常用TCP/IP5层模型介绍了各层的主要作用，包括应用层，运输层，网络层，数据链路层，物理层等。 更多文章欢迎访问我的个人博客–&gt;幻境云图 OSI与TCP/IP模型 应用层:通过应用进程间的交互来完成特定网络应用。 运输层：向用户提供可靠的、端到端的差错和流量控制，保证报文的正确传输。 网络层：通过路由算法，为报文或分组通过通信子网选择最适当的路径。 数据链路层：其最基本的服务是将源自网络层来的数据可靠地传输到相邻节点的目标机网络层。 物理层：利用传输介质为数据链路层提供屋里连接，实现比特流的透明传输。 1. 应用层主要作用:通过应用进程间的交互来完成特定网络应用。 应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如域名系统DNS，支持万维网应用的 HTTP协议，支持电子邮件的 SMTP协议等等。我们把应用层交互的数据单元称为报文。 2. 运输层 主要任务：向用户提供可靠的、端到端的差错和流量控制，保证报文的正确传输。 主要作用：向高层屏蔽下层数据通信的具体细节，即向用户透明的传送报文。 主要用到的协议： 传输控制协议 TCP（Transmisson Control Protocol）–提供面向连接的，可靠的数据传输服务。 用户数据协议 UDP（User Datagram Protocol）–提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。 2.1 UDP UDP 是无连接的； UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）； UDP 是面向报文的； UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 直播，实时视频会议等）； UDP 支持一对一、一对多、多对一和多对多的交互通信； UDP 的首部开销小，只有8个字节，比TCP的20个字节的首部要短。 2.2 TCP TCP 是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）； 每一条 TCP 连接只能有两个端点，每一条TCP连接只能是点对点的（一对一）； TCP 提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达； TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据； 面向字节流。TCP 中的“流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。 3. 网络层主要任务：通过路由算法，为报文或分组通过通信子网选择最适当的路径。该层控制数据链路层与物理层之间的信息转发，建立、维持与终止网络的连接。具体的说，数据链路层的数据在这一层被转换为数据包，然后通过路径选择、分段组合、顺序、进/出路由等控制，将信息从一个网络设备传送到另一个网络设备。 一般的，数据链路层是解决统一网络内节点之间的通信，而网络层主要解决不同子网之间的通信。例如路由选择问题。 在实现网络层功能时，需要解决的主要问题如下： 寻址：数据链路层中使用的物理地址（如MAC地址）仅解决网络内部的寻址问题。在不同子网之间通信时，为了识别和找到网络中的设备，每一子网中的设备都会被分配一 个唯一的地址。由于各个子网使用的物理技术可能不同，因此这个地址应当是逻辑地址（如IP地址） 交换：规定不同的交换方式。常见的交换技术有：线路交换技术和存储转发技术，后者包括报文转发技术和分组转发技术。路由算法：当源节点和路由节点之间存在多条路径时，本层可以根据路由算法，通过网络为数据分组选择最佳路径，并将信息从最合适的路径，由发送端传送的接受端。连接服务：与数据链路层的流量控制不同的是，前者控制的是网络相邻节点间的流量，后者控制的是从源节点到目的节点间的流量。其目的在于防止阻塞，并进行差错检测 4. 数据链路层其最基本的服务是将源自网络层来的数据可靠地传输到相邻节点的目标机网络层。 主要功能：通过各种控制协议，将有差错的物理信道变为无差错的、能可靠传输数据帧的数据链路。 具体工作：接受来自物理层的位流形式的数据，并封装成帧，传送到上一层；同样，也将来自上一层的数据帧，拆装为位流形式的数据转发到物理层；并且还负责处理接受端发回的确认帧的信息，以便提供可靠的数据传输。 该层通常又被分为 介质访问控制(MAC)和逻辑链路控制(LLC)两个子层： MAC子层的主要任务是解决共享型网络中多用户对信道竞争的问题，完成网络介质的访问控制。LLC子层的主要任务是建立和维护网络连接，执行差错校验、流量控制和链路控制。 5. 物理层主要功能：利用传输介质为数据链路层提供屋里连接，实现比特流的透明传输。 作用：实现相邻计算机节点之间比特流的透明传输，尽可能屏蔽掉具体传输介质与物理设备的差异。使其上面的数据链路层不必考虑网络的具体传输介质是什么。 透明传输的意义就是：不管传的是什么，所采用的设备只是起一个通道作用，把要传输的内容完好的传到对方！ 在互联网使用的各种协中最重要和最著名的就是 TCP/IP 两个协议。现在人们经常提到的TCP/IP并不一定单指TCP和IP这两个具体的协议，而往往表示互联网所使用的整个TCP/IP协议族。 6. 参考https://blog.csdn.net/yaopeng_2005/article/details/7064869]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(十三)---组合模式]]></title>
    <url>%2Fposts%2Fa340063f.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的 模式，并结合实例描述了 模式的具体实现和性能分析测试。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介组合模式：将对象组合成树形结构以表示”部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 所谓组合模式，其实说的是对象包含对象的问题，通过组合的方式（在对象内部引用对象）来进行布局 以Windows文件系统为例，文件夹下可能有文件，也可能还有一个文件夹。文件夹可以包含文件和文件夹，但文件却没有这些功能。所以实现的时候需要单独实现。如果用组合模式的话，将文件和文件夹看成一个整体。都是文件。当做抽象的文件。 2. 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * 组合模式 * * @author illusoryCloud */public class Employee &#123; private String name; /** * 职位 */ private String dept; /** * 工资 */ private int salary; /** * 下属 一个Employee集合 */ private List&lt;Employee&gt; subordinates; public Employee(String name, String dept, int sal) &#123; this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;Employee&gt;(); &#125; public void add(Employee e) &#123; subordinates.add(e); &#125; public void remove(Employee e) &#123; subordinates.remove(e); &#125; public List&lt;Employee&gt; getSubordinates() &#123; return subordinates; &#125; @Override public String toString() &#123; return ("Employee :[ Name : " + name + ", dept : " + dept + ", salary :" + salary + " ]"); &#125;&#125;/** * 组合模式 测试类 * * @author illusoryCloud */public class CompositeTest &#123; @Test public void compositeTest()&#123; Employee CEO = new Employee("John","CEO", 30000); Employee headSales = new Employee("Robert","Head Sales", 20000); Employee headMarketing = new Employee("Michel","Head Marketing", 20000); Employee clerk1 = new Employee("Laura","Marketing", 10000); Employee clerk2 = new Employee("Bob","Marketing", 10000); Employee salesExecutive1 = new Employee("Richard","Sales", 10000); Employee salesExecutive2 = new Employee("Rob","Sales", 10000); CEO.add(headSales); CEO.add(headMarketing); headSales.add(salesExecutive1); headSales.add(salesExecutive2); headMarketing.add(clerk1); headMarketing.add(clerk2); //打印该组织的所有员工 System.out.println(CEO); for (Employee headEmployee : CEO.getSubordinates()) &#123; System.out.println(headEmployee); for (Employee employee : headEmployee.getSubordinates()) &#123; System.out.println(employee); &#125; &#125; &#125;&#125; 3. 参考https://blog.csdn.net/qq_40709468/article/details/81990084 http://www.runoob.com/design-pattern/composite-pattern.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(十二)---观察者模式]]></title>
    <url>%2Fposts%2F48bcf013.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的观察者模式，并结合实例描述了观察者模式的具体实现和优缺点分析。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介 让多个观察者对象同时监听某一个主题对象，这个主题对象在状态上发生变化时，会通知所有观察者对象，使他们能够自动更新自己。在对象之间定义了一对多的依赖，这样一来，当一个对象改变状态，依赖它的对象会收到通知并自动更新。其实就是发布订阅模式，发布者发布信息，订阅者获取信息，订阅了就能收到信息，没订阅就收不到信息。 该模式包含四个角色 抽象被观察者角色：也就是一个抽象主题，它把所有对观察者对象的引用保存在一个集合中，每个主题都可以有任意数量的观察者。抽象主题提供一个接口，可以增加和删除观察者角色。一般用一个抽象类和接口来实现。 抽象观察者角色：为所有的具体观察者定义一个接口，在得到主题通知时更新自己。 具体被观察者角色：也就是一个具体的主题，在集体主题的内部状态改变时，所有登记过的观察者发出通知。 具体观察者角色：实现抽象观察者角色所需要的更新接口，一边使本身的状态与制图的状态相协调。 2. 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212/** * 抽象观察者角色 * 定义了一个update()方法，当被观察者调用notifyObservers()方法时，观察者的update()方法会被回调。 * * @author illusoryCloud */public interface Observer &#123; /** * 更新消息 由被观察者调用 * * @param o 被观察者 即消息来源 * @param message 收到的消息 */ void update(Observable o, Message message);&#125;/** * 抽象被观察者接口 * 声明了添加、删除、通知观察者方法 * * @author illusoryCloud */public class Observable &#123; /** * 被观察者是否有变化 * 在通知观察者时做判断 若没有发生变化则不通知 */ private boolean changed = false; /** * Vector集合 线程安全的 * 用于存放已注册的观察者 */ private Vector&lt;Observer&gt; obs; public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; /** * 注册观察者 * * @param o 需要注册的观察者 */ public synchronized void addObserver(Observer o) &#123; if (o == null) &#123; throw new NullPointerException(); &#125; if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; /** * 移除观察者 * * @param o 被移除的观察者 */ public synchronized void deleteObserver(java.util.Observer o) &#123; obs.removeElement(o); &#125; /** * 发通知 */ public void notifyObservers() &#123; notifyObservers(null); &#125; /** * 循环遍历 通知注册的所有的观察者 * * @param message 发送的消息 */ public void notifyObservers(Message message) &#123; Object[] arrLocal; synchronized (this) &#123; //判断若没有变化则直接返回 if (!changed) &#123; return; &#125; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length - 1; i &gt;= 0; i--) &#123; ((Observer) arrLocal[i]).update(this, message); &#125; &#125; /** * 移除所有观察者 */ public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; /** * set clear has 设置 清除 获取 * 观察者状态是否变化 true/false */ protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; /** * 已注册观察者的个数 * * @return count */ public synchronized int countObservers() &#123; return obs.size(); &#125;&#125;/** * 具体观察者角色 * 实现update方法 * * @author illusoryCloud */public class Client implements Observer &#123; private String clientName; private int id; public Client(String clientName, int id) &#123; this.clientName = clientName; this.id = id; &#125; @Override public void update(Observable o, Message message) &#123; System.out.println(id + "号" + clientName + "收到&lt;" + ((Server)o).getName() + "&gt;推送的消息：" + message.toString()); &#125;&#125;/** * 具体被观察者角色 * * @author illusoryCloud */public class Server extends Observable &#123; /** * 被观察者name 用于区分多个被观察者 */ private String name; public Server(String name) &#123; this.name = name; &#125; @Override public void notifyObservers(Message message) &#123; //发送消息 super.notifyObservers(message); //发送后取消change标志 clearChanged(); &#125; public String getName()&#123; return this.name; &#125;&#125;/** * 观察者模式 测试类 * * @author illusoryCloud */public class ObserverTest &#123; @Test void observerTest() &#123; //发送的消息对象 Message message = null; //1个被观察者 Server s1 = new Server("幻境"); Server s2 = new Server("云图"); //4个观察者 Client c1 = new Client("大佬", 1); Client c2 = new Client("萌新", 2); Client c3 = new Client("菜鸟", 3); Client c4 = new Client("咸鱼", 4); //将4个观察者分别注册到两个被观察者上 s1.addObserver(c1); s1.addObserver(c2); s2.addObserver(c3); s2.addObserver(c4); message = Message.newBuilder().setTitle("欢迎") .setContent("欢迎关注 &lt;幻境云图&gt;") .build(); //消息变化后 将被观察者设置为已变化状态 s1.setChanged(); s2.setChanged(); //发送消息 s1.notifyObservers(message); s2.notifyObservers(message); //再次发送消息无效 因为change=false s1.notifyObservers(message); s2.notifyObservers(message); &#125;&#125;//输出2号萌新收到&lt;幻境&gt;推送的消息：Message&#123;title='欢迎', content='欢迎关注 &lt;幻境云图&gt;'&#125;1号大佬收到&lt;幻境&gt;推送的消息：Message&#123;title='欢迎', content='欢迎关注 &lt;幻境云图&gt;'&#125;4号咸鱼收到&lt;云图&gt;推送的消息：Message&#123;title='欢迎', content='欢迎关注 &lt;幻境云图&gt;'&#125;3号菜鸟收到&lt;云图&gt;推送的消息：Message&#123;title='欢迎', content='欢迎关注 &lt;幻境云图&gt;'&#125; 3. 总结优点： 1.降低重复代码，使得代码更清晰、更易读、更易扩展 2.解耦，使得代码可维护性更好，修改代码的时候可以尽量少改地方 应用场景： 1.对一个对象状态的更新需要其他对象同步更新 2.对象仅需要将自己的更新通知给其他对象而不需要知道其他对象的细节，如消息推送. 观察者模式在Java中的应用及解读 JDK是有直接支持观察者模式的，就是java.util.Observer这个接口： 12345678910111213public interface Observer &#123; /** * This method is called whenever the observed object is changed. An * application calls an &lt;tt&gt;Observable&lt;/tt&gt; object's * &lt;code&gt;notifyObservers&lt;/code&gt; method to have all the object's * observers notified of the change. * * @param o the observable object. * @param arg an argument passed to the &lt;code&gt;notifyObservers&lt;/code&gt; * method. */ void update(Observable o, Object arg);&#125; 这就是观察者的接口，定义的观察者只需要实现这个接口就可以了。update()方法，被观察者对象的状态发生变化时，被观察者的notifyObservers()方法就会调用这个方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Observable &#123; private boolean changed = false; private Vector&lt;Observer&gt; obs; public Observable() &#123; obs = new Vector&lt;&gt;(); &#125; public synchronized void addObserver(Observer o) &#123; if (o == null) throw new NullPointerException(); if (!obs.contains(o)) &#123; obs.addElement(o); &#125; &#125; public synchronized void deleteObserver(Observer o) &#123; obs.removeElement(o); &#125; public void notifyObservers() &#123; notifyObservers(null); &#125; public void notifyObservers(Object arg) &#123; Object[] arrLocal; synchronized (this) &#123; if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; public synchronized void deleteObservers() &#123; obs.removeAllElements(); &#125; protected synchronized void setChanged() &#123; changed = true; &#125; protected synchronized void clearChanged() &#123; changed = false; &#125; public synchronized boolean hasChanged() &#123; return changed; &#125; public synchronized int countObservers() &#123; return obs.size(); &#125;&#125; 这是被观察者的父类，也就是主题对象，用的Vector集合,方法也加了synchronized关键字，是多线程安全的。 4. 参考https://www.cnblogs.com/xrq730/p/4908686.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(十一)---模板方法模式]]></title>
    <url>%2Fposts%2F57ae709c.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的模板方法模式，并结合实例描述了模板方法模式的具体实现和优缺点分析。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介模板方法模式是类的行为模式。 准备一个抽象类，将部分逻辑以具体方法以及具体构造函数的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。 这就是模板方法模式的用意。 抽象模板(Abstract Template)角色有如下责任： 定义了一个或多个抽象操作，以便让子类实现。这些抽象操作叫做基本操作，它们是一个顶级逻辑的组成步骤。 定义并实现了一个模板方法。这个模板方法一般是一个具体方法，它给出了一个顶级逻辑的骨架，而逻辑的组成步骤在相应的抽象操作中，推迟到子类实现。顶级逻辑也有可能调用一些具体方法。 具体模板(Concrete Template)角色又如下责任： 实现父类所定义的一个或多个抽象方法，它们是一个顶级逻辑的组成步骤。 每一个抽象模板角色都可以有任意多个具体模板角色与之对应，而每一个具体模板角色都可以给出这些抽象方法（也就是顶级逻辑的组成步骤）的不同实现，从而使得顶级逻辑的实现各不相同。 2. 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150假设泡茶喝咖啡都需有四个步骤：1.烧水 2.泡茶/冲咖啡 3.倒入杯子 4.添加调味品那么可以写一个抽象类，因为大多数饮料都可以看成这四个步骤。然后烧水和倒入杯子这两个步骤都是相同的，那么在抽象类中可以直接实现，然后其他特殊操作则由子类具体实现。/** * 模板方法模式 * 抽象模板角色 * * @author illusoryCloud */public abstract class BaseCreatDrink &#123; /** * 按顺序调用其他方法 */ public void doCreate() &#123; boilWater(); brew(); pourInCup(); if (isNeedCondiments()) &#123; addCondiments(); &#125; &#125; /** * 烧开水 * 通用的方法 直接实现 */ private void boilWater() &#123; System.out.println("烧开水~"); &#125; /** * 特殊操作，在子类中具体实现 */ public abstract void brew(); /** * 倒入杯中 * 通用的方法 直接实现 */ private void pourInCup() &#123; System.out.println("倒入杯中~"); &#125; /** * 添加调味品 茶里面加柠檬 咖啡中加糖等等 * 特殊操作 * 具体由子类实现 */ public abstract void addCondiments(); /** * 钩子方法，决定某些算法步骤是否挂钩在算法中 * 子类可以重写该类来改变算法或者逻辑 */ public boolean isNeedCondiments() &#123; return true; &#125;&#125;/** * 具体模板角色 * 纯茶 * * @author illusoryCloud */public class CreatTea extends BaseCreatDrink &#123; @Override public void brew() &#123; System.out.println("泡茶~"); &#125; @Override public void addCondiments() &#123; System.out.println("加柠檬~"); &#125;&#125;/** * 具体模板角色 * 茶 * * @author illusoryCloud */public class CreatPureTea extends BaseCreatDrink &#123; @Override public void brew() &#123; System.out.println("泡茶~"); &#125; @Override public void addCondiments() &#123; System.out.println("加柠檬~"); &#125; /** * 通过重写钩子方法来改变算法 * 返回true则添加调味品 * 返回false则不加 * 默认为true * * @return isNeedCondiments */ @Override public boolean isNeedCondiments() &#123; return false; &#125;&#125;/** * 具体模板角色 * 咖啡 * * @author illusoryCloud */public class CreatCoffee extends BaseCreatDrink &#123; @Override public void brew() &#123; System.out.println("冲咖啡~"); &#125; @Override public void addCondiments() &#123; System.out.println("加糖~"); &#125;&#125;/** * 模板方法模式 测试类 * * @author illusoryCloud */public class TemplateTest &#123; @Test public void templateTest() &#123; System.out.println("-------茶-------"); CreatTea tea = new CreatTea(); tea.doCreate(); System.out.println("-------咖啡-------"); CreatCoffee coffee = new CreatCoffee(); coffee.doCreate(); System.out.println("-------纯茶-------"); CreatPureTea pureTea = new CreatPureTea(); pureTea.doCreate(); &#125;&#125;//输出往锅里加的是白菜~炒啊炒啊炒~菜炒好了，起锅~往锅里加的是肉~炒啊炒啊炒~菜炒好了，起锅~ 3. 总结模板方法模式在Java中的应用 最常见的就是Servlet了。 HttpServlet担任抽象模板角色 模板方法：由service()方法担任。 基本方法：由doPost()、doGet()等方法担任。 MyServlet担任具体模板角色 自定义的servlet置换掉了父类HttpServlet中七个基本方法中的其中两个，分别是doGet()和doPost()。 4. 参考https://www.cnblogs.com/qiumingcheng/p/5219664.html https://www.cnblogs.com/yanlong300/p/8446261.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(十)---策略模式]]></title>
    <url>%2Fposts%2Fa7982bdc.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的策略模式，并结合实例描述了策略模式的具体实现和策略模式的优缺点分析。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介 策略模式是对算法的包装 策略模式定义了一系列的算法，并将每一个算法封装起来，而且它们还可以相互替换。策略模式让算法独立于使用它的客户而独立变化。 这个模式涉及到三个角色： ● 环境(Context)角色：持有一个Strategy的引用。 ● 抽象策略(Strategy)角色：这是一个抽象角色，通常由一个接口或抽象类实现。此角色给出所有的具体策略类所需的接口。 ● 具体策略(ConcreteStrategy)角色：包装了相关的算法或行为。 2. 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124/** * 策略模式 抽象策略角色 * 定义一个两个整数间的计算方法 * * @author illusoryCloud */public interface Strategy &#123; /** * 两个整数间的计算方法 * * @param a * @param b * @return */ int calculate(int a, int b);&#125;/** * 策略模式 具体策略角色 * 加法 * * @author illusoryCloud */public class AddStrategy implements Strategy &#123; @Override public int calculate(int a, int b) &#123; return a + b; &#125;&#125;/** * 策略模式 具体策略角色 * 减法 * * @author illusoryCloud */public class SubtractionStrategy implements Strategy &#123; @Override public int calculate(int a, int b) &#123; return a - b; &#125;&#125;/** * 策略模式 具体策略角色 * 乘法 * * @author illusoryCloud */public class MultiplyStrategy implements Strategy &#123; @Override public int calculate(int a, int b) &#123; return a * b; &#125;&#125;/** * 策略模式 具体策略角色 * 除法 * * @author illusoryCloud */public class DivisionStrategy implements Strategy &#123; @Override public int calculate(int a, int b) &#123; if (b != 0) &#123; return a / b; &#125; else &#123; throw new RuntimeException("除数不能为零"); &#125; &#125;&#125;/** * 策略模式 环境角色 * * @author illusoryCloud */public class Context &#123; /** * 持有Strategy的引用 */ private Strategy strategy; public Context(Strategy strategy) &#123; super(); this.strategy = strategy; &#125; public Strategy getStrategy() &#123; return strategy; &#125; /** * set方法可以完成策略更换 */ public void setStrategy(Strategy strategy) &#123; this.strategy = strategy; &#125; public int calculate(int a, int b) &#123; return strategy.calculate(a, b); &#125;&#125;/** * 策略模式 测试类 * * @author illusoryCloud */public class StrategyTest &#123; @Test public void strategyTest() &#123; //加法 Context context = new Context(new AddStrategy()); System.out.println(context.calculate(5, 5)); //减法 Context context2 = new Context(new SubtractionStrategy()); System.out.println(context2.calculate(5, 5)); //乘法 Context context3 = new Context(new MultiplyStrategy()); System.out.println(context3.calculate(5, 5)); //除法 Context context4 = new Context(new DivisionStrategy()); System.out.println(context4.calculate(5, 5)); &#125;&#125; 3. 总结策略模式的重心不是如何实现算法（就如同工厂模式的重心不是工厂中如何产生具体子类一样），而是如何组织、调用这些算法，从而让程序结构更灵活，具有更好的维护性和扩展性。 策略模式与状态模式 策略模式与状态模式及其相似，但是二者有其内在的差别，策略模式将具体策略类暴露出去，调用者需要具体明白每个策略的不同之处以便正确使用。而状态模式状态的改变是由其内部条件来改变的，与外界无关，二者在思想上有本质区别。 优点 1.让代码更优雅，避免了多重条件if…else语句。 2.策略模式提供了管理相关算法簇的办法，恰当使用继承可以把公共代码移到父类，从而避免了代码重复。 缺点 1.客户端必须知道所有的策略类，并自行决定使用 哪一个策略，这意味着客户端必须理解这些算法的区别，以便选择恰当的算法 2.如果备选策略很多，对象的数据会很多 4. 参考https://www.cnblogs.com/xrq730/p/4906313.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[枚举式单例模式与序列化]]></title>
    <url>%2Fposts%2Fdff2f393.html</url>
    <content type="text"><![CDATA[本文主要记录了单例模式中的枚举式写法和序列化与反序列化安全问题，通过分析源码说明了为什么枚举式单例是序列化安全的。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 问题Java中单例模式大概有五种：饿汉式、静态内部类、懒汉式、双重校验锁、枚举式。 静态内部类和双重校验锁已经这么优秀了为什么还要有第五种枚举式呢？ 因为前面4种都存在一个序列化和反序列化时的安全问题。将单例对象序列化后，在反序列化时会重新创建一个单例对象，违背了单例模式的初衷。而枚举式单例则没有这个问题。更多Java单例模式信息请阅读:Java设计模式(一)—单例模式。 2. 分析序列化可能会破坏单例模式，比较每次反序列化一个序列化的对象实例时都会创建一个新的实例,枚举类单例可以解决该问题。枚举序列化是由jvm保证的，每一个枚举类型和定义的枚举变量在JVM中都是唯一的，在枚举类型的序列化和反序列化上，Java做了特殊的规定：在序列化时Java仅仅是将枚举对象的name属性输出到结果中，反序列化的时候则是通过java.lang.Enum的valueOf()方法来根据名字查找枚举对象。同时，编译器是不允许任何对这种序列化机制的定制的并禁用了writeObject、readObject、readObjectNoData、writeReplace和readResolve等方法，从而保证了枚举实例的唯一性. Enum类的valueOf方法: 12345678910public static &lt;T extends Enum&lt;T&gt;&gt; T valueOf(Class&lt;T&gt; enumType, String name) &#123; T result = enumType.enumConstantDirectory().get(name); if (result != null) return result; if (name == null) throw new NullPointerException("Name is null"); throw new IllegalArgumentException( "No enum constant " + enumType.getCanonicalName() + "." + name); &#125; 实际上通过调用enumType(Class对象的引用)的enumConstantDirectory()方法获取到的是一个Map集合，在该集合中存放了以枚举name为key和以枚举实例变量为value的Key&amp;Value数据，因此通过name的值就可以获取到枚举实例. enumConstantDirectory()方法： 12345678910111213141516Map&lt;String, T&gt; enumConstantDirectory() &#123; if (enumConstantDirectory == null) &#123; //getEnumConstantsShared最终通过反射调用枚举类的values方法 T[] universe = getEnumConstantsShared(); if (universe == null) throw new IllegalArgumentException( getName() + " is not an enum type"); Map&lt;String, T&gt; m = new HashMap&lt;&gt;(2 * universe.length); //map存放了当前enum类的所有枚举实例变量，以name为key值 for (T constant : universe) m.put(((Enum&lt;?&gt;)constant).name(), constant); enumConstantDirectory = m; &#125; return enumConstantDirectory; &#125; private volatile transient Map&lt;String, T&gt; enumConstantDirectory = null; 到这里我们也就可以看出枚举序列化确实不会重新创建新实例，jvm保证了每个枚举实例变量的唯一性。 通过反射获取构造器并创建枚举 : 123456public static void main(String[] args) throws IllegalAccessException, InvocationTargetException, InstantiationException, NoSuchMethodException &#123; Constructor&lt;SingletonEnum&gt; constructor=SingletonEnum.class.getDeclaredConstructor(String.class,int.class); constructor.setAccessible(true); //创建枚举 SingletonEnum singleton=constructor.newInstance("otherInstance",9); &#125; 执行报错 12345678Exception in thread "main" java.lang.IllegalArgumentException: Cannot reflectively create enum objects at java.lang.reflect.Constructor.newInstance(Constructor.java:417) at zejian.SingletonEnum.main(SingletonEnum.java:38) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) 显然不能使用反射创建枚举类，这是为什么呢？在newInstance()方法中找找原因。 newInstance()方法： 123456789101112131415161718192021public T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, null, modifiers); &#125; &#125; //这里判断Modifier.ENUM是不是枚举修饰符，如果是就抛异常 if ((clazz.getModifiers() &amp; Modifier.ENUM) != 0) throw new IllegalArgumentException("Cannot reflectively create enum objects"); ConstructorAccessor ca = constructorAccessor; // read volatile if (ca == null) &#123; ca = acquireConstructorAccessor(); &#125; @SuppressWarnings("unchecked") T inst = (T) ca.newInstance(initargs); return inst; &#125; 源码显示确实无法使用反射创建枚举实例，也就是说明了创建枚举实例只有编译器能够做到而已。 3. 结论显然枚举单例模式确实是很不错的选择，因此我们推荐使用它。 不过由于使用枚举时占用的内存常常是静态变量的两倍还多，因此android官方在内存优化方面给出的建议是尽量避免在android中使用enum。 但是不管如何，关于单例，我们总是应该记住：线程安全，延迟加载，序列化与反序列化安全，反射安全是很重重要的。 4. 参考https://blog.csdn.net/javazejian/article/details/71333103#%E6%9E%9A%E4%B8%BE%E4%B8%8E%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(九)---享元模式]]></title>
    <url>%2Fposts%2F34e634e7.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的享元模式，并结合实例描述了享元模式的具体实现，具体优缺点和单例模式的对比。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 享元模式介绍享元模式：“享”就是分享之意，指一物被众人共享，而这也正是该模式的终旨所在。 享元模式有点类似于单例模式，都是只生成一个对象来被共享使用。存储这些共享实例对象的地方称为享元池 。享元对象能做到共享的关键是区分了内部状态(Intrinsic State)和外部状态(Extrinsic State)。 内部状态是存储在享元对象内部并且不会随环境改变而改变的状态，内部状态可以共享。如围棋中的的黑棋白棋，不会随外部环境的变化而变化，无论在任何环境下黑棋始终是黑棋。 外部状态是随环境改变而改变的、不可以共享的状态。享元对象的外部状态通常由客户端保存，并在享元对象被创建之后，需要使用的时候再传入到享元对象内部。比如每颗棋子的位置是不同的。 围棋中的黑棋和白棋可以是共享的对象，不用每次都创建一个新的对象。这样就只需要创建黑棋和白棋两个对象了。颜色是不会变得，所以是内部状态。落下得位置是随机的，所以作为外部状态。 2. 单纯享元模式 在单纯的享元模式中，所有的享元对象都是可以共享的。 单纯享元模式所涉及到的角色如下： ● 抽象享元(Flyweight)角色 ：给出一个抽象接口，以规定出所有具体享元角色需要实现的方法。 ● 具体享元(ConcreteFlyweight)角色：实现抽象享元角色所规定出的接口。如果有内蕴状态的话，必须负责为内蕴状态提供存储空间。 ● 享元工厂(FlyweightFactory)角色 ：本角色负责创建和管理享元角色。本角色必须保证享元对象可以被系统适当地共享。当一个客户端对象调用一个享元对象的时候，享元工厂角色会检查系统中是否已经有一个符合要求的享元对象。如果已经有了，享元工厂角色就应当提供这个已有的享元对象；如果系统中没有一个适当的享元对象的话，享元工厂角色就应当创建一个合适的享元对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112/** * 单纯享元模式 抽象享元角色 * * @author illusoryCloud */public interface Ball &#123; /** * 简单的show方法 * 根据传入的参数(外蕴状态)不同而产生不同的表现 * * @param color 外蕴状态 */ void show(String color);&#125;/** * 单纯享元模式 具体享元角色 * 内蕴状态为type 即球的类型 由构造方法传入 * 外蕴状态为color 即球的颜色 作为show()方法的参数传入 * * @author illusoryCloud */public class ConcreteBall implements Ball &#123; private String type; public ConcreteBall(String type) &#123; this.type = type; &#125; @Override public void show(String color) &#123; System.out.println("这是一个：" + color + "的" + type); &#125;&#125; /** * 单纯享元模式 享元工厂角色 * * @author illusoryCloud */public class BallFactory &#123; /** * 将对象存在map中 */ private static Map&lt;String, Ball&gt; factory = new HashMap&lt;&gt;(); /** * 获取单纯享元角色 * * @param type 内蕴状态 * @return 具体享元角色 */ public Ball getBall(String type) &#123; Ball ball = factory.get(type); if (ball == null) &#123; //如果对象不存在则创建一个新的对象 ball = new ConcreteBall(type); //把这个新的Flyweight对象添加到缓存中 factory.put(type, ball); &#125; return ball; &#125; /** * 静态内部类 单例模式 */ private BallFactory() &#123; &#125; private static class SingletonHolder &#123; private static final BallFactory INSTANCE = new BallFactory(); &#125; public static BallFactory getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125;/** * 单纯享元模式 测试类 * * @author illusoryCloud */public class PureTest &#123; /** * 当客户端需要单纯享元对象的时候，需要调用享元工厂的factory()方法， * 并传入所需的单纯享元对象的内蕴状态，由工厂方法产生所需要的享元对象。 */ @Test public void flyWeightTest() &#123; BallFactory ballFactory = BallFactory.getInstance(); Ball basketball = ballFactory.getBall("篮球"); Ball football = ballFactory.getBall("足球"); basketball.show("红色"); basketball.show("黄色"); football.show("黑色"); football.show("白色"); Ball basketball2 = ballFactory.getBall("篮球"); Ball football2 = ballFactory.getBall("足球"); //true 都是同一个对象 System.out.println(basketball.equals(basketball2)); //true System.out.println(football.equals(football2)); &#125;&#125;//输出这是一个：红色的篮球这是一个：黄色的篮球这是一个：黑色的足球这是一个：白色的足球truetrue 3. 复合享元模式 在单纯享元模式中，所有的享元对象都是单纯享元对象，也就是说都是可以直接共享的。还有一种较为复杂的情况，将一些单纯享元使用合成模式加以复合，形成复合享元对象。这样的复合享元对象本身不能共享，但是它们可以分解成单纯享元对象，而后者则可以共享。 复合享元角色所涉及到的角色如下： ● 抽象享元(Flyweight)角色 ：给出一个抽象接口，以规定出所有具体享元角色需要实现的方法。 ● 具体享元(ConcreteFlyweight)角色：实现抽象享元角色所规定出的接口。如果有内蕴状态的话，必须负责为内蕴状态提供存储空间。 ● 复合享元(ConcreteCompositeFlyweight)角色 ：复合享元角色所代表的对象是不可以共享的，但是一个复合享元对象可以分解成为多个本身是单纯享元对象的组合。复合享元角色又称作不可共享的享元对象。 ● 享元工厂(FlyweightFactory)角色 ：本角 色负责创建和管理享元角色。本角色必须保证享元对象可以被系统适当地共享。当一个客户端对象调用一个享元对象的时候，享元工厂角色会检查系统中是否已经有 一个符合要求的享元对象。如果已经有了，享元工厂角色就应当提供这个已有的享元对象；如果系统中没有一个适当的享元对象的话，享元工厂角色就应当创建一个 合适的享元对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122/** * 复合享元模式 复合享元角色 * * @author illusoryCloud */public class CompositeBall implements Ball &#123; /** * 复合享元角色内部包含多个单纯享元角色 */ private Map&lt;String, Ball&gt; composite = new HashMap&lt;&gt;(); /** * 增加一个新的单纯享元对象到集合中 */ public void add(String type, Ball ball) &#123; composite.put(type, ball); &#125; /** * 遍历的方式挨个调用内部单纯享元角色的show方法 * * @param color 外蕴状态 */ @Override public void show(String color) &#123; Set&lt;String&gt; strings = composite.keySet(); for (String type : strings) &#123; Ball ball = composite.get(type); ball.show(color); &#125; &#125;&#125;/** * 复合享元模式 复合工厂角色 * * @author illusoryCloud */public class CompositeFactory &#123; private Map&lt;String, Ball&gt; factory = new HashMap&lt;String, Ball&gt;(); /** * 获取复合享元 * * @param types 类型集合 * @return 复合享元对象 包含多个单纯享元对象 */ public Ball getComposite(List&lt;String&gt; types) &#123; CompositeBall composteBall = new CompositeBall(); for (String type : types) &#123; composteBall.add(type, getPure(type)); &#125; return composteBall; &#125; /** * 获取单纯享元角色 * * @param type 内蕴状态 * @return 具体享元角色 */ public Ball getPure(String type) &#123; Ball ball = factory.get(type); if (ball == null) &#123; //如果对象不存在则创建一个新的对象 ball = new ConcreteBall(type); //把这个新的Flyweight对象添加到缓存中 factory.put(type, ball); &#125; return ball; &#125; /** * 静态内部类 单例模式 */ private CompositeFactory() &#123; &#125; private static class SingletonHolder &#123; private static final CompositeFactory INSTANCE = new CompositeFactory(); &#125; public static CompositeFactory getInstance() &#123; return CompositeFactory.SingletonHolder.INSTANCE; &#125;&#125;/** * 单纯享元模式 测试类 * * @author illusoryCloud */public class CompositeTest &#123; /** * 当客户端需要单纯享元对象的时候，需要调用享元工厂的factory()方法， * 并传入所需的单纯享元对象的内蕴状态，由工厂方法产生所需要的享元对象。 */ @Test public void flyWeightTest() &#123; CompositeFactory compositeFactory = CompositeFactory.getInstance(); Ball pure = compositeFactory.getPure("篮球"); Ball pure2 = compositeFactory.getPure("篮球"); pure.show("红色"); List&lt;String&gt; types = Arrays.asList("篮球", "足球", "排球"); Ball composite = compositeFactory.getComposite(types); Ball composite2 = compositeFactory.getComposite(types); composite.show("蓝色"); //false 复合享元角色不相同 System.out.println(composite.equals(composite2)); //true 单纯享元角色相同 System.out.println(pure.equals(pure2)); &#125;&#125;//输出这是一个：红色的篮球这是一个：蓝色的足球这是一个：蓝色的篮球这是一个：蓝色的排球falsetrue 4. 总结享元模式的核心在于享元工厂类，享元工厂类的作用在于提供一个用于存储享元对象的享元池，用户需要对象时，首先从享元池中获取，如果享元池中不存在，则创建一个新的享元对象返回给用户，并在享元池中保存该新增对象。 优点： 节约系统的开销，可以少创建对象。外部状态不会影响内部状态，可以在不同环境下进行共享哦。缺点： 享元模式使逻辑变得更加复杂，需要将享元对象分出内部状态和外部状态。 并且为了使对象可以共享，外部状态在很多情况下是必须有的，当读取外部状态时明显会增加运行时间。 享元模式使用的场景： 当我们项目中创建很多对象，而且这些对象存在许多相同模块，这时，我们可以将这些相同的模块提取出来采用享元模式生成单一对象，再使用这个对象与之前的诸多对象进行配合使用，这样无疑会节省很多空间。 与单例模式的区别： 享元模式的目的是共享，避免多次创建耗费资源，减少不会要额内存消耗 。 单例模式的目的是限制创建多个对象以避免冲突等 。 5. 参考http://blog.csdn.net/lovelion&gt; https://blog.csdn.net/Hmily_hui/article/details/80917975]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(八)---外观模式]]></title>
    <url>%2Fposts%2F22a51705.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的外观模式，并结合实例描述了 模式的具体实现和性能分析测试。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介 它通过引入一个外观角色来简化客户端与子系统之间的交互，为复杂的子系统调用提供一个统一的入口，降低子系统与客户端的耦合度，且客户端调用非常方便。 外观模式结构： SubSystem: 子系统角色。表示一个系统的子系统或模块。 Facade: 外观角色，客户端通过操作外观角色从而达到控制子系统角色的目的。对于客户端来说，外观角色好比一道屏障，对客户端屏蔽了子系统的具体实现。 2. 具体实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495/** * 子系统角色类 * 电脑CPU * * @author illusoryCloud */public class CPU &#123; public void startUp()&#123; System.out.println("cpu is startUp..."); &#125; public void shutDown()&#123; System.out.println("cpu is shutDown..."); &#125;&#125;/** * 子系统角色类 * 电脑硬盘 * * @author illusoryCloud */public class Disk &#123; public void startUp() &#123; System.out.println("disk is startUp..."); &#125; public void shutDown() &#123; System.out.println("disk is shutDown..."); &#125;&#125;/** * 子系统角色类 * 电脑内存 * * @author illusoryCloud */public class Memory &#123; public void startUp() &#123; System.out.println("memory is startUp..."); &#125; public void shutDown() &#123; System.out.println("memory is shutDown..."); &#125;&#125;/** * 外观角色 * 电脑 * 用户通过操作当前类即可达到操作所有子系统的目的 * * @author illusoryCloud */public class Computer &#123; private CPU cpu; private Disk disk; private Memory memory; public Computer() &#123; cpu = new CPU(); disk = new Disk(); memory = new Memory(); &#125; public void startUp() &#123; cpu.startUp(); disk.startUp(); memory.startUp(); &#125; public void shutDown() &#123; cpu.shutDown(); disk.shutDown(); memory.shutDown(); &#125;&#125;/** * 外观模式 测试类 * * @author illusoryCloud */public class FacedeTest &#123; @Test public void facedeTest() &#123; Computer computer = new Computer(); computer.startUp(); System.out.println("------------------"); computer.shutDown(); &#125;&#125; 3. 总结外观模式的优点 外观模式有如下几个优点： 1、松散耦合 外观模式松散了客户端和子系统的耦合关系，让子系统内部的模块能更容易扩展和维护 2、简单易用 客户端不需要了解系统内部的实现，也不需要和众多子系统内部的模块交互，只需要和外观类交互就可以了 3、更好地划分层次 通过合理使用Facade，可以帮助我们更好地划分层次。有些方法是系统对内的，有些方法是对外的，把需要暴露给外部的功能集中到Facade中，这样既方便客户端使用，也很好地隐藏了内部的细节 4. Tomcat中的外观模式Tomcat中有很多场景都使用到了外观模式，因为Tomcat中有很多不同的组件，每个组件需要相互通信，但又不能将自己内部数据过多地暴露给其他组件。用外观模式隔离数据是个很好的方法，比如Request上使用外观模式。 比如Servlet，doGet和doPost方法，参数类型是接口HttpServletRequest和接口HttpServletResponse，那么Tomcat中传递过来的真实类型到底是什么呢？ 在真正调用Servlet前，会经过很多Tomcat方法，传递给Tomcat的request和response的真正类型是一个Facade类。 Request类 123456public HttpServletRequest getRequest() &#123; if (facade == null) &#123; facade = new RequestFacade(this); &#125; return facade;&#125; Response类 123456public HttpServletResponse getResponse() &#123; if (facade == null) &#123; facade = new ResponseFacade(this); &#125; return (facade);&#125; 因为Request类中很多方法都是组件内部之间交互用的，比如setComet、setReuqestedSessionId等方法，这些方法并不对外公开，但又必须设置为public，因为还要和内部组件交互使用。最好的解决方法就是通过使用一个Facade类，屏蔽掉内部组件之间交互的方法，只提供外部程序要使用的方法。 如果不使用Facade，直接传递的是HttpServletRequest和HttpServletResponse，那么熟悉容器内部运作的开发者可以分别把ServletRequest和ServletResponse向下转型为HttpServletRequest和HttpServletResponse，这样就有安全性的问题了。 5. 参考https://www.cnblogs.com/xrq730/p/4908822.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(七)---代理模式]]></title>
    <url>%2Fposts%2Fae2a93bd.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的代理模式，并结合实例描述了各种代理模式的具体实现和对比。包括：JDK静态代理，JDK动态代理，cglib动态代理. Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介 给某一对象提供一个代理对象，并由代理对象控制对原对象的引用。 代理模式的结构 有些情况下，一个客户不想或者不能够直接引用一个对象，可以通过代理对象在客户端和目标对象之间起到中介作用。代理模式中的角色有： 1、抽象对象角色 声明了目标对象和代理对象的共同接口，这样一来在任何可以使用目标对象的地方都可以使用代理对象 2、目标对象角色 定义了代理对象所代表的目标对象 3、代理对象角色 代理对象内部含有目标对象的引用，从而可以在任何时候操作目标对象；代理对象提供一个与目标对象相同的接口，以便可以在任何时候替代目标对象 2. 静态代理123由程序员创建或特定工具自动生成源代码，也就是在编译时就已经将接口，被代理类，代理类等确定下来。在程序运行之前，代理类的.class文件就已经生成。代理类和被代理类必须实现同一个接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 抽象对象角色 * * @author illusoryCloud */public interface Human &#123; void work();&#125;/** * 目标对象角色 * * @author illusoryCloud */public class Singer implements Human &#123; @Override public void work() &#123; System.out.println("歌手在唱歌~"); &#125;&#125;/** * 代理对象角色 * * @author illusoryCloud */public class ProxyMan implements Human &#123; /** * 持有目标对象的引用 */ private Human human; /** * 通过构造方法注入 * * @param human 目标对象 */ public ProxyMan(Human human) &#123; this.human = human; &#125; @Override public void work() &#123; System.out.println("经纪人为歌手安排好时间~"); human.work(); System.out.println("经纪人为歌手联系下一场演出~"); &#125;&#125; /** * 静态代理模式 测试类 * * @author illusoryCloud */public class StaticProxyTest &#123; @Test public void staticProxyTest() &#123; Human singer = new ProxyMan(new Singer()); singer.work(); &#125;&#125; //输出结果经纪人为歌手安排好时间~歌手在唱歌~经纪人为歌手联系下一场演出~ 3. JDK动态代理 代理类在程序运行时创建的代理方式被成为动态代理。 1. 具体实现123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 回调方法 * * @author illusoryCloud */public class MyInvocationHandler implements InvocationHandler &#123; public static final String PROXY_METHOD = "work"; /** * 持有一个被代理对象的引用 */ private Human human; public MyInvocationHandler(Human human) &#123; this.human = human; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // 判断是否是需要代理的方法 if (PROXY_METHOD.equals(method.getName())) &#123; System.out.println("经纪人为歌手安排好时间~"); Object invoke = method.invoke(human, args); System.out.println("经纪人为歌手联系下一场演出~"); return invoke; &#125; else &#123; return null; &#125; &#125;&#125;/** * JDK动态代理 测试类 * * @author illusoryCloud */public class JDKProxyTest &#123; @Test public void JDKProxyTest() &#123; Singer singer = new Singer(); //参数1：类加载器 参数2：被代理类实现的接口 参数3：回调 由自己实现 Human human = (Human) Proxy.newProxyInstance(singer.getClass().getClassLoader() , singer.getClass().getInterfaces() , new MyInvocationHandler(singer)); human.work(); &#125;&#125; 2. InvocationHandlerInvocationHandler是一个接口，官方文档解释说，每个代理的实例都有一个与之关联的 InvocationHandler实现类，如果代理的方法被调用，那么代理便会通知和转发给内部的 InvocationHandler 实现类，由它决定处理。 1234public interface InvocationHandler &#123; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 接口内部只是一个 invoke() 方法，正是这个方法决定了怎么样处理代理传递过来的方法调用。对代理对象的增强就在这里进行。实现该接口 重写此方法 可以用匿名内部类或者直接用生成代理的那个类实现该接口。 方法参数 1.proxy 代理对象，可以使用反射获取代理对象proxy.getClass().getName() 2.method 代理对象调用的方法 3.args 调用的方法中的参数 因为Proxy动态产生的代理会调用InvocationHandler实现类，所以InvocationHandler是实际执行者。 3. 生成代理对象 Proxy.newProxyInstance(classLoader, interfaces, dynamicInvocationHandler); 方法参数 1.classLoader 类加载器,告诉虚拟机用哪个字节码加载器加载内存中创建出来的字节码文件 一般是application类加载器.(增强哪个对象就写哪个类的类加载器) 2.interfaces 字节码数组 告诉虚拟机内存中正在你被创建的字节码文件中应该有哪些方法(被代理类实现的所有接口的字节码数组 ) 3.一个InvocationHandler对象,表示的是当我这个动态代理对象在调用方法的时候，会关联到哪一个InvocationHandler对象上,告诉虚拟机字节码上的那些方法如何处理 （用户自定义增强操作等 写在实现InvocationHandler接口的那个类中. 小结： 1.通过 Proxy.newProxyInstance(classLoader, interfaces, dynamicInvocationHandler);生成代理对象 2.创建InvocationHandler接口实现类 重写invoke方法 实现具体的方法增强 3.调用对象的方法最后都是调用InvocationHandler接口的invoke方法 4.只能增强接口中有的方法 4. CGLIB动态代理JDK代理要求被代理的类必须实现接口，有很强的局限性。 而CGLIB动态代理则没有此类强制性要求。简单的说，CGLIB会让生成的代理类继承被代理类，并在代理类中对代理方法进行强化处理(前置处理、后置处理等)。在CGLIB底层，其实是借助了ASM这个非常强大的Java字节码生成框架。 cglib原理 通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。由于是通过子类来代理父类，因此不能代理被final字段修饰的方法。 需要引入两个jar包 cglib-3.2.10.jar //cglib包 asm-7.0.jar //底层用到的asm包 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 被代理类 没有实现接口 无法使用JDK动态代理 * * @author illusoryCloud */public class Dancer &#123; public void dance() &#123; System.out.println("跳舞者翩翩起舞~"); &#125;&#125;/** * @author illusoryCloud */public class MyMethodInterceptor implements MethodInterceptor &#123; public static final String PROXY_METHOD = "work"; /** * @param o cglib生成的代理对象 * @param method 目标对象的方法 * @param objects 方法入参 * @param methodProxy 代理方法 * @return 返回值 * @throws Throwable 异常 */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("经纪人为舞蹈演员安排好时间~"); //注意 这里是invokeSuper 若是invoke则会循环调用最终堆栈溢出 Object o1 = methodProxy.invokeSuper(o, objects); System.out.println("经纪人为舞蹈演员联系下一场演出~"); return o1; &#125;&#125;/** * CGLib动态代理 测试类 * * @author illusoryCloud */public class CglibProxyTest &#123; @Test public void cglibProxyTest()&#123; Enhancer enhancer=new Enhancer(); //设置父类 即被代理类 cglib是通过生成子类的方式来代理的 enhancer.setSuperclass(Dancer.class); //设置回调 enhancer.setCallback(new MyMethodInterceptor()); Dancer dancer= (Dancer) enhancer.create(); dancer.dance(); &#125;&#125; 5. 代理模式比较 代理方式 实现 优点 缺点 特点 JDK静态代理 代理类与委托类实现同一接口，并且在代理类中需要硬编码接口 实现简单，容易理解 代理类需要硬编码接口，在实际应用中可能会导致重复编码，浪费存储空间并且效率很低 好像没啥特点 JDK动态代理 代理类与委托类实现同一接口，主要是通过代理类实现InvocationHandler并重写invoke方法来进行动态代理的，在invoke方法中将对方法进行增强处理 不需要硬编码接口，代码复用率高 只能够代理实现了接口的委托类 底层使用反射机制进行方法的调用 CGLIB动态代理 代理类将委托类作为自己的父类并为其中的非final委托方法创建两个方法，一个是与委托方法签名相同的方法，它在方法中会通过super调用委托方法；另一个是代理类独有的方法。在代理方法中，它会判断是否存在实现了MethodInterceptor接口的对象，若存在则将调用intercept方法对委托方法进行代理 可以在运行时对类或者是接口进行增强操作，且委托类无需实现接口 不能对final类以及final方法进行代理 底层将方法全部存入一个数组中，通过数组索引直接进行方法调用 6. 代理模式与装饰器模式代理模式和装饰者模式有着很多的应用，这两者具有一定的相似性，都是通过一个新的对象封装原有的对象。二者之间的差异在于理模式是为了实现对象的控制，可能被代理的对象难以直接获得或者是不想暴露给客户端，而装饰者模式是继承的一种替代方案，在避免创建过多子类的情况下为被装饰者提供更多的功能。 装饰器模式应当为所装饰的对象提供增强功能，而代理模式对所代理对象的使用施加控制，并不提供对象本身的增强功能。 代理模式侧重于不能直接访问一个对象，只能通过代理来间接访问，比如对象在另外一台机器上，或者对象被持久化了，对象是受保护的。对象在另外一台机器上，其实就是rpc，感兴趣的可以看看dubbo的源码本地访问的其实就是远程对象的代理，只不过代理帮你做了访问这个对象之前和之后的很多事情，但是对使用者是透明的了。对象被持久化了，比如mybatis的mapperProxy。通过mapper文件自动生成代理类。第三种，对内核对象的访问。 装饰器模式是因为没法在编译期就确定一个对象的功能，需要运行时动态的给对象添加职责，所以只能把对象的功能拆成一一个个的小部分，动态组装，感兴趣的可以看看dubbo的源码，里面的mock，cluster，failover都是通过装饰器来实现的。因为这些功能是由使用者动态配置的。但是代理模式在编译期其实就已经确定了和代理对象的关系。 同时这两个设计模式是为了解决不同的问题而抽象总结出来的。是可以混用的。可以在代理的基础上在加一个装饰，也可以在装饰器的基础上在加一个代理。感兴趣的去看看dubbo源码，里面就是这么实现的。 7. 参考https://www.cnblogs.com/xrq730/p/4907999.html https://www.zhihu.com/question/41988550/answer/567925484]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(六)---装饰者模式]]></title>
    <url>%2Fposts%2F75903408.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的装饰者模式，并结合实例描述了装饰者模式的具体实现和优缺点分析。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介 在不必改变原类文件和使用继承的情况下，动态地扩展一个对象的功能。 它是通过创建一个包装对象，也就是装饰来包裹真实的对象。是继承关系的一个替代方案。 装饰模式由4种角色组成：（1）抽象构件（Component）角色：给出一个抽象接口，以规范准备接收附加职责的对象。（2）具体构件（Concrete Component）角色：定义一个将要接收附加职责的类。（3）装饰（Decorator）角色：持有一个构件（Component）对象的实例，并实现一个与抽象构件接口一致的接口，从外类来扩展Component类的功能，但对于Component类来说，是无需知道Decorato的存在的。（4）具体装饰（Concrete Decorator）角色：负责给构件对象添加上附加的职责。 2. 具体实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130/** * 抽象构件角色 * 人类 * * @author illusoryCloud */public interface Human &#123; void run();&#125;/** * 具体构件角色 * 男人 * * @author illusoryCloud */public class Man implements Human &#123; @Override public void run() &#123; System.out.println("男人跑得很快"); &#125;&#125;/** * 抽象装饰角色 * * @author illusoryCloud */public class Decorator implements Human &#123; /** * 持有一个具体构件的引用 */ private Human human; public Decorator(Human human) &#123; this.human = human; &#125; @Override public void run() &#123; human.run(); &#125;&#125;/** * 具体装饰角色 * 飞人 * * @author illusoryCloud */public class FlyMan extends Decorator &#123; public FlyMan(Human human) &#123; super(human); &#125; @Override public void run() &#123; super.run(); this.fly(); &#125; /** * 扩展功能 */ private void fly() &#123; System.out.println("变成飞人了，跑得更快了~"); &#125;&#125;/** * 具体装饰角色 * 强壮的男人 * * @author illusoryCloud */public class StrongMan extends Decorator &#123; public StrongMan(Human human) &#123; super(human); &#125; @Override public void run() &#123; super.run(); this.strong(); &#125; public void strong() &#123; System.out.println("变得强壮了，耐力提升了~"); &#125;&#125;/** * 装饰者模式 测试类 * * @author illusoryCloud */public class DecoratorTest &#123; @Test public void decoratorTest() &#123; //普通对象 Human man = new Man(); man.run(); System.out.println("--------------------"); //装饰后的对象 Human flyMan = new FlyMan(man); flyMan.run(); System.out.println("--------------------"); //装饰后的对象 Human strongMan = new StrongMan(man); strongMan.run(); System.out.println("--------------------"); //装饰后的对象再次装饰 Human strongFlyMan = new StrongMan(flyMan); strongFlyMan.run(); &#125;&#125; //输出男人在跑--------------------男人在跑变成飞人了，速度加快了~--------------------男人在跑变得强壮了，耐力提升了~--------------------男人在跑变成飞人了，速度加快了~变得强壮了，耐力提升了~ 3. 总结优点 1.装饰者模式可以提供比继承更多的灵活性。装饰器模式允许系统动态决定贴上一个需要的装饰，或者除掉一个不需要的装饰。继承关系是不同，继承关系是静态的，它在系统运行前就决定了。 2.通过使用不同的具体装饰器以及这些装饰类的排列组合，设计师可以创造出很多不同的行为组合。 缺点 由于使用装饰器模式，可以比使用继承关系需要较少数目的类。使用较少的类，当然使设计比较易于进行。但是另一方面，由于使用装饰器模式会产生比使用继承关系更多的对象，更多的对象会使得查错变得困难，特别是这些对象看上去都很像。 装饰者模式和代理模式对比 装饰者模式主要对功能进行扩展，代理模式主要是添加一些无关业务的功能，比如日志，验证等。 使用代理模式,代理和真实对象之间的关系在编译时就已经确定了,而装饰器者能够在运行时递归的被构造.(代理模式会在代理类中创建真实处理类的一个实例,所以可以确定代理和真实对象的关系,而装饰器模式是将原始对象作为一个参数传给装饰器类) 装饰模式：以对客户端透明的方式扩展对象的功能，是继承关系的一个替代方案；代理模式：给一个对象提供一个代理对象，并有代理对象来控制对原有对象的引用； 4. 装饰者模式在Java中的应用装饰器模式在Java体系中的经典应用是Java I/O 抽象构件角色:InputStream 具体构建角色:ByteArrayInputStream、FileInputStream、ObjectInputStream、PipedInputStream等 装饰角色；FilterInputStream –&gt;实现了InputStream内的所有抽象方法并且持有一个InputStream的引用 具体装饰角色:InflaterInputStream、BufferedInputStream、DataInputStream等 5. 参考https://www.cnblogs.com/xrq730/p/4908940.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(五)---适配器模式]]></title>
    <url>%2Fposts%2Ff444ac9.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式之适配器模式，并结合实例描述了适配器模式的具体实现和优缺点分析。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介 适配器模式将一个接口转换成客户希望的另外一个接口。它使得原来由于接口不兼容而不能在一起工作的那些类可以一起工作。 把一个类的接口变换成客户端所期待的另一种接口 用到的对象 Target —定义Client使用的与特定领域相关的接口。 Client —与符合Target接口的对象协同。 Adaptee —定义一个已经存在的接口，这个接口需要适配。 Adapter —对Adaptee的接口与Target接口进行适配 2. 类适配器模式原理： 通过继承来实现适配器功能。 当我们要访问的类A中没有我们想要的方法 ，却在另一个接口B中发现了合适的方法，但我们又不能改变类A。 在这种情况下，我们可以定义一个适配器p来进行中转，这个适配器p要继承我们访问类A，这样我们就能继续访问当前类A中的方法（虽然它目前不是我们的菜），然后再实现接口B，这样我们可以在适配器P中访问接口B的方法了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 目标类 * * @author illusoryCloud */public interface Target &#123; void Target();&#125;/** * 被适配类 * 只有Adaptee方法 但是目标接口要Target方法 * * @author illusoryCloud */public class Adaptee &#123; public void Adaptee() &#123; System.out.println("这是现有的方法"); &#125;&#125;/** * 适配器类 * 继承Adaptee类 使得此类保留了Adaptee方法 * 实现Target接口 使得此类同时也拥有Target方法 * 适配完成 * * @author illusoryCloud */public class Adapter extends Adaptee implements Target &#123; @Override public void Target() &#123; System.out.println("这是目标方法"); &#125;&#125;/** * 类适配器模式 测试类 * * @author illusoryCloud */public class ClassAdapterTest &#123; @Test public void classAdapterTest() &#123; //Target类型的对象 同时拥有Target()和Adaptee()方法 Target target = new Adapter(); //这是目标方法 target.Target(); //这是现有的方法 ((Adapter) target).Adaptee(); &#125;&#125; 3. 对象适配器模式原理 基本思路和类的适配器模式相同，只是将 Adapter 类作修改，这次不继承 Adaptee 类，而是持有 Adaptee 类的实例，以达到解决兼容性的问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243//-------Target和Adaptee与上面一样----------/** * 适配器类 持有Adaptee对象来代替继承Adaptee类 * 传入Adaptee对象 使得此类同样拥有Adaptee方法 * 实现Target接口 使得此类同时也拥有Target方法 * 适配完成 * * @author illusoryCloud */public class Adapter implements Target &#123; private Adaptee adaptee; public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; @Override public void Target() &#123; System.out.println("这是目标方法"); &#125; public void Adaptee() &#123; adaptee.Adaptee(); &#125;&#125;/** * 对象适配器模式 测试类 * * @author illusoryCloud */public class ObjectAdapterTest &#123; @Test public void objectAdapterTest() &#123; Target target = new Adapter(new Adaptee()); //这是目标方法 target.Target(); //这是现有的方法 ((Adapter) target).Adaptee(); &#125;&#125; 4. 总结适配器模式优点 1、有更好的复用性。系统需要使用现有的类，但此类接口不符合系统需要，通过适配器模式让这些功能得到很好的复用 2、有更好的扩展性。实现适配器，可以调用自己开发的功能 缺点 过多使用适配器会使得系统非常凌乱，明明调用的是A接口，内部却被适配成了B接口。因此除非必要，不推荐使用适配器，而是作为一种补救措施，条件允许的情况下推荐直接对系统重构。 适配器模式在JDK中的应用 InputStreamReader/OutputStreanWriter 创建InputStreamReader对象的时候必须在构造函数中传入一个InputStream实例，然后InputStreamReader的作用就是将InputStream适配到Reader。很显然，适配器就是InputStreamReader，源角色就是InputStream代表的实例对象，目标接口就是Reader类。 5. 参考https://www.cnblogs.com/xrq730/p/4906487.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(四)---原型模式]]></title>
    <url>%2Fposts%2F24b6c0e4.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的原型模式，并结合实例描述了原型模式的具体实现和应用场景，优缺点分析等。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介1.1 原型模式 原型模式的思想就是将一个对象作为原型，对其进行复制、克隆，产生一个和原对象类似的新对象。简单地说原型模式就是创建复杂对象的时候使用克隆手段来代替新建一个对象。当创建新的对象实例较为复杂时，使用原型模式可以简化对象的创建过程，通过一个已有实例可以提高新实例的创建效率。 原型模式主要包含如下三个角色： Prototype：抽象原型类。声明克隆自身的接口。 ConcretePrototype：具体原型类。实现克隆的具体操作。 Client：客户类。让一个原型克隆自身，从而获得一个新的对象。 1.2 Java中的克隆我们需要知道，Java中的对象克隆分为浅克隆和深克隆。 浅克隆：将一个对象克隆后，基本数据类型的变量都会重新创建，而引用类型，指向的还是原对象所指向的。 深克隆：将一个对象克隆后，不论是基本数据类型还有引用类型，都是重新创建的。 简单来说，就是深克隆进行了完全彻底的克隆，而浅克隆不彻底。 2. 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114//实现Cloneable接口浅克隆，Serializable接口深克隆/** * 构建的消息对象 * 普通对象 * * @author illusoryCloud */public class Message implements Serializable, Cloneable &#123; /** * 标题 */ private String Title; /** * 内容 */ private String Content; /** * 发送者 */ private User From; /** * 接收者 */ private User To; /** * 时间 */ private Date Time; /** * 浅克隆 * * @return * @throws CloneNotSupportedException */ @Override protected Object clone() throws CloneNotSupportedException &#123; try &#123; return super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 深克隆 * * @return Message对象 * @throws IOException * @throws ClassNotFoundException */ public Message deepClone() throws IOException, ClassNotFoundException &#123; // 写入当前对象的二进制流 ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); // 读出二进制流产生的新对象 ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return (Message) ois.readObject(); &#125; //省略Getter、Setter、toString、构造函数等 &#125;//User类 Message类中引用 /** * 用户类 被消息类引用 * 主类实现深克隆 则被引用类也得实现Serializable接口 * @author illusoryCloud */public class User implements Serializable &#123; private String name; private int age; //省略Getter、Setter、toString、构造函数等&#125;//测试 /** * 原型模式测试类 * * @author illusoryCloud */public class PrototypeTest &#123; @Test public void prototypeTest() &#123; User zhangsan = new User("张三", 22); User lisi = new User("李四", 23); Message message = new Message(); message.setTitle("hello"); message.setContent("how are you~"); message.setFrom(zhangsan); message.setTo(lisi); message.setTime(new Date()); Message cloneOne = null; Message cloneTwo = null; try &#123; cloneOne = (Message) message.clone(); cloneTwo = message.deepClone(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //false 克隆实现的是一个(和原对象相似的)新对象 System.out.println(message == cloneOne); //false System.out.println(message == cloneTwo); //true 浅克隆 引用对象指向的还是原对象 System.out.println(message.getFrom()==cloneOne.getFrom()); //false 深克隆 引用对象也重新创建 System.out.println(message.getFrom()==cloneTwo.getFrom()); &#125;&#125; 3. 总结为什么要用原型模式 通过复制已有的对象，可以简化对象的创建过程，提高创建对象的效率。 深克隆保存对象状态，实现撤销恢复功能。 缺点： 在实现深克隆时需要编写复杂的代码。 需要为每一个类写一个克隆方法，如果要深克隆，则类中的每一层对象的类都得支持深克隆，代码比较复杂。 应用场景 创建对象成本高。 当一个系统应该独立于它的产品创建、构成和表示时，要使用原型模式。 当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些。 原型模式在Java中的应用及解读 只要是实现了Cloneable接口的类都可以算是原型模式的应用，比如ArrayList。 1234567891011121314151617public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; ... public Object clone() &#123; try &#123; ArrayList&lt;E&gt; v = (ArrayList&lt;E&gt;) super.clone(); v.elementData = Arrays.copyOf(elementData, size); v.modCount = 0; return v; &#125; catch (CloneNotSupportedException e) &#123; // this shouldn't happen, since we are Cloneable throw new InternalError(); &#125; &#125; ...&#125; 程序中获取到了一个ArrayList的实例arrayList，我们完全可以通过调用arrayList.clone()方法获取到原ArrayList的拷贝。 4. 参考https://www.cnblogs.com/xrq730/p/4905907.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(三)---建造者模式]]></title>
    <url>%2Fposts%2F52453.html</url>
    <content type="text"><![CDATA[本文主要介绍了Java23种设计模式中的建造者模式，并结合实例描述了建造者模式的具体实现和优缺点及建造者模式和工厂模式的差别分析等。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介 建造者模式是将一个复杂的对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。。 建造者模式通常包括下面几个角色： （1） Builder：给出一个抽象接口，以规范产品对象的各个组成成分的建造。这个接口规定要实现复杂对象的哪些部分的创建，并不涉及具体的对象部件的创建。 （2） ConcreteBuilder：实现Builder接口，针对不同的商业逻辑，具体化复杂对象的各部分的创建。 在建造过程完成后，提供产品的实例。 （3）Director：调用具体建造者来创建复杂对象的各个部分，在指导者中不涉及具体产品的信息，只负责保证对象各部分完整创建或按某种顺序创建。 （4）Product：要创建的复杂对象 2. 实现2.1 常见写法以创建一个Person为例： Product（要创建的对象）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package builder.first;import java.util.Date;/** * 构建的消息对象 * 普通对象 * * @author illusoryCloud */public class Message &#123; /** * 标题 */ private String title; /** * 内容 */ private String content; /** * 发送者 */ private String from; /** * 接收者 */ private String to; /** * 时间 */ private Date time; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public String getFrom() &#123; return from; &#125; public void setFrom(String from) &#123; this.from = from; &#125; public String getTo() &#123; return to; &#125; public void setTo(String to) &#123; this.to = to; &#125; public Date getTime() &#123; return time; &#125; public void setTime(Date time) &#123; this.time = time; &#125; @Override public String toString() &#123; return "Message&#123;" + "title='" + title + '\'' + ", content='" + content + '\'' + ", from='" + from + '\'' + ", to='" + to + '\'' + ", time=" + time + '&#125;'; &#125;&#125; Builder（给出一个抽象接口，以规范产品对象的各个组成成分的建造 ） 123456789101112/** * Builder接口 建造对象的标准 */public interface Builder &#123; void setTitle(); void setContent(); void setFrom(); void setTo(); void setTime(); Message build();&#125; ConcreteBuilder（实现Builder接口，针对不同的商业逻辑，具体化复杂对象的各部分的创建） 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 具体的建造对象类 实现了Builder接口 * 可以根据不同需求有不同的实现 * * @author illusoryCloud */public class CommonMessageBuilder implements Builder &#123; private Message message; public CommonMessageBuilder() &#123; this.message = new Message(); &#125; @Override public void setTitle() &#123; message.setTitle("常见的标题"); &#125; @Override public void setContent() &#123; message.setContent("普通的内容"); &#125; @Override public void setFrom() &#123; message.setFrom("未知的发送者"); &#125; @Override public void setTo() &#123; message.setTo("未知的接收者"); &#125; @Override public void setTime() &#123; message.setTime(new Date()); &#125; @Override public Message build() &#123; return this.message; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 具体的建造对象类 实现了Builder接口 * 可以根据不同需求有不同的实现 * * @author illusoryCloud */public class OthersMessageBuilder implements Builder &#123; private Message message; public OthersMessageBuilder() &#123; this.message = new Message(); &#125; @Override public void setTitle() &#123; message.setTitle("不寻常的标题"); &#125; @Override public void setContent() &#123; message.setContent("奇怪的内容"); &#125; @Override public void setFrom() &#123; message.setFrom("神秘的发送者"); &#125; @Override public void setTo() &#123; message.setTo("诡异的接收者"); &#125; @Override public void setTime() &#123; message.setTime(new Date()); &#125; @Override public Message build() &#123; return this.message; &#125;&#125; Director（调用具体建造者来创建复杂对象的各个部分，在指导者中不涉及具体产品的信息，只负责保证对象各部分完整创建 ） 12345678910111213141516171819/** 指导者 *只负责保证对象各部分完整创建 * @author illusoryCloud */public class Dreator &#123; /** * * @param builder 参数是只要实现了Builder接口的类都可以 * @return */ public Message createMessage(Builder builder) &#123; builder.setTitle(); builder.setContent(); builder.setFrom(); builder.setTo(); builder.setTime(); return builder.build(); &#125;&#125; 测试 123456789public class Test &#123; @org.junit.jupiter.api.Test public void testBuilder() &#123; Message commonMessage = new Dreator().createMessage(new CommonMessageBuilder()); Message othersMessage = new Dreator().createMessage(new OthersMessageBuilder()); System.out.println(commonMessage); System.out.println(othersMessage); &#125;&#125; 2.2 静态内部类方式静态内部类写法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * 构建的消息对象 * 有个静态内部类 * * @author illusoryCloud */public class Message &#123; /** * 标题 */ private String title; /** * 内容 */ private String content; /** * 发送者 */ private String from; /** * 接收者 */ private String to; /** * 时间 */ private Date time; @Override public String toString() &#123; return "Message&#123;" + "title='" + title + '\'' + ", content='" + content + '\'' + ", from='" + from + '\'' + ", to='" + to + '\'' + ", time=" + time + '&#125;'; &#125; public static Builder newBuilder() &#123; return new Builder(); &#125; /** * 静态内部类 builder */ public static class Builder &#123; /** * 设置默认值 */ private String title = "未命名"; private String content = "暂无内容"; private String from = "unknow"; private String to = "unknow"; private Date time = new Date(); /** * 设置消息标题 * * @param title 要设置的标题 * @return 返回Builder对象 以达到链式调用 */ public Builder setTitle(String title) &#123; this.title = title; return this; &#125; public Builder setContent(String content) &#123; this.content = content; return this; &#125; public Builder setFrom(String from) &#123; this.from = from; return this; &#125; public Builder setTo(String to) &#123; this.to = to; return this; &#125; public Builder setTime(Date time) &#123; this.time = time; return this; &#125; public Message build() &#123; Message message = new Message(); message.title = title; message.content = content; message.from = from; message.to = to; message.time = time; return message; &#125; &#125;&#125; 测试类 1234567891011121314151617/** * 建造者模式 测试类 * * @author illusoryCloud */public class Test &#123; @org.junit.jupiter.api.Test public void testBuilder() &#123; Message build = Message.newBuilder().setTitle("这是消息标题") .setContent("这是消息内容") .setFrom("这是消息发送者") .setTo("这是消息接收者") .setTime(new Date()) .Build(); System.out.println(build.toString()); &#125;&#125; 3. 总结建造者模式优点： 1.将对象本身与对象的创建过程解耦，使得相同的创建过程可以创建不同的对象。 2.可以更加精细地控制产品的创建过程 3.增加新的具体建造者无须修改原有类库的代码，符合开闭原则 与工厂模式的区别： 工厂模式注重的是整体对象的创建方法，只为了获取对象，关注整体 建造者模式注重的是部件构建的过程，旨在通过一步一步地精确构造创建出一个复杂的对象，关注细节。建造者模式一般用来创建更为复杂的对象 4. 参考https://blog.csdn.net/zhuhuitao_struggle/article/details/80489572]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(二)---工厂模式]]></title>
    <url>%2Fposts%2F34710.html</url>
    <content type="text"><![CDATA[本章主要介绍了设计模式中的工厂模式，并结合实例描述了工厂模式的具体实现和使用场景。包括：普通工厂模式、工厂方法模式、抽象工厂模式等。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介工厂模式可以分为普通工厂模、工厂方法模式和抽象工厂模式。 简单工厂模式：建立一个工厂类，根据传入的参数对实现了同一接口的一些类进行实例的创建。如果传入的字符串错误就不能正确创建对象。 工厂方法模式：是对普通工厂方法模式的改进，提供多个工厂方法，分别创建对象。 抽象工厂模式：创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。 工厂模式优点： (1) 解耦：把对象的创建和使用的过程分开 (2)减少重复代码: 若创建对象的过程很复杂，有一定的代码量，且很多地方都要用到，那么就会有很多重复代码。 (3) 降低维护成本 ：创建过程都由工厂统一管理，发生业务逻辑变化，只需要在工厂里修改即可。 适用场景 （1）需要创建的对象较少。 （2）客户端不关心对象的创建过程。 2. 简单工厂模式 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 抽象产品类 水果 */public interface Fruit &#123; void show();&#125;/** * 具体产品类 * 苹果 实现了水果接口 * @author illusoryCloud */public class Apple implements Fruit &#123; @Override public void show() &#123; System.out.println("This is Apple"); &#125;&#125;/** * 具体产品类 * 橘子 实现了水果接口 * @author illusoryCloud */public class Orange implements Fruit &#123; @Override public void show() &#123; System.out.println("This is Orange"); &#125;&#125;/** * 工厂类 水果工厂 * 负责生产各种产品 * * @author illusoryCloud */public class FruitFactory &#123; public static final String FRUIT_APPLE = "Apple"; public static final String FRUIT_ORANGE = "Orange"; public static Fruit creatFruit(String fruit) &#123; if (FRUIT_APPLE.equals(fruit)) &#123; return new Apple(); &#125; else if (FRUIT_ORANGE.equals(fruit)) &#123; return new Orange(); &#125; else &#123; System.out.println("error unknown fruit ~"); return null; &#125; &#125;&#125;/** * 简单工厂模式 测试 * * @author illusoryCloud * */public class EasyFactoryTest &#123; @Test public void testEasyFactory() &#123; Fruit apple = FruitFactory.creatFruit(FruitFactory.FRUIT_APPLE); if (apple != null) &#123; apple.show(); &#125; Fruit orange = FruitFactory.creatFruit(FruitFactory.FRUIT_ORANGE); if (orange != null) &#123; orange.show(); &#125; &#125;&#125; 3. 工厂方法模式简单工厂模式中，如果创建对象时传入的字符串出现错误则不能正确创建产品。工厂方法模式为每种产品创建一个工厂，则不会出现这样的问题。 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 抽象产品工厂类 * @author illusoryCloud */public interface FruitFactory &#123; Fruit create();&#125;/** * 具体产品工厂 实现接口 * 苹果工厂 * @author illusoryCloud */public class AppleFactory implements FruitFactory &#123; @Override public Fruit create() &#123; return new Apple(); &#125;&#125;/** * 具体产品工厂 实现接口 * 苹果工厂 * @author illusoryCloud */public class AppleFactory implements FruitFactory &#123; @Override public Fruit create() &#123; return new Apple(); &#125;&#125;/** * 工厂方法模式 测试类 * * @author illusoryCloud */public class FactoryMethodTest &#123; @Test public void factoryMethodTest() &#123; Fruit apple = new AppleFactory().create(); apple.show(); Fruit orange = new OrangeFactory().create(); orange.show(); &#125;&#125; 4. 抽象工厂模式网上找的一个类图： 工厂方法模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？就用到抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能，直接增加新的工厂类就可以了，不需要修改之前的代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/** * 抽象产品类 果汁 * * @author illusoryCloud */public interface Juice &#123; void show();&#125;/** * 具体产品类 * 苹果汁 * * @author illusoryCloud */public class AppleJuice implements Juice &#123; @Override public void show() &#123; System.out.println("AppleJuice"); &#125;&#125;/** * 具体产品类 * 橘子汁 * * @author illusoryCloud */public class OrangeJuice implements Juice &#123; @Override public void show() &#123; System.out.println("OrangeJuice"); &#125;&#125;/** * 抽象工厂类 * * @author illusoryCloud */public interface AbstractFactory &#123; /** * 创建水果 * * @return 水果 */ Fruit createFruit(); /** * 创建果汁 * * @return 果汁 */ Juice createJuice();&#125;/** * 具体工厂类 * 苹果工厂 生产苹果和苹果汁 * * @author illusoryCloud */public class AppleFactory implements AbstractFactory &#123; @Override public Fruit createFruit() &#123; return new Apple(); &#125; @Override public Juice createJuice() &#123; return new AppleJuice(); &#125;&#125;/** * 具体工厂类 * 橘子工厂 生产橘子和橘子汁 * * @author illusoryCloud */public class OrangeFactory implements AbstractFactory &#123; @Override public Fruit createFruit() &#123; return new Orange(); &#125; @Override public Juice createJuice() &#123; return new OrangeJuice(); &#125;&#125;/** * 抽象工厂模式 测试类 * * @author illusoryCloud */public class AbstractFactoryTest &#123; @Test public void abstractFactoryTest() &#123; //苹果产品簇 AbstractFactory appleFactory = new AppleFactory(); Fruit apple = appleFactory.createFruit(); Juice appleJuice = appleFactory.createJuice(); //橘子产品簇 AbstractFactory orangeFactory = new OrangeFactory(); Fruit orange = orangeFactory.createFruit(); Juice orangeJuice = orangeFactory.createJuice(); apple.show(); appleJuice.show(); orange.show(); orangeJuice.show(); &#125;&#125; 优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 缺点：产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 工厂里加代码，又要在具体的工厂里面加代码。要增加一个新的系列时比较简单。 例如上面例子中在苹果系列增加一个苹果派就很困难得修改苹果工厂和抽象工厂，但是若增加一个菠萝系列就很简单，只需要添加一个菠萝工厂就行了。 5. 总结工厂模式的优点？为什么要使用工厂模式 工厂都是用来封装对象的具体创建过程，减少重复代码，降低对象变化时的维护成本，将对象创建过程和使用相解耦。 工厂方法模式使用继承，抽象工厂使用对象组合；两者利用抽象的原则，将具体的实例化过程延迟到子类。 工厂利用的最重要和基本的原则——依赖抽象，不要依赖具体类。 应用场景 简单工厂：适合创建同一级别的不同对象。 工厂方法：为每种产品提供一个工厂类，通过不同的工厂实例来创建不同的产品。 抽象工厂模式：一个对象族（或是一组没有任何关系的对象）都有相同的约束，则可以使用抽象工厂模式。 工厂模式在Java中的应用 简单工厂模式 JDK中的简单工厂模式有很多应用，比较典型的比如线程池。我们使用线程池的时候，可以使用ThreadPoolExecutor，根据自己的喜好传入corePoolSize、maximumPoolSize、keepAliveTimem、unit、workQueue、threadFactory、handler这几个参数，new出一个指定的ThreadPoolExecutor出来。 工厂方法模式 123456789101112public interface ThreadFactory &#123; /** * Constructs a new &#123;@code Thread&#125;. Implementations may also initialize * priority, name, daemon status, &#123;@code ThreadGroup&#125;, etc. * * @param r a runnable to be executed by new thread instance * @return constructed thread, or &#123;@code null&#125; if the request to * create a thread is rejected */ Thread newThread(Runnable r);&#125; 这是一个生产线程的接口,具体的线程工厂可以implements这个接口并实现newThread(Runnable r)方法，来生产具体线程工厂想要生产的线程。 6. 参考https://blog.csdn.net/d1562901685/article/details/77623237 https://www.cnblogs.com/xrq730/p/4905578.html]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[volatile关键字在单例模式(双重校验锁)中的作用]]></title>
    <url>%2Fposts%2Fe7cef119.html</url>
    <content type="text"><![CDATA[本文主要讲述了Java单例模式之双重校验锁中volatile关键字的作用。 更多文章欢迎访问我的个人博客–&gt;幻境云图 上篇文章Java设计模式(一)–单例模式中讲了Java单例模式的几种写法，其中懒汉式和双重校验锁方式写法如下： 1. 懒汉式12345678910111213public class Singleton &#123; private static Singleton instance; private Singleton ()&#123;&#125; public static synchronized Singleton getInstance() &#123; if (instance == null) &#123; instance = new Singleton(); &#125; return instance; &#125; &#125; 这种方式实现的单例：实现了lazy loading 使用时才创建实例。synchronized保证了线程安全，但效率低。 2. 双重校验锁1234567891011121314151617public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; //1 if (singleton == null) &#123; //2 singleton = new Singleton(); //3 &#125; &#125; &#125; return singleton; &#125;&#125; 3. 执行过程双重校验锁方式的执行过程如下： 1.线程A进入 getInstance() 方法。 2.由于 singleton为 null，线程A在 //1 处进入 synchronized 块。 3.线程A被线程B预占。 4.线程B进入 getInstance() 方法。 5.由于 singleton仍旧为 null，线程B试图获取 //1 处的锁。然而，由于线程A已经持有该锁，线程B在 //1 处阻塞。 6.线程B被线程A预占。 7.线程A执行，由于在 //2 处实例仍旧为 null，线程A还创建一个 Singleton 对象并将其引用赋值给 instance。 8.线程A退出 synchronized 块并从 getInstance() 方法返回实例。 9.线程A被线程B预占。 10.线程B获取 //1 处的锁并检查 instance 是否为 null。 11.由于 singleton是非 null 的，并没有创建第二个 Singleton 对象，由线程A所创建的对象被返回。 4. 问题双重检查锁定背后的理论是完美的。不幸地是，现实完全不同。双重检查锁定的问题是：并不能保证它会在单处理器或多处理器计算机上顺利运行。 双重检查锁定失败的问题并不归咎于 JVM 中的实现 bug，而是归咎于 Java 平台内存模型。内存模型允许所谓的“无序写入”，这也是这些习语失败的一个主要原因。 singleton = new Singleton(); 该语句非原子操作，实际是三个步骤。 1.给 singleton 分配内存； 2.调用 Singleton 的构造函数来初始化成员变量； 3.将给 singleton 对象指向分配的内存空间（此时 singleton 才不为 null ）； 虚拟机的指令重排序–&gt; 执行命令时虚拟机可能会对以上3个步骤交换位置 最后可能是132这种 分配内存并修改指针后未初始化 多线程获取时可能会出现问题。 当线程A进入同步方法执行singleton = new Singleton();代码时，恰好这三个步骤重排序后为1 3 2， 那么步骤3执行后 singleton 已经不为 null ,但是未执行步骤2，singleton对象初始化不完全，此时线程B执行 getInstance() 方法，第一步判断时 singleton 不为null,则直接将未完全初始化的singleton对象返回了。 5. 解决如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的，同时还会禁止指令重排序 所以使用volatile关键字会禁止指令重排序,可以避免这种问题。使用volatile关键字后使得 singleton = new Singleton();语句一定会按照上面拆分的步骤123来执行。 参考https://blog.csdn.net/qq646040754/article/details/81327933]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式(一)---单例模式]]></title>
    <url>%2Fposts%2F53093.html</url>
    <content type="text"><![CDATA[本文主要介绍了设计模式的六大原则，并结合实例描述了各种单例模式的具体实现和性能分析测试。包括：饿汉式、静态内部类、懒汉式、双重校验锁、枚举等。 Java设计模式系列文章目录 Java设计模式(一)—单例模式 Java设计模式(二)—工厂模式 Java设计模式(三)—建造者模式 Java设计模式(四)—原型模式 Java设计模式(五)—适配器模式 Java设计模式(六)—装饰者模式 Java设计模式(七)—代理模式 Java设计模式(八)—外观模式 Java设计模式(九)—享元模式 Java设计模式(十)—策略模式 Java设计模式(十一)—模板方法模式 Java设计模式(十二)—观察者模式 Java设计模式(十三)—组合模式 …….. Demo下载–&gt; Github 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 设计模式的六大原则1、开闭原则（Open Close Principle） 开闭原则就是说对扩展开放，对修改关闭。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。 2、里氏代换原则（Liskov Substitution Principle） 其官方描述比较抽象，可自行百度。实际上可以这样理解： （1）子类的能力必须大于等于父类，即父类可以使用的方法，子类都可以使用。 （2）返回值也是同样的道理。假设一个父类方法返回一个List，子类返回一个ArrayList，这当然可以。如果父类方法返回一个ArrayList，子类返回一个List，就说不通了。这里子类返回值的能力是比父类小的。 （3）还有抛出异常的情况。任何子类方法可以声明抛出父类方法声明异常的子类。而不能声明抛出父类没有声明的异常。 3、依赖倒转原则（Dependence Inversion Principle） 这个是开闭原则的基础，具体内容：面向接口编程，依赖于抽象而不依赖于具体。 4、接口隔离原则（Interface Segregation Principle） 这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。还是一个降低类之间的耦合度的意思，从这儿我们看出，其实设计模式就是一个软件的设计思想，从大型软件架构出发，为了升级和维护方便。所以上文中多次出现：降低依赖，降低耦合。 5、迪米特法则（最少知道原则）（Demeter Principle） 为什么叫最少知道原则，就是说：一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 6、合成复用原则（Composite Reuse Principle） 原则是尽量使用合成/聚合的方式，而不是使用继承。 Java 中一般认为有 23 种设计模式，总体来说设计模式分为三大类： 创建型模式，共五种：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式，共七种：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式，共十一种：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录 模式、状态模式、访问者模式、中介者模式、解释器模式。 比较常用的有：工厂方法模式、抽象工厂模式、单例模式、建造者模式、适配器模式、代理模式、享元模式、策略模式、观察者模式。 2. 单例模式2.1 单例模式介绍作用：保证一个类仅有一个实例，并提供一个访问它的全局访问点。 主要解决：一个全局使用的类频繁地创建与销毁。 优点： 1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例。 2、避免对资源的多重占用（比如写文件操作）。 缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 应用场景： 1.配置文件访问类，不用每次使用时都new一个 2.数据库连接池 保证项目中只有一个连接池存在。 2.2 单例模式实现1. 饿汉式1234567891011121314151617181920212223242526/** * 饿汉式 * @author illusoryCloud */public class FirstSingleton &#123; /** * 类变量在类准备阶段就初始化了然后放在&lt;clinit&gt;构造方法中 * 一旦外部调用了静态方法，那么就会初始化完成。 * 一个类的&lt;clinit&gt;只会执行一次 保证多线程情况下不会创建多个实例 */ private static final FirstSingleton INSTANCE =new FirstSingleton(); /** * * 构造函数私有化 */ private FirstSingleton()&#123;&#125; /** * 提供公共方法以获取实例对象 * @return instance 实例对象 */ public static FirstSingleton getInstance()&#123; return INSTANCE ; &#125;&#125; 这种方式实现的单例：类加载时就创建实例。由classloder保证了线程安全。 2. 静态内部类123456789101112131415161718192021/** * 静态内部类方式 * * @author illusoryCloud */public class SecondSingleton &#123; private static class SingletonHolder &#123; /** * 静态变量类加载时才会被创建 且只会创建一次 */ private static final SecondSingleton INSTANCE = new SecondSingleton(); &#125; private SecondSingleton() &#123; &#125; public static SecondSingleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125;&#125; 这种方式实现的单例：实现了lazy loading 使用时才创建实例，由classloder保证了线程安全。 饿汉式/静态内部类是如何保证线程安全的： 在《深入理解JAVA虚拟机》中，有这么一句话: 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的&lt;clinit&gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法完毕。 3. 懒汉式12345678910111213141516171819202122232425/** * 懒汉式 * * @author illusoryCloud */public class ThirdSingleton &#123; private static ThirdSingleton instance; private ThirdSingleton() &#123; &#125; /** * synchronized 保证线程安全 但效率低 * * @return instance单例对象 */ public static synchronized ThirdSingleton getInstance() &#123; if (instance == null) &#123; instance = new ThirdSingleton(); &#125; return instance; &#125;&#125; 这种方式实现的单例：实现了lazy loading 使用时才创建实例。synchronized保证了线程安全，但效率低。 4. 双重校验锁12345678910111213141516171819202122232425262728293031323334/** * 双重校验锁式 * * @author illusoryCloud */public class FourSingleton &#123; /** * volatile关键字禁止指令重排序 * 保证多线程下不会获取到未完全初始化的实例 * 详细请阅读：https://www.lixueduan.com/posts/e7cef119.html */ private static volatile FourSingleton instance; private FourSingleton() &#123; &#125; /** * 双重if校验 缩小synchronized代码块范围 * 若instance不为空 就可直接return * * @return instance 实例对象 */ public static FourSingleton getInstance() &#123; if (instance == null) &#123; synchronized (FourSingleton.class) &#123; if (instance == null) &#123; //非原子操作 instance = new FourSingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 这种方式实现的单例：实现了lazy loading 使用时才创建实例。synchronized保证了线程安全，volatile禁止指令重排序保证了多线程获取时不为空，但要JDK1.5以上才行。详细信息请阅读volatile关键字在单例模式(双重校验锁)中的作用 5. 枚举123456789101112131415161718192021/** * 枚举式 * 序列化及反序列化安全 * @author illusoryCloud */public enum FiveSingleton &#123; //定义一个枚举的元素，它就是 singleton 的一个实例 INSTANCE; public void doSomeThing(FiveSingleton instance) &#123; System.out.println("枚举方式实现单例"); &#125;&#125;public class Test &#123; public static void main(String[] args) &#123; Singleton singleton = Singleton.INSTANCE; singleton.doSomeThing();//output:枚举方法实现单例 &#125;&#125; 这种方式也是《Effective Java 》以及《Java与模式》的作者推荐的方式。 静态内部类和双重校验锁已经这么优秀了为什么还要有第五种枚举式呢？ 因为前面4种都存在一个序列化和反序列化时的安全问题。将单例对象序列化后，在反序列化时会重新创建一个单例对象，违背了单例模式的初衷。而枚举式单例则没有这个问题，具体信息查看：枚举式单例模式与序列化 3. 性能测试五种单例实现方式，在100个线程下，每个线程访问1千万次实例的用时. Tables 实现方式 用时(毫秒) 1 饿汉式 13 2 懒汉式 10778 3 双重检查 15 4 静态内部类 14 5 枚举 12 (*注意:由于不同电脑之间的性能差异，测试的结果可能不同) 根据不同场合选择具体的实现方式，一般情况下我是使用的静态内部类或者DCL双重校验锁方式。 4. 总结为什么要使用单例模式？什么场景适合使用单例模式?单例模式有什么好处 1.单例模式能够保证一个类仅有唯一的实例，避免创建多个实例。并提供一个全局访问点，优化和共享资源访问。 2.当一个对象需要频繁创建和销毁时使用单例模式能节省系统资源。 应用场景： 1.配置文件访问类，不用每次使用时都new一个 2.数据库连接池 保证项目中只有一个连接池存在。 单例模式的缺点： 单例模式一般没有接口，扩展很困难，若要扩展只能修改代码。 单例模式在Java中的应用 1234567891011121314151617181920public class Runtime &#123; private static Runtime currentRuntime = new Runtime(); /** * Returns the runtime object associated with the current Java application. * Most of the methods of class &lt;code&gt;Runtime&lt;/code&gt; are instance * methods and must be invoked with respect to the current runtime object. * * @return the &lt;code&gt;Runtime&lt;/code&gt; object associated with the current * Java application. */ public static Runtime getRuntime() &#123; return currentRuntime; &#125; /** Don't let anyone else instantiate this class */ private Runtime() &#123;&#125; ...&#125; 5. 参考http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html https://blog.csdn.net/qq_22706515/article/details/74202814]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android事件分发机制详解]]></title>
    <url>%2Fposts%2F7d3d70a4.html</url>
    <content type="text"><![CDATA[本文主要记录了Android中的事件分发机制。通过对源码进行分析和实例测试，对Android事件分发机制有了更深的了解。主要为学习Android时的笔记。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 触发过程1.1 点击控件1.2 dispatchTouchEven一定会执行dispatchTouchEvent方法，若当前类没有该方法，则向上往父类查找。 1234567public boolean dispatchTouchEvent(MotionEvent event) &#123; if (mOnTouchListener != null &amp;&amp; (mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; mOnTouchListener.onTouch(this, event)) &#123; return true; &#125; return onTouchEvent(event);&#125; 条件1 mOnTouchListener != null 123public void setOnTouchListener(OnTouchListener l) &#123; mOnTouchListener = l;&#125; 给控件设置监听就会给mOnTouchListener赋值，则条件1成立。 条件2 (mViewFlags &amp; ENABLED_MASK) == ENABLED 控件是否是可点击的 条件3 mOnTouchListener.onTouch(this, event) 回调onTouch方法，返回true 则成立 小结：dispatchTouchEvent 方法中一定会执行onTouch方法，如果onTouch方法返回true 则dispatchTouchEvent方法直接返回true 不会执行if外的 return onTouchEvent(event)。 1234567 title_bar.setOnTouchListener(new View.OnTouchListener() &#123; @Override public boolean onTouch(View v, MotionEvent event) &#123;Log.v("Az","onTouch"); return false; &#125; &#125;); 在setOnTouchListener时，onTouch方法默认返回false,所以才会执行后面的onTouchEvent方法； 1.3 onTouchEvent1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192public boolean onTouchEvent(MotionEvent event) &#123; final int viewFlags = mViewFlags; if ((viewFlags &amp; ENABLED_MASK) == DISABLED) &#123; // A disabled view that is clickable still consumes the touch // events, it just doesn't respond to them. return (((viewFlags &amp; CLICKABLE) == CLICKABLE || (viewFlags &amp; LONG_CLICKABLE) == LONG_CLICKABLE)); &#125; if (mTouchDelegate != null) &#123; if (mTouchDelegate.onTouchEvent(event)) &#123; return true; &#125; &#125; if (((viewFlags &amp; CLICKABLE) == CLICKABLE || (viewFlags &amp; LONG_CLICKABLE) == LONG_CLICKABLE)) &#123; switch (event.getAction()) &#123; case MotionEvent.ACTION_UP: boolean prepressed = (mPrivateFlags &amp; PREPRESSED) != 0; if ((mPrivateFlags &amp; PRESSED) != 0 || prepressed) &#123; // take focus if we don't have it already and we should in // touch mode. boolean focusTaken = false; if (isFocusable() &amp;&amp; isFocusableInTouchMode() &amp;&amp; !isFocused()) &#123; focusTaken = requestFocus(); &#125; if (!mHasPerformedLongPress) &#123; // This is a tap, so remove the longpress check removeLongPressCallback(); // Only perform take click actions if we were in the pressed state if (!focusTaken) &#123; // Use a Runnable and post this rather than calling // performClick directly. This lets other visual state // of the view update before click actions start. if (mPerformClick == null) &#123; mPerformClick = new PerformClick(); &#125; if (!post(mPerformClick)) &#123; performClick(); &#125; &#125; &#125; if (mUnsetPressedState == null) &#123; mUnsetPressedState = new UnsetPressedState(); &#125; if (prepressed) &#123; mPrivateFlags |= PRESSED; refreshDrawableState(); postDelayed(mUnsetPressedState, ViewConfiguration.getPressedStateDuration()); &#125; else if (!post(mUnsetPressedState)) &#123; // If the post failed, unpress right now mUnsetPressedState.run(); &#125; removeTapCallback(); &#125; break; case MotionEvent.ACTION_DOWN: if (mPendingCheckForTap == null) &#123; mPendingCheckForTap = new CheckForTap(); &#125; mPrivateFlags |= PREPRESSED; mHasPerformedLongPress = false; postDelayed(mPendingCheckForTap, ViewConfiguration.getTapTimeout()); break; case MotionEvent.ACTION_CANCEL: mPrivateFlags &amp;= ~PRESSED; refreshDrawableState(); removeTapCallback(); break; case MotionEvent.ACTION_MOVE: final int x = (int) event.getX(); final int y = (int) event.getY(); // Be lenient about moving outside of buttons int slop = mTouchSlop; if ((x &lt; 0 - slop) || (x &gt;= getWidth() + slop) || (y &lt; 0 - slop) || (y &gt;= getHeight() + slop)) &#123; // Outside button removeTapCallback(); if ((mPrivateFlags &amp; PRESSED) != 0) &#123; // Remove any future long press/tap checks removeLongPressCallback(); // Need to switch from pressed to not pressed mPrivateFlags &amp;= ~PRESSED; refreshDrawableState(); &#125; &#125; break; &#125; return true; &#125; return false;&#125; 首先在第14行我们可以看出，如果该控件是可以点击的就会进入到第16行的switch判断中去，而如果当前的事件是抬起手指，则会进入到MotionEvent.ACTION_UP这个case当中。在经过种种判断之后，会执行到第38行的performClick()方法，那我们进入到这个方法里瞧一瞧： 若当前事件为抬手，则进入performClick方法 123456789public boolean performClick() &#123; sendAccessibilityEvent(AccessibilityEvent.TYPE_VIEW_CLICKED); if (mOnClickListener != null) &#123; playSoundEffect(SoundEffectConstants.CLICK); mOnClickListener.onClick(this); return true; &#125; return false;&#125; 如果 mOnClickListener != null 则会执行onClick方法， 123456public void setOnClickListener(OnClickListener l) &#123; if (!isClickable()) &#123; setClickable(true); &#125; mOnClickListener = l;&#125; 所以只要给控件设置了点击监听，setOnClickListener就会给mOnClickListener赋值，上面条件就成立，然后回调onClick方法。 到这儿差不多就清楚了分发流程。 这样View的整个事件分发的流程就让我们搞清楚了！不过别高兴的太早，现在还没结束，还有一个很重要的知识点需要说明，就是touch事件的层级传递。我们都知道如果给一个控件注册了touch事件，每次点击它的时候都会触发一系列的ACTION_DOWN，ACTION_MOVE，ACTION_UP等事件。这里需要注意，如果你在执行ACTION_DOWN的时候返回了false，后面一系列其它的action就不会再得到执行了。简单的说，就是当dispatchTouchEvent在进行事件分发的时候，只有前一个action返回true，才会触发后一个action。 1234567891011121314151617public boolean onTouchEvent(MotionEvent event) &#123; //省略...if (((viewFlags &amp; CLICKABLE) == CLICKABLE || (viewFlags &amp; LONG_CLICKABLE) == LONG_CLICKABLE)) &#123; switch (event.getAction()) &#123; case MotionEvent.ACTION_UP: break; case MotionEvent.ACTION_DOWN: break; case MotionEvent.ACTION_CANCEL: break; case MotionEvent.ACTION_MOVE: break; &#125; return true; &#125;&#125; 可以看出在dispatchTouchEvent方法中，onTouch方法返回false,然后执行onTouchEvent方法，在进入if判断后，不管进入那个case,最后都会return true,所以才会执行后续的action. **1. onTouch和onTouchEvent有什么区别，又该如何使用？** 都是dispatchTouchEvent中的方法，onTouch优先级高，若onTouch返回true，就会消费掉当前事件，onTouchEvent就不会执行。 要执行onTouch也需要两个条件，1 给控件设置了触摸监听OnTouchListener ，2该控件是可以点击的。 若控件是非enable的，则不会执行onTouch方法，会执行onTouchEvent，所以想要监听ouTouch事件只能重写onTouchEvent方法来实现。 小结： 控件被点击或触摸后一定会执行dispatchTouchEvent方法（当前类没有则去父类找），如果设置了触摸监听且控件是enable的，就执行onTouch方法 。OnTouch方法返回true则消耗掉本次事件，不执行后面的方法，返回false则执行onTouchEvent方法，如果设置了点击监听且控件是enable的，就在抬手的时候执行onClick方法。 给一个控件注册了touch事件，每次点击它的时候都会触发一系列的ACTION_DOWN，ACTION_MOVE，ACTION_UP等事件。当dispatchTouchEvent在进行事件分发的时候，只有前一个action返回true，才会触发后一个action。 2. ViewGroupAndroid中touch事件的传递，绝对是先传递到ViewGroup，再传递到View的 上边说只要你触摸了任何控件，就一定会调用该控件的dispatchTouchEvent方法。这个说法没错，只不过还不完整而已。实际情况是，当你点击了某个控件，首先会去调用该控件所在布局的dispatchTouchEvent方法，然后在布局的dispatchTouchEvent方法中找到被点击的相应控件，再去调用该控件的dispatchTouchEvent方法。 ViewGroup的dispatchTouchEvent方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public boolean dispatchTouchEvent(MotionEvent ev) &#123; final int action = ev.getAction(); final float xf = ev.getX(); final float yf = ev.getY(); final float scrolledXFloat = xf + mScrollX; final float scrolledYFloat = yf + mScrollY; final Rect frame = mTempRect; boolean disallowIntercept = (mGroupFlags &amp; FLAG_DISALLOW_INTERCEPT) != 0; if (action == MotionEvent.ACTION_DOWN) &#123; if (mMotionTarget != null) &#123; mMotionTarget = null; &#125; if (disallowIntercept || !onInterceptTouchEvent(ev)) &#123; ev.setAction(MotionEvent.ACTION_DOWN); final int scrolledXInt = (int) scrolledXFloat; final int scrolledYInt = (int) scrolledYFloat; final View[] children = mChildren; final int count = mChildrenCount; for (int i = count - 1; i &gt;= 0; i--) &#123; final View child = children[i]; if ((child.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) &#123; child.getHitRect(frame); if (frame.contains(scrolledXInt, scrolledYInt)) &#123; final float xc = scrolledXFloat - child.mLeft; final float yc = scrolledYFloat - child.mTop; ev.setLocation(xc, yc); child.mPrivateFlags &amp;= ~CANCEL_NEXT_UP_EVENT; if (child.dispatchTouchEvent(ev)) &#123; mMotionTarget = child; return true; &#125; &#125; &#125; &#125; &#125; &#125; boolean isUpOrCancel = (action == MotionEvent.ACTION_UP) || (action == MotionEvent.ACTION_CANCEL); if (isUpOrCancel) &#123; mGroupFlags &amp;= ~FLAG_DISALLOW_INTERCEPT; &#125; final View target = mMotionTarget; if (target == null) &#123; ev.setLocation(xf, yf); if ((mPrivateFlags &amp; CANCEL_NEXT_UP_EVENT) != 0) &#123; ev.setAction(MotionEvent.ACTION_CANCEL); mPrivateFlags &amp;= ~CANCEL_NEXT_UP_EVENT; &#125; return super.dispatchTouchEvent(ev); &#125; if (!disallowIntercept &amp;&amp; onInterceptTouchEvent(ev)) &#123; final float xc = scrolledXFloat - (float) target.mLeft; final float yc = scrolledYFloat - (float) target.mTop; mPrivateFlags &amp;= ~CANCEL_NEXT_UP_EVENT; ev.setAction(MotionEvent.ACTION_CANCEL); ev.setLocation(xc, yc); if (!target.dispatchTouchEvent(ev)) &#123; &#125; mMotionTarget = null; return true; &#125; if (isUpOrCancel) &#123; mMotionTarget = null; &#125; final float xc = scrolledXFloat - (float) target.mLeft; final float yc = scrolledYFloat - (float) target.mTop; ev.setLocation(xc, yc); if ((target.mPrivateFlags &amp; CANCEL_NEXT_UP_EVENT) != 0) &#123; ev.setAction(MotionEvent.ACTION_CANCEL); target.mPrivateFlags &amp;= ~CANCEL_NEXT_UP_EVENT; mMotionTarget = null; &#125; return target.dispatchTouchEvent(ev);&#125; 第二个if语句 if (disallowIntercept || !onInterceptTouchEvent(ev) 第一个条件disallowIntercept 是否禁用掉事件拦截的功能，默认是false 所以是否进入if内部就由第二个条件决定了。 ViewGroup中有一个onInterceptTouchEvent方法 是否拦截触摸事件 默认返回false 即不拦截 123public boolean onInterceptTouchEvent(MotionEvent ev) &#123; return false;&#125; 第二个条件 !onInterceptTouchEvent(ev) 对返回值取反 即返回false不拦截触摸事件时进入if内部，返回true拦截时不进入if内部 1234567891011121314//省略。。。if (disallowIntercept || !onInterceptTouchEvent(ev)) &#123; for (int i = count - 1; i &gt;= 0; i--) &#123;//遍历当前ViewGroup下的所有子View if ((child.mViewFlags &amp; VISIBILITY_MASK) == VISIBLE || child.getAnimation() != null) &#123; if (frame.contains(scrolledXInt, scrolledYInt)) &#123;//判断当前遍历的View是不是正在点击的View if (child.dispatchTouchEvent(ev)) &#123;//是则调用子View的dispatchTouchEvent mMotionTarget = child; return true; &#125; &#125; &#125; &#125; &#125; if内部对子View进行了遍历，最终调用子View的dispatchTouchEvent，然后控件可点击那么dispatchTouchEvent一定会返回true，所以后面的代码就执行不了。 即 ViewGroup 的onInterceptTouchEvent返回false,不拦截触摸事件时，最终会执行子View的dispatchTouchEvent。 ViewGroup 的onInterceptTouchEvent返回true,拦截触摸事件，就不会进入if内部，则会执行到后面的程序 12345678if (target == null) &#123; ev.setLocation(xf, yf); if ((mPrivateFlags &amp; CANCEL_NEXT_UP_EVENT) != 0) &#123; ev.setAction(MotionEvent.ACTION_CANCEL); mPrivateFlags &amp;= ~CANCEL_NEXT_UP_EVENT; &#125; return super.dispatchTouchEvent(ev); &#125; 可以看到，最后会执行super.dispatchTouchEvent(ev)，执行父类即View的dispatchTouchEvent。 View的dispatchTouchEvent如下： 1234567public boolean dispatchTouchEvent(MotionEvent event) &#123; if (mOnTouchListener != null &amp;&amp; (mViewFlags &amp; ENABLED_MASK) == ENABLED &amp;&amp; mOnTouchListener.onTouch(this, event)) &#123; return true; &#125; return onTouchEvent(event);&#125; 然后又和前面的一样了。执行onTouch或者onTouchEvent。。 3. 总结传递顺序Activity －&gt; PhoneWindow －&gt; DecorView －&gt; ViewGroup －&gt; … －&gt; View 通俗语言总结一下，事件来的时候， Activity会询问Window，Window这个事件你能不能消耗， Window一看，你先等等，我去问问DecorView他能不能消耗， DecorView一看，onInterceptTouchEvent返回false啊，不让我拦截啊， (DecorView继承自FrameLayout,FrameLayout是ViewGroup的子类，所以DecorView也是ViewGroup的子类，事件从Activity传到了ViewGroup) 遍历一下子View吧，问问他们能不能消耗，那个谁，事件按在你的身上了，你看看你能不能消耗， 假如子View为RelativeLayout RelativeLayout一看，也没有让我拦截啊，我也得遍历看看这个事件发生在那个子View上面， 到这儿事件从ViewGroup传到View上了 那个TextView,事件在你身上，你能不能消耗了他。TextView一看，消耗不了啊， RelativeLayout一看TextView消耗不了啊，mFirstTouchTarget==null啊，得，我自己消耗吧，嗯！一看自己的onTouchEvent也消耗不了啊！那个DecorView事件我消耗不了， DecorView一看自己，我也消耗不了，继续往上传，那个Window啊。事件我消耗不了啊， Window再告诉Activity事件消耗不了啊。 Activity还得我自己来啊。调用自己的onTouchEvent，还是消耗不了，算了，不要了。 最后Activity的onTouchEvent无论返回什么，事件分发都结束。（如果事件在边界范围外默认会返回false） 参考https://blog.csdn.net/guolin_blog/article/details/9097463 https://blog.csdn.net/guolin_blog/article/details/9153747]]></content>
      <categories>
        <category>Android</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git入门教程]]></title>
    <url>%2Fposts%2F498941.html</url>
    <content type="text"><![CDATA[​ 本文主要记录了Git常用的一些命令，和Git基本使用教学，包括了版本库的创建、代码提交、推送、拉取、版本回退、撤销等操作。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. 简介1.1 Git简介Git(读音为/gɪt/。)是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。 [1] Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。 1.2 Git工作区概念Git本地有四个工作区域：工作目录（Working Directory）、暂存区(Stage/Index)、版本库(Repository或Commit History)、远程仓库(Remote Directory)。文件在这四个区域之间的转换关系如下： Working Directory： 工作区，就是你平时存放项目代码的地方，大概就是一个文件夹。 Index / Stage： 暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息 Repository： 仓库区（或版本库），就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本 Remote： 远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换 1.3 工作流程git的工作流程一般是这样的： １、在工作目录中添加、修改文件； ２、将需要进行版本管理的文件放入暂存区域； ３、将暂存区域的文件提交到git仓库。 因此，git管理的文件有三种状态：已修改（modified）,已暂存（staged）,已提交(committed) 1.4 文件的四种状态版本控制就是对文件的版本控制，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在还不想提交的文件，或者要提交的文件没提交上。 GIT不关心文件两个版本之间的具体差别，而是关心文件的整体是否有改变，若文件被改变，在添加提交时就生成文件新版本的快照，而判断文件整体是否改变的方法就是用 SHA-1算法计算文件的校验和。 Untracked: 未跟踪, 此文件在文件夹中, 但并没有加入到git库, 不参与版本控制. 通过git add 状态变为Staged. Unmodify: 文件已经入库, 未修改, 即版本库中的文件快照内容与文件夹中完全一致. 这种类型的文件有两种去处, 如果它被修改, 而变为Modified. ​ 如果使用git rm移出版本库, 则成为Untracked文件 Modified: 文件已修改, 仅仅是修改, 并没有进行其他的操作. 这个文件也有两个去处, 通过git add可进入暂存staged状态, 使用git checkout 则丢弃修改过, ​ 返回到unmodify状态, 这个git checkout即从库中取出文件, 覆盖当前修改 ​ Staged: 暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodify状态. 执行git reset HEAD filename取消暂存, ​ 文件状态为Modified 下面的图很好的解释了这四种状态的转变： 新建文件后 —&gt;Untracked 使用add命令将新建的文件加入到暂存区—&gt;Staged 使用commit命令将暂存区的文件提交到本地仓库—&gt;Unmodified 如果对Unmodified状态的文件进行修改—&gt; modified 如果对Unmodified状态的文件进行remove操作—&gt;Untracked 2. 使用2.1 git配置使用之前首先要设置账号的。 12git config --global user.name //git中你的用户名 在查看提交历史等地方用到 一般为真实姓名 xxxgit config --global user.email //你的邮箱 一般为公司邮箱xxx@xxx.com 查看Git配置信息 1git config --list 2.2 创建git仓库git init用 git init 在目录中创建新的 Git 仓库。 你可以在任何时候、任何目录中这么做，完全是本地化的。执行后会在当前文件夹中多出一个.git文件夹，Git相关信息都在里面。 12$ git initInitialized empty Git repository in C:/Users/13452/Desktop/gitte/.git/ git clone当然，也可以在远程服务器上拉取代码，拷贝一个 Git 仓库到本地 123git clone [url]例如git clone git@github.com:illusorycloud/design-pattern.git 2.3 代码提交假如已经通过git clone从远程服务器上拉取了一下git仓库到本地了，然后在本地新增了一个test.txt文件 git status可以通过git status 查看当前文件的状态 由于是新增的文件，还未加入git追踪，所以当前test.txt为Untracked状态 1234567891011$ git statusOn branch masterNo commits yetUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) test.txtnothing added to commit but untracked files present (use "git add" to track) git diff执行git diff命令来查看文件与之前的区别。 1234git diff //查看本地工作区和index区域的文件的区别git diff --cached // 查看Index区域与Repository区域的区别git diff HEAD //查看所有文件与本地仓库的区别git diff --stat //只显示摘要而不是全部显示 git add在本地将文件修改完成后(Working Directory)使用git add命令可将该文件添加到缓存 (Index) 1234git add 文件名 //添加单个文件git add . //添加所有文件git add test.txt //将test.txt文件添加到Index git commit在使用 git add命令将想要快照的内容写入缓存区， 而执行git commit将缓存区内容添加到本地仓库中。(Repository) 1234git commit //提交Index中的文件 执行后会进入写注释的界面git commit -m"注释" //提交时直接写注释git commit -m"新增test.txt文件" git push在执行git commit将缓存区内容添加到本地仓库中后，可以使用git push将本地的修改推送到服务器上的远程仓库中，这样其他人就可以同步了。 12git push [主机名] [分支名]git push origin master //推送到Orinoco主机的master分支 其中默认的主机名是origin git reset撤销命令，git中比较重要的命令之一了。 1git reset [恢复等级] [commitId] soft/mixed/hardgit reset有三个参数，可以看做是三个恢复等级。 git reset –soft 仅仅将commit回退到了指定的提交 ，只修改Repository区域git reset –mixed用指定的commit覆盖Repository区域和Index区，之前所有暂存的内容都变为未暂存的状态 (默认为该参数) git reset –hard使用指定的commit的内容覆盖Repository区域、Index区和工作区。(危险！！！ 此操作会丢弃工作区所做的修改！需谨慎！！！) commidID表示将要恢复到哪个版本。有如下几种表示法 HEAD:表示当前最新的一次提交,(HEAD^)表示倒数第二次提交,(HEAD^^)表示倒数第三次提交，倒数第100次提交则是HEAD^^...^^^ 100个^,当然不会这么傻，还有另外一种写法HEAD~100 就是倒数第100次了。 当然还可以使用具体的commitID: 使用git log可以查看到提交历史，其中就包含了commitID 1234567891011121314151617181920212223$ git log ////这个是最新的一次提交的commitIdcommit 06f1cd144f57c38d6fdbed07616af8ed5d69a9ea(HEAD -&gt; hexo, origin/hexo, origin/HEAD)Author: lillusory &lt;xueduanli@163.com&gt;Date: Sat Feb 16 17:51:18 2019 +0800 添加Git工作区概念详解commit 8f8908ff3edbba0d24d7eee7682e09d002faee6f //这个就是commitIdAuthor: lillusory &lt;xueduanli@163.com&gt;Date: Fri Feb 15 19:10:06 2019 +0800 fix建造者模式两种写法commit 71a44acd12d427f694f554df1d2f26ad59df5978 //这个就是commitIdAuthor: lillusory &lt;xueduanli@163.com&gt;Date: Fri Feb 15 00:31:33 2019 +0800 fix 单例模式+Git 常用命令commit 099675715979832baa107f9da080bfd38d3d63e0 //这个就是commitIdAuthor: lillusory &lt;xueduanli@163.com&gt;Date: Thu Feb 14 23:26:10 2019 +0800 所以git reset有多种写法 12345git reset HEAD //Repository和Index恢复到最后一次提交的状态 不影响工作区git reset HEAD test.txt //只恢复test.txt 文件git reset --soft HEAD //Repository恢复到最后一次提交的状态git reset --hard HEAD //Repository、Index和工作区都恢复到最后一次提交的状态 丢弃工作区所有内容git reset 099675715979832baa107f9da080bfd38d3d63e0 //恢复到commitID版本 一般不用写完整的commitid 写前几位git就可以分辨出来了 git reflog前面的git reset可以恢复到各个版本，但是若恢复到前面的版本了，那么在使用git log查看是就找不到后面的提交了，想要恢复到后面的版本时就可以使用git reflog查看，该命令可以看到所有的版本改动信息。 1234567891011$ git logcommit 86a08a6fbacffcf93f7b4dd94be4a21ca31682c4 (HEAD -&gt; master)Author: lillusory &lt;xueduanli@163.com&gt;Date: Sat Feb 16 18:29:48 2019 +0800 新增test.txt $ git reflog86a08a6 HEAD@&#123;1&#125;: reset: moving to HEAD^b9802c7 (HEAD -&gt; master) HEAD@&#123;2&#125;: commit: 添加内容111186a08a6 HEAD@&#123;3&#125;: commit (initial): 新增test.txt git pull在其他人提交代码后，可以通过git pull命令拉取服务器代码到本地。 12git pull [主机名] [分支名]git pull origin master //推送到Orinoco主机的master分支 其中默认的主机名是origin 2.4 分支操作创建项目后默认在master分支 即主分支 应保证master分支代码永远是正确的，稳定的，可运行的 创建分支实际开发时一般会根据功能创建多个分支 123git branch branchName //创建分支branchNamegit checkout branchName //切换到分支branchNamegit checkout -b branchName //创建并切换到分支branchName 合并分支在新建的分支开发完后需要进行合并，将新的功能代码合并搭到master分支. 12341.切换到master分支 git checkout master2.把新分支代码合并 git merge branchName 删除分支合并完成后即可删除开发时创建的分 1git branch -d branchName //删除分支branchName 3. 常用命令12345678910111213141516171819202122232425# 新建仓库git initgit clone [url]# 代码提交git add &lt;filename&gt;git commit -m"注释"git push # 版本恢复git reset# 代码拉取git pull# 分支操作git branch &lt;branchName&gt;git checkout &lt;branchName&gt;git merge &lt;branchName&gt;# 信息查看git statusgit loggit refloggit config -l 最后附上一张网上找到的Git常用命令速查表 4. 参考http://www.runoob.com/git/git-basic-operations.html https://www.cnblogs.com/qdhxhz/p/9757390.html]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git 配置及SSH key及使用]]></title>
    <url>%2Fposts%2F49894.html</url>
    <content type="text"><![CDATA[​ 本地 Git 仓库和 GitHub 仓库之间的传输是通过 SSH 加密的，所以配置SSH key之后，上传代码到Github远程仓库时就不用输入密码了。一般是在C盘用户目录下有一个 something 和 something.pub 来命名的一对文件，这个 something 通常就是 id_dsa 或 id_rsa。有 .pub 后缀的文件就是公钥，另一个文件则是密钥。连接时必须提供一个公钥用于授权，没有的话就要生成一个。 更多文章欢迎访问我的个人博客–&gt;幻境云图 1. Git 配置配置全局用户名和密码，git提交代码时用来显示你身份和联系方式，并不是github用户名和邮箱 12git config --global user.name "lillusory" //改成自己的git config --global user.email "xueduanli@163.com" //改成自己的 2. 生成SSH key2.1 生成秘钥 执行ssh-keygen -t rsa -C &quot;你的邮箱地址&quot; 命令 生成ssh key 然后会叫你输入保存路径，直接按回车即可，保存在C盘用户目录下 然后会提示输入密码和确认密码，不用输入直接按两下回车即可 到这里SSH key就生成好了，接下来就是配置到github上。 2.2 配置SSH key 登陆Github–&gt;点击头像–&gt;Settings–&gt;SSH and GPG keys–&gt;选择SSh keys上的New SSH keys–&gt;name 随便写，key就是刚才生成的文件中的所有内容。 文件默认是在C盘用户目录下，我的是C:\Users\13452\.ssh 文件夹中应该会有两个文件 ：id_rsa和id_rsa.pub id_rsa.pub就是我们要的key, 一般以ssh-rsa开头，以你刚才输的邮箱结尾。 2.3 测试执行ssh -T git@github.com命令验证一下。 可能会提示，无法验证主机的真实性是否要建立连接，输入yes就行了。 如果，看到： Hi xxx! You’ve successfully authenticated, but GitHub does not # provide shell access. 恭喜你，你的设置已经成功了。 3. 参考Git Book]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
